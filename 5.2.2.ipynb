{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-30 12:44:25,289 - INFO - PyTorch version 1.1.0 available.\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import datetime\n",
    "import pickle\n",
    "import scipy.sparse as ss\n",
    "import logging\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '32'\n",
    "# import seaborn as sns\n",
    "\n",
    "import IPython.display as ipd\n",
    "import copy\n",
    "import random\n",
    "# from pandarallel import pandarallel\n",
    "# Initialization\n",
    "# pandarallel.initialize(progress_bar=True)\n",
    "# df.parallel_apply(func)\n",
    "import time\n",
    "from gensim.models.word2vec import Word2Vec \n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "\n",
    "from transformers import *\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers.modeling_bert import BertConfig, BertEncoder, BertAttention,\\\n",
    "BertSelfAttention,BertLayer,BertPooler,BertLayerNorm\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec \n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from scipy.special import softmax\n",
    "\n",
    "from category_encoders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:2\")\n",
    "# device=torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 18:26:37,442 - INFO - start read\n"
     ]
    }
   ],
   "source": [
    "logging.info('start read')\n",
    "df_master_records = pickle.load(open('../data_sortout/df_master_records.pickle', 'rb'))\n",
    "se_id_install_list = pickle.load(open('../data_sortout/se_id_install_list.pickle', 'rb'))\n",
    "df_install_behave = pickle.load(open('../data_sortout/df_install_behave_no_date.pickle', 'rb'))\n",
    "df_behave_time = pickle.load(open('../data_sortout/df_time_cut.pickle', 'rb'))\n",
    "# df_userlog = pickle.load(open('../data_sortout/df_userlog_sequence_less.pickle', 'rb'))\n",
    "se_userlog_cross = pickle.load(open('../data_sortout/se_userlog_cross_id.pickle', 'rb'))\n",
    "df_userlog_time_seq = pickle.load(open('../data_sortout/df_userlog_time_seq.pickle', 'rb'))\n",
    "\n",
    "# df_app_list_te_sequence = pickle.load(open('../data_sortout/df_app_list_target_encode_sequence.pickle', 'rb'))\n",
    "# df_app_behave_te_sequence = pickle.load(open('../data_sortout/df_app_behave_target_encode_sequence.pickle', 'rb'))\n",
    "\n",
    "df_app_list_te_qcut = pickle.load(open('../data_sortout/df_app_list_target_qcut.pickle', 'rb'))\n",
    "df_app_behave_te_qcut = pickle.load(open('../data_sortout/df_app_behave_target_qcut.pickle', 'rb'))\n",
    "\n",
    "\n",
    "logging.info('finish read')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 17:30:51,926 - INFO - all_train_id len :326082, all_test_id: 75896\n"
     ]
    }
   ],
   "source": [
    "split_date = datetime.datetime(2019, 8, 31)\n",
    "end_date = datetime.datetime(2019, 9, 30)\n",
    "\n",
    "df_master_records = df_master_records.dropna(axis=0, how='any')\n",
    "df_train_master = df_master_records.query('loan_date <= @split_date')\n",
    "df_test_master = df_master_records.query('loan_date > @split_date & loan_date <= @end_date')\n",
    "all_train_id = list(df_train_master.index)\n",
    "all_test_id = list(df_test_master.index)\n",
    "logging.info('all_train_id len :%d, all_test_id: %d' % (len(all_train_id), len(all_test_id)))\n",
    "df_target = df_master_records[['target_1m30+', 'target_2m30+', 'target_3m30+', 'target_4m30+']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_app_list_id = max(se_id_install_list.apply(max))\n",
    "max_app_behave_id = max(df_install_behave['pkg_id'].apply(max))\n",
    "max_uselog_id = max(se_userlog_cross.apply(max))\n",
    "start_app_list_id = max_app_list_id + 1\n",
    "start_app_behave_id = max_app_behave_id + 1 \n",
    "start_uselog_id = max_uselog_id + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_master_user_discrete(df_master_records):\n",
    "    \n",
    "    df_master_records['qcut_amount_bin'] = pd.qcut(df_master_records['amount_bin'], 5)\n",
    "    df_master_records['new_client'] = df_master_records['loan_sequence'] == 1\n",
    "    df_master_records['qcut_age'] = pd.qcut(df_master_records['age'], 5, duplicates='drop')\n",
    "    \n",
    "    df_master_records['qcut_min_income'] = pd.qcut(df_master_records['min_income'], 6, duplicates='drop')\n",
    "    df_master_records['qcut_max_income'] = pd.qcut(df_master_records['max_income'].apply(int), 6, duplicates='drop')\n",
    "\n",
    "#     df_master_records['qcut_loan_sequence'] = pd.qcut(df_master_records['loan_sequence'], 6, duplicates='drop')\n",
    "#     pne_hot_cols = ['months', 'gender', 'educationid', 'marriagestatusid', 'income', \n",
    "#                     'qcut_amount_bin', 'new_client', 'qcut_loan_sequence', 'qcut_age', 'qcut_min_income', 'qcut_max_income']\n",
    "    pne_hot_cols = ['months', 'gender', 'educationid', 'marriagestatusid', 'income', \n",
    "                'qcut_amount_bin', 'qcut_age', 'qcut_min_income', 'qcut_max_income']\n",
    "\n",
    "    return  pd.get_dummies(df_master_records[pne_hot_cols], columns = pne_hot_cols)\n",
    "df_user_one_hot = get_master_user_discrete(df_master_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "ARG = namedtuple('ARG', [\n",
    "    'batch_size',\n",
    "    'epoch',\n",
    "    'lr',\n",
    "    'weight_decay',\n",
    "    'debug',\n",
    "    'n_embedding',\n",
    "    'app_install_list_max_length',\n",
    "    'app_behave_max_length',\n",
    "    'userlog_max_length',\n",
    "    'n_eval',\n",
    "    'dropout_rate',\n",
    "    'n_worker',\n",
    "    'use_cuda',\n",
    "    'n_gpu',\n",
    "    'device',\n",
    "    'card_list'\n",
    "])\n",
    " \n",
    "args = ARG(\n",
    "    batch_size = 256,\n",
    "    epoch = 16,\n",
    "    lr = 0.001,\n",
    "    weight_decay = 0.0,\n",
    "    dropout_rate = 0.,\n",
    "    debug = False,\n",
    "    n_embedding = 100,\n",
    "    app_install_list_max_length = 256,\n",
    "    app_behave_max_length = 256,\n",
    "    userlog_max_length = 256,\n",
    "    n_eval = len(all_test_id)+1,\n",
    "    n_worker = 0,\n",
    "    use_cuda = True,\n",
    "    n_gpu = 1,\n",
    "    card_list = [0, 1],\n",
    "#     device=torch.device(\"cuda:1\"),\n",
    "    device=torch.device(\"cpu\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_behave_set = set(df_install_behave.index) & (set(all_train_id) | set(all_test_id))\n",
    "install_list_set = set(se_id_install_list.index) & (set(all_train_id) | set(all_test_id))\n",
    "user_info_set = set(df_user_one_hot.index) & (set(all_train_id) | set(all_test_id))\n",
    "user_log_set = set(se_userlog_cross.index) & (set(all_train_id) | set(all_test_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     10,
     37,
     53,
     59
    ]
   },
   "outputs": [],
   "source": [
    "class AppDataset(Data.Dataset):\n",
    "    def __init__(self, master_ids):\n",
    "        self.master_ids = list(master_ids)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.master_ids)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.master_ids[idx]\n",
    "\n",
    "x_dict = {\n",
    "    \n",
    "    'user_info' : np.zeros((args.batch_size, df_user_one_hot.shape[1])),\n",
    "\n",
    "    'app_list' : np.zeros((args.batch_size, args.app_install_list_max_length + 1)).astype('int'),\n",
    "    'app_list_te_qcut' : np.zeros((args.batch_size, args.app_install_list_max_length + 1, 4)).astype('int'),\n",
    "    'app_list_len' :  np.zeros((args.batch_size,)).astype('int'),\n",
    "    \n",
    "    'app_behave' : np.zeros((args.batch_size, args.app_behave_max_length + 1)).astype('int'),\n",
    "    'app_behave_time_cut' : np.zeros((args.batch_size, args.app_behave_max_length + 1)).astype('int'),\n",
    "    'app_behave_time_qcut' : np.zeros((args.batch_size, args.app_behave_max_length + 1)).astype('int'),\n",
    "    \n",
    "    'app_behave_action' : np.zeros((args.batch_size, args.app_behave_max_length + 1)).astype('int'),\n",
    "    'app_behave_te_qcut' : np.zeros((args.batch_size, args.app_behave_max_length + 1, 4)).astype('int'),\n",
    "\n",
    "    'app_behave_len' :  np.zeros((args.batch_size,)).astype('int'),\n",
    "    \n",
    "    'userlog' : np.zeros((args.batch_size, args.userlog_max_length + 1)).astype('int'),\n",
    "    'userlog_len' :  np.zeros((args.batch_size,)).astype('int'),\n",
    "    'userlog_day_qcut' : np.zeros((args.batch_size, args.userlog_max_length + 1)).astype('int'),\n",
    "    'userlog_day_cut' : np.zeros((args.batch_size, args.userlog_max_length + 1)).astype('int'),\n",
    "    'userlog_second_qcut' : np.zeros((args.batch_size, args.userlog_max_length + 1)).astype('int'),\n",
    "    'userlog_second_cut' : np.zeros((args.batch_size, args.userlog_max_length + 1)).astype('int'),\n",
    "    \n",
    "    'view_mask' : np.zeros((args.batch_size, 4)).astype('int'),\n",
    "}\n",
    "\n",
    "def set_first_token():\n",
    "    x_dict['app_list'][:, 0] = start_app_list_id\n",
    "    x_dict['app_behave'][:, 0] = start_app_behave_id\n",
    "    x_dict['userlog'][:, 0] = start_uselog_id\n",
    "\n",
    "    x_dict['app_list'][:, 0] = 0\n",
    "    x_dict['app_behave'][:, 0] = 0\n",
    "    x_dict['userlog'][:, 0] = 0\n",
    "\n",
    "    x_dict['userlog_day_qcut'][:, 0] = 8\n",
    "    x_dict['userlog_day_cut'][:, 0] = 8\n",
    "    x_dict['userlog_second_qcut'][:, 0] = 32\n",
    "    x_dict['userlog_second_cut'][:, 0] = 32\n",
    "\n",
    "set_first_token()\n",
    "\n",
    "def collate_fn(master_ids):\n",
    "    master_ids = np.array(master_ids)\n",
    "\n",
    "#     sub_master_id = se_id_install_list.loc[master_ids]\n",
    "#     df_sub_behave = df_install_behave.loc[master_ids]\n",
    "#     df_sub_time = df_behave_time.loc[master_ids]\n",
    "    for i, master_id in enumerate(master_ids):\n",
    "        if master_id in user_info_set:\n",
    "            x_dict['user_info'][i] = df_user_one_hot.loc[master_id].values\n",
    "            x_dict['view_mask'][i][0] = 1\n",
    "        else:\n",
    "            x_dict['user_info'][i] = 0\n",
    "            x_dict['view_mask'][i][0] = 0\n",
    "\n",
    "        if master_id in install_list_set:\n",
    "            app_list = se_id_install_list.at[master_id][:args.app_install_list_max_length]\n",
    "            x_dict['app_list_len'][i] = len(app_list) + 1\n",
    "            x_dict['app_list'][i][1 : x_dict['app_list_len'][i]] = app_list\n",
    "            x_dict['app_list'][i][x_dict['app_list_len'][i] :] = 0\n",
    "            \n",
    "#             target_encode_data = np.array(list(df_app_list_te_qcut.loc[master_id].values))[:, :args.app_install_list_max_length].T\n",
    "#             x_dict['app_list_te_qcut'][i][1 : x_dict['app_list_len'][i]] = target_encode_data\n",
    "            \n",
    "            x_dict['view_mask'][i][1] = 1\n",
    "        else:\n",
    "            x_dict['app_list_len'][i] = 1\n",
    "            x_dict['app_list'][i][1:] = 0\n",
    "            x_dict['app_list_te_qcut'][i] = 0\n",
    "            x_dict['view_mask'][i][1] = 0\n",
    "\n",
    "        if master_id in install_behave_set:\n",
    "            app_behave = df_install_behave['pkg_id'].at[master_id][-args.app_behave_max_length:]\n",
    "            len_app = len(app_behave) + 1\n",
    "            x_dict['app_behave_len'][i] = len_app\n",
    "            x_dict['app_behave'][i][1: len_app] = app_behave\n",
    "            x_dict['app_behave'][i][len_app :] = 0\n",
    "            \n",
    "#             target_encode_data = np.array(list(df_app_behave_te_qcut.loc[master_id].values))[:, -args.app_behave_max_length:].T\n",
    "#             x_dict['app_behave_te_qcut'][i][1 : len_app] = target_encode_data\n",
    "            \n",
    "            x_dict['app_behave_time_cut'][i][1:len_app] = df_behave_time['cut_id'].at[master_id][-args.app_behave_max_length:]\n",
    "            x_dict['app_behave_time_qcut'][i][1:len_app] = df_behave_time['qcut_id'].at[master_id][-args.app_behave_max_length:]\n",
    "            x_dict['app_behave_action'][i][1:len_app] = df_install_behave['action'].at[master_id][-args.app_behave_max_length:]\n",
    "            x_dict['view_mask'][i][2] = 1\n",
    "        else:\n",
    "            x_dict['app_behave_len'][i] = 1\n",
    "            x_dict['app_behave'][i][1:] = 0\n",
    "            x_dict['app_behave_te_qcut'][i] = 0\n",
    "\n",
    "            x_dict['app_behave_time_cut'][i][1:] = 0\n",
    "            x_dict['app_behave_time_qcut'][i][1:] = 0\n",
    "            x_dict['app_behave_action'][i][1:] = 0\n",
    "            x_dict['view_mask'][i][2] = 0\n",
    "        \n",
    "        \n",
    "        if master_id in user_log_set:\n",
    "            userlog_list = se_userlog_cross.at[master_id][:args.userlog_max_length]\n",
    "            len_userlog = len(userlog_list) + 1\n",
    "            x_dict['userlog_len'][i] = len_userlog\n",
    "            x_dict['userlog'][i][1 : len_userlog] = userlog_list\n",
    "            x_dict['userlog'][i][len_userlog :] = 0\n",
    "            x_dict['userlog_day_qcut'][i][1 : len_userlog] = df_userlog_time_seq['qcut_day_id'].at[master_id][:args.userlog_max_length]\n",
    "            x_dict['userlog_day_qcut'][i][len_userlog :] = 0\n",
    "            x_dict['userlog_day_cut'][i][1 : len_userlog] = df_userlog_time_seq['cut_day_id'].at[master_id][:args.userlog_max_length]\n",
    "            x_dict['userlog_day_cut'][i][len_userlog :] = 0\n",
    "            x_dict['userlog_second_qcut'][i][1 : len_userlog] = df_userlog_time_seq['qcut_second_id'].at[master_id][:args.userlog_max_length]\n",
    "            x_dict['userlog_second_qcut'][i][len_userlog :] = 0\n",
    "            x_dict['userlog_second_cut'][i][1 : len_userlog] = df_userlog_time_seq['cut_second_id'].at[master_id][:args.userlog_max_length]\n",
    "            x_dict['userlog_second_cut'][i][len_userlog :] = 0\n",
    "\n",
    "            x_dict['view_mask'][i][3] = 1\n",
    "        else:\n",
    "            x_dict['userlog_len'][i] = 1\n",
    "            x_dict['userlog'][i] = 0\n",
    "            x_dict['userlog_day_qcut'][i] = 0\n",
    "            x_dict['userlog_day_cut'][i] = 0\n",
    "            x_dict['userlog_second_qcut'][i] = 0\n",
    "            x_dict['userlog_second_cut'][i] = 0\n",
    "\n",
    "            x_dict['view_mask'][i][3] = 0\n",
    "    \n",
    "    \n",
    "    len_id = master_ids.shape[0]\n",
    "    x_dict['app_list'][len_id:] = 0\n",
    "    x_dict['app_behave'][len_id:] = 0\n",
    "    return {\n",
    "        \n",
    "        'user_info' : torch.tensor(x_dict['user_info'][:len_id]).float(),\n",
    "        \n",
    "        'app_list' : torch.tensor(x_dict['app_list'][:len_id]).long(),\n",
    "        'app_list_te_qcut' : torch.tensor(x_dict['app_list_te_qcut'][:len_id]).long(),\n",
    "        'app_list_len' : torch.tensor(x_dict['app_list_len'][:len_id]).long(),\n",
    "        \n",
    "        'app_behave' : torch.tensor(x_dict['app_behave'][:len_id]).long(),\n",
    "        'app_behave_te_qcut' : torch.tensor(x_dict['app_behave_te_qcut'][:len_id]).long(),\n",
    "        'app_behave_len' : torch.tensor(x_dict['app_behave_len'][:len_id]).long(),\n",
    "        \n",
    "        'app_behave_time_cut' : torch.tensor(x_dict['app_behave_time_cut'][:len_id]).long(),\n",
    "        'app_behave_time_qcut' : torch.tensor(x_dict['app_behave_time_qcut'][:len_id]).long(),\n",
    "        'app_behave_action' : torch.tensor(x_dict['app_behave_action'][:len_id]).long(),\n",
    "        'userlog' : torch.tensor(x_dict['userlog'][:len_id]).long(),\n",
    "        'userlog_len' : torch.tensor(x_dict['userlog_len'][:len_id]).long(),\n",
    "        'userlog_day_qcut' : torch.tensor(x_dict['userlog_day_qcut'][:len_id]).long(),\n",
    "        'userlog_day_cut' : torch.tensor(x_dict['userlog_day_cut'][:len_id]).long(),\n",
    "        'userlog_second_qcut' : torch.tensor(x_dict['userlog_second_qcut'][:len_id]).long(),\n",
    "        'userlog_second_cut' : torch.tensor(x_dict['userlog_second_cut'][:len_id]).long(),\n",
    "\n",
    "        'view_mask' : torch.tensor(x_dict['view_mask'][:len_id]).long(),\n",
    "        'labels1' : torch.tensor(df_target.loc[master_ids]['target_1m30+'].values).long(),\n",
    "        'labels2' : torch.tensor(df_target.loc[master_ids]['target_2m30+'].values).long(),\n",
    "        'labels3' : torch.tensor(df_target.loc[master_ids]['target_3m30+'].values).long(),\n",
    "        'labels4' : torch.tensor(df_target.loc[master_ids]['target_4m30+'].values).long(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0,
     12,
     23,
     39,
     56,
     67,
     92,
     96,
     116,
     153,
     201,
     202,
     233,
     289,
     290,
     321
    ]
   },
   "outputs": [],
   "source": [
    "def masked_softmax(X, valid_len):\n",
    "    if valid_len is None:\n",
    "        return F.softmax(X,dim=-1)\n",
    "    else:\n",
    "        shape=X.shape\n",
    "        if valid_len.dim()==1:\n",
    "            valid_len=valid_len.view(-1,1).repeat(1,shape[1])\n",
    "        mask = (torch.arange(0,X.shape[-1]).repeat(X.shape[0],1).to(args.device) < valid_len).repeat(1, X.shape[1]).view(shape)\n",
    "        \n",
    "        X = X.masked_fill_(~mask, -float('inf'))\n",
    "        return F.softmax(X,dim=-1).view(shape)\n",
    "\n",
    "def make_mask(X, valid_len):\n",
    "    if valid_len is None:\n",
    "        return F.softmax(X,dim=-1)\n",
    "    else:\n",
    "        shape=X.shape\n",
    "        if valid_len.dim()==1:\n",
    "            valid_len=valid_len.view(-1,1).repeat(1,shape[1])\n",
    "\n",
    "        mask=(torch.arange(0,X.shape[1]).repeat(X.shape[0],1).to(X.device)<valid_len).byte()\n",
    "        return mask.unsqueeze(2) \n",
    "\n",
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # `query`: (`batch_size`, #queries, `d`)\n",
    "    # `key`: (`batch_size`, #kv_pairs, `d`)\n",
    "    # `value`: (`batch_size`, #kv_pairs, `dim_v`)\n",
    "    # `valid_len`: either (`batch_size`, ) or (`batch_size`, xx)\n",
    "    def forward(self, query, key, value, valid_len=None):\n",
    "        d = query.shape[-1]\n",
    "        # Set transpose_b=True to swap the last two dimensions of key\n",
    "        scores = torch.bmm(query, key.transpose(1,2)) / math.sqrt(d)\n",
    "        attention_weights = self.dropout(masked_softmax(scores, valid_len))\n",
    "        return torch.bmm(attention_weights, value)\n",
    "    \n",
    "class MLPAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size, units, dropout=0., **kwargs):\n",
    "        super(MLPAttention, self).__init__(**kwargs)\n",
    "        self.W_k = nn.Linear(key_size, units, bias=False)\n",
    "        self.W_q = nn.Linear(query_size, units, bias=False)\n",
    "        self.v = nn.Linear(units, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, valid_len):\n",
    "        query, key = self.W_k(query), self.W_q(key)\n",
    "        # Expand query to (`batch_size`, #queries, 1, units), and key to\n",
    "        # (`batch_size`, 1, #kv_pairs, units). Then plus them with broadcast\n",
    "        features = query.unsqueeze(2) + key.unsqueeze(1)\n",
    "        scores = self.v(features).squeeze(-1)\n",
    "        attention_weights = self.dropout(masked_softmax(scores, valid_len))\n",
    "        return torch.bmm(attention_weights, value)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,features,eps=1e-6):\n",
    "        super(LayerNorm,self).__init__()\n",
    "        self.gamma=nn.Parameter(torch.ones(features))\n",
    "        self.beta=nn.Parameter(torch.zeros(features))\n",
    "        self.eps=eps\n",
    "    def forward(self,X):\n",
    "        mean=X.mean(-1,keepdim=True)\n",
    "        std=X.std(-1,keepdim=True)\n",
    "        return self.gamma*(X-mean)/(std+self.eps)+self.beta\n",
    "    \n",
    "class MLPAttentionPool(nn.Module):\n",
    "    def __init__(self,key_size,units):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(nn.Linear(key_size,units,bias=False),\n",
    "                                  nn.Tanh(),\n",
    "                                  nn.Linear(units,1,bias=False))\n",
    "        \n",
    "    def masked_softmax_1d(self, X, valid_len):\n",
    "        if valid_len is None:\n",
    "            return F.softmax(X,dim=-1), _\n",
    "        else:\n",
    "            shape=X.shape\n",
    "            if valid_len.dim()==1:\n",
    "                valid_len=valid_len.view(-1,1).repeat(1,shape[1])\n",
    "\n",
    "            mask=(torch.arange(0,X.shape[-1]).repeat(X.shape[0],1).to(X.device)<valid_len).byte()\n",
    "            X = X.masked_fill_(~mask, -float('inf'))\n",
    "            return F.softmax(X,dim=-1).view(shape), mask\n",
    "\n",
    "    def forward(self, key, valid_len):\n",
    "        scores = self.proj(key).squeeze(-1)\n",
    "        attention_weights, mask = self.masked_softmax_1d(scores,valid_len)\n",
    "        seq_out = attention_weights.unsqueeze(-1) * key\n",
    "        return seq_out.sum(1)\n",
    "\n",
    "class GeLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1. + torch.tanh(x * 0.7978845608 * (1. + 0.044715 * x * x)))\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super().__init__()\n",
    "        hidden = 128\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_feature, hidden),\n",
    "            GeLU(),\n",
    "            nn.Dropout(args.dropout_rate),\n",
    "            nn.Linear(hidden, out_feature)\n",
    "        )\n",
    "        self.dense.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)\n",
    "\n",
    "class UserNetwork(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        n_dim = df_user_one_hot.shape[1]\n",
    "        self.dense_hidden = Dense(n_dim, config.hidden)\n",
    "\n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "        \n",
    "    def forward(self, input_dict):\n",
    "        \n",
    "        x = input_dict['user_info'].to(args.device)\n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        \n",
    "        hidden = self.dense_hidden(x)\n",
    "        \n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "        \n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return loss, y1, y2, y3, y4, hidden\n",
    "\n",
    "class AppListNetwork(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 64\n",
    "        self.input_size = 100\n",
    "        self.embeddings = nn.Embedding.from_pretrained(app_list_weight)\n",
    "        self.layer_norm = LayerNorm(self.input_size)\n",
    "        \n",
    "#         self.attention_layer = DotProductAttention(0.)\n",
    "#         self.attention_layer = MLPAttention(self.input_size, self.input_size, 256)\n",
    "\n",
    "        self.attention_layer = MLPAttentionPool(self.input_size, config.hidden)\n",
    "        self.dense_hidden = Dense(self.input_size, config.hidden)\n",
    "        \n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "        \n",
    "    def forward(self, input_dict):\n",
    "        app_list_ids = input_dict['app_list'].to(args.device)\n",
    "        app_list_len = input_dict['app_list_len'].to(args.device)\n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "\n",
    "        app_list = self.embeddings(app_list_ids)\n",
    "        app_list = self.layer_norm(app_list)\n",
    "\n",
    "        x = self.attention_layer(app_list, app_list_len)\n",
    "        \n",
    "        hidden = self.dense_hidden(x)        \n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "        \n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return loss, y1, y2, y3, y4, hidden\n",
    "\n",
    "class AppBehaveNetwork(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.hidden_size = config.hidden\n",
    "        self.embeddings = nn.Embedding.from_pretrained(app_behave_weight)        \n",
    "        for i in self.embeddings.parameters():\n",
    "            i.requires_grad=False\n",
    "        \n",
    "        self.qcut_time_embeddings = nn.Embedding(64, 16)\n",
    "        self.cut_time_embeddings = nn.Embedding(64, 16)\n",
    "#         self.action_embeddings = nn.Embedding(2, 4)\n",
    "\n",
    "        \n",
    "        self.layer_norm = LayerNorm(100)\n",
    "        self.rnn = nn.GRU(16 + 16 + 100,\n",
    "                          hidden_size = config.hidden,\n",
    "                          num_layers = 1,\n",
    "                          dropout = 0,\n",
    "                          bidirectional = False, \n",
    "                          batch_first=True)\n",
    "        \n",
    "#         self.attention_layer = DotProductAttention(0.)\n",
    "#         self.attention_layer = MLPAttention(config.hidden, config.hidden, config.hidden)\n",
    "        self.attention_layer = MLPAttentionPool(config.hidden, config.hidden)\n",
    "\n",
    "        self.dense_hidden = Dense(config.hidden, config.hidden)\n",
    "\n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "\n",
    "    def rnn_forward(self, x, x_lens):\n",
    "        X = torch.nn.utils.rnn.pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
    "        hidden, _= self.rnn(X)\n",
    "        hidden, _ = torch.nn.utils.rnn.pad_packed_sequence(hidden,total_length=x.shape[1],batch_first=True)\n",
    "        return hidden\n",
    "   \n",
    "    def forward(self, input_dict):\n",
    "        \n",
    "        app_behave_ids = input_dict['app_behave'].to(args.device)\n",
    "        app_behave_len = input_dict['app_behave_len'].to(args.device)\n",
    "        app_behave_time_cut = input_dict['app_behave_time_cut'].to(args.device)\n",
    "        app_behave_time_qcut = input_dict['app_behave_time_qcut'].to(args.device)\n",
    "#         app_behave_action = input_dict['app_behave_action'].to(args.device)\n",
    "        \n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        \n",
    "        app_behave = self.embeddings(app_behave_ids)\n",
    "#         app_behave = self.layer_norm(app_behave)\n",
    "        cut_time_embed = self.cut_time_embeddings(app_behave_time_cut)\n",
    "        qcut_time_embed = self.cut_time_embeddings(app_behave_time_qcut)\n",
    "#         action_embed = self.action_embeddings(app_behave_action)\n",
    "        \n",
    "        seq_data = torch.cat([\n",
    "            app_behave, \n",
    "            cut_time_embed,\n",
    "            qcut_time_embed,\n",
    "#             action_embed,\n",
    "        ], dim = -1)\n",
    "        \n",
    "        \n",
    "        rnn_out = self.rnn_forward(seq_data, app_behave_len)\n",
    "        \n",
    "        x = self.attention_layer(rnn_out, app_behave_len)\n",
    "#         mask = make_mask(x, app_behave_len)\n",
    "#         x = x.masked_fill_(~mask, 0).sum(1)\n",
    "\n",
    "        \n",
    "        hidden = self.dense_hidden(x)\n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "        \n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return loss, y1, y2, y3, y4, hidden\n",
    "\n",
    "class UserlogNetwork(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.hidden_size = config.hidden\n",
    "        self.embeddings = nn.Embedding.from_pretrained(userlog_weight)        \n",
    "#         for i in self.embeddings.parameters():\n",
    "#             i.requires_grad=False\n",
    "        self.embeddings_day_qcut = nn.Embedding(9, 8)\n",
    "        self.embeddings_day_cut = nn.Embedding(9, 8)\n",
    "        self.embeddings_second_qcut = nn.Embedding(33, 16)\n",
    "        self.embeddings_second_cut = nn.Embedding(33, 16)\n",
    "\n",
    "        \n",
    "        self.layer_norm = LayerNorm(100)\n",
    "        self.rnn = nn.GRU(100 + 8 + 16 + 8 + 16,\n",
    "                          hidden_size = config.hidden,\n",
    "                          num_layers = 1,\n",
    "                          dropout = 0,\n",
    "                          bidirectional = False, \n",
    "                          batch_first=True)\n",
    "        \n",
    "#         self.attention_layer = DotProductAttention(0.)\n",
    "#         self.attention_layer = MLPAttention(config.hidden, config.hidden, config.hidden)\n",
    "        self.attention_layer = MLPAttentionPool(config.hidden, config.hidden)\n",
    "\n",
    "        self.dense_hidden = Dense(config.hidden, config.hidden)\n",
    "\n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "\n",
    "    def rnn_forward(self, x, x_lens):\n",
    "        X = torch.nn.utils.rnn.pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
    "        hidden, _= self.rnn(X)\n",
    "        hidden, _ = torch.nn.utils.rnn.pad_packed_sequence(hidden,total_length=x.shape[1],batch_first=True)\n",
    "        return hidden\n",
    "   \n",
    "    def forward(self, input_dict):\n",
    "        \n",
    "        userlog_action_id = input_dict['userlog'].to(args.device)\n",
    "        userlog_len = input_dict['userlog_len'].to(args.device)\n",
    "        userlog_day_qcut_id = input_dict['userlog_day_qcut'].to(args.device)\n",
    "        userlog_day_cut_id = input_dict['userlog_day_cut'].to(args.device)\n",
    "        userlog_second_qcut_id = input_dict['userlog_second_qcut'].to(args.device)\n",
    "        userlog_second_cut_id = input_dict['userlog_second_cut'].to(args.device)\n",
    "\n",
    "        \n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        \n",
    "        userlog_action = self.embeddings(userlog_action_id)\n",
    "#         app_behave = self.layer_norm(app_behave)\n",
    "        userlog_day_qcut = self.embeddings_day_qcut(userlog_day_qcut_id)\n",
    "        userlog_day_cut = self.embeddings_day_cut(userlog_day_cut_id)\n",
    "        userlog_second_qcut = self.embeddings_second_qcut(userlog_second_qcut_id)\n",
    "        userlog_second_cut = self.embeddings_second_cut(userlog_second_cut_id)\n",
    "        hidden = torch.cat([\n",
    "            userlog_action,\n",
    "            userlog_day_qcut,\n",
    "            userlog_day_cut,\n",
    "            userlog_second_qcut,\n",
    "            userlog_second_cut], dim = -1)\n",
    "        \n",
    "    \n",
    "        rnn_out = self.rnn_forward(hidden, userlog_len)\n",
    "        \n",
    "        x = self.attention_layer(rnn_out, userlog_len)\n",
    "#         mask = make_mask(x, app_behave_len)\n",
    "#         x = x.masked_fill_(~mask, 0).sum(1)\n",
    "\n",
    "        \n",
    "        hidden = self.dense_hidden(x)\n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "         \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "        \n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return loss, y1, y2, y3, y4, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def view_generate(model, master_ids):\n",
    "    \n",
    "    torch_dataset = AppDataset(master_ids)\n",
    "    data_loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      \n",
    "        batch_size=args.batch_size,      \n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers = args.n_worker,\n",
    "    )\n",
    "    \n",
    "    hidden_list = [] \n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(tqdm(data_loader)):\n",
    "            loss, y1, y2, y3, y4, hidden = model(data)\n",
    "            hidden_list.append(hidden.cpu().detach().numpy())\n",
    "            \n",
    "    return np.concatenate(hidden_list,  axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 17:30:58,458 - INFO - start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5370ef7d6c7748a3b89c38a323e951be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e807a3061c524e67b52eaa081a625634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=297), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 17:34:39,163 - INFO - finish\n"
     ]
    }
   ],
   "source": [
    "logging.info('start')\n",
    "\n",
    "user_train_id = all_train_id\n",
    "user_test_id = all_test_id\n",
    "user_net = torch.load('../code_new_model/user_net.model.torch').to(args.device)\n",
    "hidden_train = view_generate(user_net, user_train_id)\n",
    "hidden_test = view_generate(user_net, user_test_id)\n",
    "user_ret_dict = {\n",
    "    'train_id' : user_train_id,\n",
    "    'test_id' : user_test_id,\n",
    "    'hidden_train' : hidden_train,\n",
    "    'hidden_test' : hidden_test,\n",
    "}\n",
    "pickle.dump(user_ret_dict, open('5_data/user_attribute.pickle', 'wb'))\n",
    "logging.info('finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App behave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154835, 42589)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_behave_ids = list(df_install_behave.index)\n",
    "train_app_behave_ids = list( set(app_behave_ids) & set(all_train_id) )\n",
    "test_app_behave_ids = list( set(app_behave_ids) & set(all_test_id) )\n",
    "len(train_app_behave_ids), len(test_app_behave_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 17:34:39,678 - INFO - start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc54fc2f81864f0db5b619f1e6b9e740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=605), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d04d75ce6b4bdfa90216172fcea9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=167), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 17:46:01,582 - INFO - finish\n"
     ]
    }
   ],
   "source": [
    "logging.info('start')\n",
    "\n",
    "app_behave_net = torch.load('../code_new_model/app_behave_net.model.torch').to(args.device)\n",
    "hidden_train = view_generate(app_behave_net, train_app_behave_ids)\n",
    "hidden_test = view_generate(app_behave_net, test_app_behave_ids)\n",
    "app_behavior_dict = {\n",
    "    'train_id' : train_app_behave_ids,\n",
    "    'test_id' : test_app_behave_ids,\n",
    "    'hidden_train' : hidden_train,\n",
    "    'hidden_test' : hidden_test,\n",
    "}\n",
    "pickle.dump(app_behavior_dict, open('5_data/app_behaviors.pickle', 'wb'))\n",
    "logging.info('finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139440, 38950)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_list_ids = se_id_install_list.index\n",
    "train_app_list_ids = list( set(app_list_ids) & set(all_train_id) )\n",
    "test_app_list_ids = list( set(app_list_ids) & set(all_test_id) )\n",
    "len(train_app_list_ids), len(test_app_list_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 17:46:02,662 - INFO - start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b7a8cc2c14488194051d2bb738a624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=545), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68c619fb3cb436cb81f8df6533cd0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=153), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 17:48:40,013 - INFO - finish\n"
     ]
    }
   ],
   "source": [
    "logging.info('start')\n",
    "\n",
    "app_list_net = torch.load('../code_new_model/app_list_net.model.torch').to(args.device)\n",
    "hidden_train = view_generate(app_list_net, train_app_list_ids)\n",
    "hidden_test = view_generate(app_list_net, test_app_list_ids)\n",
    "app_list_dict = {\n",
    "    'train_id' : train_app_list_ids,\n",
    "    'test_id' : test_app_list_ids,\n",
    "    'hidden_train' : hidden_train,\n",
    "    'hidden_test' : hidden_test,\n",
    "}\n",
    "pickle.dump(app_list_dict, open('5_data/app_list.pickle', 'wb'))\n",
    "logging.info('finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App in-log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253808, 65313)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userlog_ids = se_userlog_cross.index\n",
    "train_userlog_ids = list( set(userlog_ids) & set(all_train_id) )\n",
    "test_userlog_ids = list( set(userlog_ids) & set(all_test_id) )\n",
    "len(train_userlog_ids), len(test_userlog_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 17:54:40,671 - INFO - start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d54175f5b049d89192006f5e571642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=992), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f22bdc4b67f4ea1a17843a16044fb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=256), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 18:07:30,049 - INFO - finish\n"
     ]
    }
   ],
   "source": [
    "logging.info('start')\n",
    "\n",
    "user_log_net = torch.load('../code_new_model/userlog_net.model.torch').to(args.device)\n",
    "hidden_train = view_generate(user_log_net, train_userlog_ids)\n",
    "hidden_test = view_generate(user_log_net, test_userlog_ids)\n",
    "user_log_dict = {\n",
    "    'train_id' : train_userlog_ids,\n",
    "    'test_id' : test_userlog_ids,\n",
    "    'hidden_train' : hidden_train,\n",
    "    'hidden_test' : hidden_test,\n",
    "}\n",
    "pickle.dump(user_log_dict, open('5_data/userlog.pickle', 'wb'))\n",
    "logging.info('finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = user_log_dict['hidden_train'], \\\n",
    "df_master_records['target_1m30+'].loc[user_log_dict['train_id']], \\\n",
    "user_log_dict['hidden_test'], \\\n",
    "df_master_records['target_1m30+'].loc[user_log_dict['test_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 18:36:30,569 - INFO - start\n",
      "2020-11-21 19:25:34,465 - INFO - finish\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model, svm, neural_network, ensemble\n",
    "logging.info('start')\n",
    "clf = ensemble.GradientBoostingClassifier(random_state=0)\n",
    "clf.fit(train_x, train_y)\n",
    "logging.info('finish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071459871397953"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test = clf.predict_proba(test_x)\n",
    "auc_test = roc_auc_score(test_y, predict_test[:, 1])\n",
    "auc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_attribute_dict = pickle.load(open('5_data/user_attribute.pickle', 'rb'))\n",
    "app_behavior_dict = pickle.load(open('5_data/app_behaviors.pickle', 'rb'))\n",
    "app_list_dict = pickle.load(open('5_data/app_list.pickle', 'rb'))\n",
    "user_log_dict = pickle.load(open('5_data/userlog.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_attribute_matrix = np.concatenate([user_attribute_dict['hidden_train'], user_attribute_dict['hidden_test']], axis = 0).astype('float32')\n",
    "master_ids = user_attribute_dict['train_id'] + user_attribute_dict['test_id']\n",
    "mp_master_id_idx = dict(zip(master_ids, range(len(master_ids))))\n",
    "app_behaviors_matrix = np.zeros(user_attribute_matrix.shape).astype('float32')\n",
    "app_list_matrix = np.zeros(user_attribute_matrix.shape).astype('float32')\n",
    "user_log_matrix = np.zeros(user_attribute_matrix.shape).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_matrix(matrix, ret_dict):\n",
    "    exsit_id = ret_dict['train_id'] + ret_dict['test_id']\n",
    "    exsit_idx = [mp_master_id_idx[master_id] for master_id in exsit_id]\n",
    "    matrix[exsit_idx] = np.concatenate([ret_dict['hidden_train'], ret_dict['hidden_test']], axis = 0)\n",
    "    return exsit_idx\n",
    "app_behaviors_exsit_idx = set_matrix(app_behaviors_matrix, app_behavior_dict)\n",
    "app_list_exsit_idx = set_matrix(app_list_matrix, app_list_dict)\n",
    "user_log_exsit_idx = set_matrix(user_log_matrix, user_log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_attribute_exsit_idx = list(range(user_attribute_matrix.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401978, 197424, 178390, 319121)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_attribute_exsit_idx), len(app_behaviors_exsit_idx), len(app_list_exsit_idx), len(user_log_exsit_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master_records = pickle.load(open('../data_sortout/df_master_records.pickle', 'rb'))\n",
    "new_client = (df_master_records['loan_sequence'] == 1).loc[user_attribute_dict['test_id']].values\n",
    "old_client = ~new_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = df_master_records.loc[user_attribute_dict['train_id'] + user_attribute_dict['test_id']]['target_1m30+'].values\n",
    "y2 = df_master_records.loc[user_attribute_dict['train_id'] + user_attribute_dict['test_id']]['target_2m30+'].values\n",
    "y3 = df_master_records.loc[user_attribute_dict['train_id'] + user_attribute_dict['test_id']]['target_3m30+'].values\n",
    "y4 = df_master_records.loc[user_attribute_dict['train_id'] + user_attribute_dict['test_id']]['target_4m30+'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " array([0., 1., 0., ..., 0., 0., 0.]),\n",
       " array([0., 1., 0., ..., 0., 0., 0.]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1, y2, y3, y4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-View Learning With Incomplete Views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_items, n_hidden, n_view, n_factors=20):\n",
    "        super().__init__()\n",
    "\n",
    "        self.u_list = nn.ModuleList([nn.Embedding(n_items, n_factors) for i in range(n_view) ])\n",
    "        self.w = nn.Embedding(n_hidden, n_factors)\n",
    "\n",
    "    def forward(self, i_s, j_s, view_idx):\n",
    "        feat_i = self.u_list[view_idx](i_s)\n",
    "        feat_j = self.w(j_s).transpose(1, 0)\n",
    "        result = torch.mm(feat_i, feat_j)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "# device=torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixFactorization(user_attribute_matrix.shape[0], user_attribute_matrix.shape[1], 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 18:27:08,477 - ERROR - Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "2020-11-23 18:27:08,480 - INFO - \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-6b5406380738>\", line 17, in <module>\n",
      "    ret = model(torch.tensor(exsit_idxs[view_idx]).to(device), j_s, view_idx)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "epoch = 1000\n",
    "exsit_idxs = [user_attribute_exsit_idx, app_behaviors_exsit_idx, app_list_exsit_idx, user_log_exsit_idx]\n",
    "matrixs = [\n",
    "    torch.tensor(user_attribute_matrix).to(device), \n",
    "    torch.tensor(app_behaviors_matrix).to(device),\n",
    "    torch.tensor(app_list_matrix).to(device),\n",
    "    torch.tensor(user_log_matrix).to(device)\n",
    "]\n",
    "\n",
    "j_s = torch.arange(user_attribute_matrix.shape[1]).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "for i in range(epoch):\n",
    "    loss = 0\n",
    "    for view_idx in range(4):\n",
    "        ret = model(torch.tensor(exsit_idxs[view_idx]).to(device), j_s, view_idx)\n",
    "        loss += torch.mean((ret - matrixs[view_idx][exsit_idxs[view_idx]]) ** 2)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 2)\n",
    "    optimizer.step()\n",
    "    if ((i + 1) % 2000 == 0):\n",
    "        logging.info('epoch:%d : loss: %f' % (i, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_idx_tensor = torch.tensor(exsit_idxs[0]).to(device)\n",
    "user_attribute_generation = model(all_idx_tensor, j_s, 0)\n",
    "app_behaviors_generation = model(all_idx_tensor, j_s, 1)\n",
    "app_list_exsit_generation = model(all_idx_tensor, j_s, 2)\n",
    "user_log_exsit_generation = model(all_idx_tensor, j_s, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([401978, 256]),\n",
       " torch.Size([401978, 256]),\n",
       " torch.Size([401978, 256]),\n",
       " torch.Size([401978, 256]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_attribute_generation.shape, app_behaviors_generation.shape, app_list_exsit_generation.shape, user_log_exsit_generation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c75a89b3dac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m generation_dict = {\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m'user_attribute'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0muser_attribute_generation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'app_behaviors'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mapp_behaviors_generation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'app_list'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mapp_list_exsit_generation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'user_log'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0muser_log_exsit_generation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "generation_dict = {\n",
    "    'user_attribute' : user_attribute_generation.cpu().detach().numpy(),\n",
    "    'app_behaviors' : app_behaviors_generation.cpu().detach().numpy(),\n",
    "    'app_list' : app_list_exsit_generation.cpu().detach().numpy(),\n",
    "    'user_log' : user_log_exsit_generation.cpu().detach().numpy(),\n",
    "    'y1' : y1,\n",
    "    'y2' : y2,\n",
    "    'y3' : y3,\n",
    "    'y4' : y4,\n",
    "}\n",
    "pickle.dump(generation_dict, open('5_data/Chang_Xu2015_generation_views.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_dict = pickle.load(open('5_data/Chang_Xu2015_generation_views.pickle', 'rb'))\n",
    "user_attribute_generation = generation_dict['user_attribute']\n",
    "app_behaviors_generation = generation_dict['app_behaviors']\n",
    "app_list_exsit_generation = generation_dict['app_list']\n",
    "user_log_exsit_generation = generation_dict['user_log']\n",
    "# y1 = generation_dict['y1']\n",
    "# y2 = generation_dict['y2']\n",
    "# y3 = generation_dict['y3']\n",
    "# y4 = generation_dict['y4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_attribute_generation[user_attribute_exsit_idx] = user_attribute_matrix[user_attribute_exsit_idx] \n",
    "app_behaviors_generation[app_behaviors_exsit_idx] = app_behaviors_matrix[app_behaviors_exsit_idx]\n",
    "app_list_exsit_generation[app_list_exsit_idx] = app_list_matrix[app_list_exsit_idx]\n",
    "user_log_exsit_generation[user_log_exsit_idx]  = user_log_matrix[user_log_exsit_idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401978, 1024)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_x = np.concatenate([\n",
    "    user_attribute_generation,\n",
    "    app_behaviors_generation,\n",
    "    app_list_exsit_generation,\n",
    "    user_log_exsit_generation,\n",
    "], axis=1)\n",
    "\n",
    "label1, label2, label3, label4 = y1.astype('float32'), y2.astype('float32'), y3.astype('float32'), y4.astype('float32')\n",
    "full_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0,
     4,
     24
    ]
   },
   "outputs": [],
   "source": [
    "class GeLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1. + torch.tanh(x * 0.7978845608 * (1. + 0.044715 * x * x)))\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super().__init__()\n",
    "        hidden = 64\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_feature, hidden),\n",
    "            GeLU(),\n",
    "            nn.Dropout(0),\n",
    "            nn.Linear(hidden, out_feature)\n",
    "        )\n",
    "        self.dense.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)\n",
    "    \n",
    "class OutputLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        n_dim = 1024\n",
    "        self.dense_hidden = Dense(n_dim, 64)\n",
    "\n",
    "        self.dense1 = Dense(64, 2)\n",
    "        self.dense2 = Dense(64, 2)\n",
    "        self.dense3 = Dense(64, 2)\n",
    "        self.dense4 = Dense(64, 2)\n",
    "        \n",
    "    def forward(self, x, labels1, labels2, labels3, labels4 ):\n",
    "                \n",
    "        hidden = self.dense_hidden(x)\n",
    "        \n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "        \n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return loss, y1, y2, y3, y4, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(user_attribute_dict['train_id'])\n",
    "# train_x, test_x = tensor_x[:num_train].clone(), tensor_x[num_train:].clone()\n",
    "# train_y1, test_y1 = label1[:num_train].clone(), label1[num_train:].clone()\n",
    "# train_y2, test_y2 = label2[:num_train].clone(), label2[num_train:].clone()\n",
    "# train_y3, test_y3 = label3[:num_train].clone(), label3[num_train:].clone()\n",
    "# train_y4, test_y4 = label4[:num_train].clone(), label4[num_train:].clone()\n",
    "\n",
    "# train_x, test_x = tensor_x[:num_train].clone().detach().requires_grad_(True), tensor_x[num_train:].clone().detach().requires_grad_(True)\n",
    "# train_y1, test_y1 = label1[:num_train].clone().detach().requires_grad_(True), label1[num_train:].clone().detach().requires_grad_(True)\n",
    "# train_y2, test_y2 = label2[:num_train].clone().detach().requires_grad_(True), label2[num_train:].clone().detach().requires_grad_(True)\n",
    "# train_y3, test_y3 = label3[:num_train].clone().detach().requires_grad_(True), label3[num_train:].clone().detach().requires_grad_(True)\n",
    "# train_y4, test_y4 = label4[:num_train].clone().detach().requires_grad_(True), label4[num_train:].clone().detach().requires_grad_(True)\n",
    "\n",
    "train_x, test_x = torch.tensor(full_x[:num_train]), torch.tensor(full_x[num_train:])\n",
    "train_y1, test_y1 = torch.tensor(label1[:num_train]), torch.tensor(label1[num_train:])\n",
    "train_y2, test_y2 = torch.tensor(label2[:num_train]), torch.tensor(label2[num_train:])\n",
    "train_y3, test_y3 = torch.tensor(label3[:num_train]), torch.tensor(label3[num_train:])\n",
    "train_y4, test_y4 = torch.tensor(label4[:num_train]), torch.tensor(label4[num_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_x, train_y1, train_y2, train_y3, train_y4)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers = 0)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(test_x, test_y1, test_y2, test_y3, test_y4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52f873c54654e0590e3d79365792260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.476344</td>\n",
       "      <td>0.691523</td>\n",
       "      <td>0.693486</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.648995</td>\n",
       "      <td>0.643411</td>\n",
       "      <td>0.654663</td>\n",
       "      <td>0.627502</td>\n",
       "      <td>0.617316</td>\n",
       "      <td>0.718873</td>\n",
       "      <td>0.711141</td>\n",
       "      <td>0.668519</td>\n",
       "      <td>0.647508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.476344  0.691523  0.693486  0.662651  0.648995   0.643411   0.654663   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.627502   0.617316   0.718873   0.711141   0.668519   0.647508  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40116e6f28ba44d4aa031fed142c8747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.468731</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>0.687031</td>\n",
       "      <td>0.657435</td>\n",
       "      <td>0.642869</td>\n",
       "      <td>0.642194</td>\n",
       "      <td>0.648042</td>\n",
       "      <td>0.621519</td>\n",
       "      <td>0.609791</td>\n",
       "      <td>0.716308</td>\n",
       "      <td>0.703322</td>\n",
       "      <td>0.663946</td>\n",
       "      <td>0.642179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.468731  0.688965  0.687031  0.657435  0.642869   0.642194   0.648042   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.621519   0.609791   0.716308   0.703322   0.663946   0.642179  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd4d83a8b5649978d2e2e456670a0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.538517</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.691344</td>\n",
       "      <td>0.663013</td>\n",
       "      <td>0.651047</td>\n",
       "      <td>0.64817</td>\n",
       "      <td>0.655009</td>\n",
       "      <td>0.62816</td>\n",
       "      <td>0.620104</td>\n",
       "      <td>0.718692</td>\n",
       "      <td>0.707776</td>\n",
       "      <td>0.669435</td>\n",
       "      <td>0.649303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.538517  0.693431  0.691344  0.663013  0.651047    0.64817   0.655009   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test    0.62816   0.620104   0.718692   0.707776   0.669435   0.649303  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c7bff908db47759d5ced1dab70aa58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.56519</td>\n",
       "      <td>0.681454</td>\n",
       "      <td>0.694251</td>\n",
       "      <td>0.658302</td>\n",
       "      <td>0.649595</td>\n",
       "      <td>0.637185</td>\n",
       "      <td>0.657078</td>\n",
       "      <td>0.622835</td>\n",
       "      <td>0.619084</td>\n",
       "      <td>0.711097</td>\n",
       "      <td>0.711189</td>\n",
       "      <td>0.665127</td>\n",
       "      <td>0.648822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.56519  0.681454  0.694251  0.658302  0.649595   0.637185   0.657078   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.622835   0.619084   0.711097   0.711189   0.665127   0.648822  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5ad00a6cd84af293d7c139fe14314c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.54805</td>\n",
       "      <td>0.686333</td>\n",
       "      <td>0.691869</td>\n",
       "      <td>0.660801</td>\n",
       "      <td>0.652412</td>\n",
       "      <td>0.641824</td>\n",
       "      <td>0.655121</td>\n",
       "      <td>0.625985</td>\n",
       "      <td>0.623007</td>\n",
       "      <td>0.717757</td>\n",
       "      <td>0.708073</td>\n",
       "      <td>0.668418</td>\n",
       "      <td>0.652469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.54805  0.686333  0.691869  0.660801  0.652412   0.641824   0.655121   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.625985   0.623007   0.717757   0.708073   0.668418   0.652469  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b2dca1e6d343409ef786556a9b076a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.530147</td>\n",
       "      <td>0.679595</td>\n",
       "      <td>0.691696</td>\n",
       "      <td>0.656854</td>\n",
       "      <td>0.650676</td>\n",
       "      <td>0.633373</td>\n",
       "      <td>0.652468</td>\n",
       "      <td>0.619353</td>\n",
       "      <td>0.619929</td>\n",
       "      <td>0.707294</td>\n",
       "      <td>0.708074</td>\n",
       "      <td>0.664056</td>\n",
       "      <td>0.651125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.530147  0.679595  0.691696  0.656854  0.650676   0.633373   0.652468   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.619353   0.619929   0.707294   0.708074   0.664056   0.651125  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595385e1f3a240a69c2d3f5bda0393b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.497238</td>\n",
       "      <td>0.68816</td>\n",
       "      <td>0.694713</td>\n",
       "      <td>0.660392</td>\n",
       "      <td>0.65246</td>\n",
       "      <td>0.642749</td>\n",
       "      <td>0.656942</td>\n",
       "      <td>0.625536</td>\n",
       "      <td>0.622463</td>\n",
       "      <td>0.718624</td>\n",
       "      <td>0.710813</td>\n",
       "      <td>0.666884</td>\n",
       "      <td>0.65318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss    1m30+     2m30+     3m30+    4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.497238  0.68816  0.694713  0.660392  0.65246   0.642749   0.656942   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.625536   0.622463   0.718624   0.710813   0.666884    0.65318  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a637a7a2234f4aa9f08a550bdd42a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.56382</td>\n",
       "      <td>0.679928</td>\n",
       "      <td>0.690544</td>\n",
       "      <td>0.659212</td>\n",
       "      <td>0.6511</td>\n",
       "      <td>0.632279</td>\n",
       "      <td>0.653163</td>\n",
       "      <td>0.624241</td>\n",
       "      <td>0.621016</td>\n",
       "      <td>0.708408</td>\n",
       "      <td>0.704937</td>\n",
       "      <td>0.665716</td>\n",
       "      <td>0.651383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss     1m30+     2m30+     3m30+   4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.56382  0.679928  0.690544  0.659212  0.6511   0.632279   0.653163   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.624241   0.621016   0.708408   0.704937   0.665716   0.651383  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6feaabaa7d4e30be14382356af7f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.534963</td>\n",
       "      <td>0.670258</td>\n",
       "      <td>0.68923</td>\n",
       "      <td>0.654278</td>\n",
       "      <td>0.645357</td>\n",
       "      <td>0.626039</td>\n",
       "      <td>0.651032</td>\n",
       "      <td>0.617363</td>\n",
       "      <td>0.614468</td>\n",
       "      <td>0.695274</td>\n",
       "      <td>0.705009</td>\n",
       "      <td>0.662485</td>\n",
       "      <td>0.646754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+    2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.534963  0.670258  0.68923  0.654278  0.645357   0.626039   0.651032   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.617363   0.614468   0.695274   0.705009   0.662485   0.646754  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f5534c53f24e91bd47af5885d673fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.581861</td>\n",
       "      <td>0.650516</td>\n",
       "      <td>0.694294</td>\n",
       "      <td>0.657914</td>\n",
       "      <td>0.649113</td>\n",
       "      <td>0.607691</td>\n",
       "      <td>0.655799</td>\n",
       "      <td>0.620993</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.65887</td>\n",
       "      <td>0.709937</td>\n",
       "      <td>0.664355</td>\n",
       "      <td>0.648846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.581861  0.650516  0.694294  0.657914  0.649113   0.607691   0.655799   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.620993   0.619048    0.65887   0.709937   0.664355   0.648846  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539a03d837654f44a0b01faf8110f6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.591755</td>\n",
       "      <td>0.659712</td>\n",
       "      <td>0.687627</td>\n",
       "      <td>0.64959</td>\n",
       "      <td>0.642883</td>\n",
       "      <td>0.611912</td>\n",
       "      <td>0.648062</td>\n",
       "      <td>0.612493</td>\n",
       "      <td>0.611739</td>\n",
       "      <td>0.677608</td>\n",
       "      <td>0.703081</td>\n",
       "      <td>0.657231</td>\n",
       "      <td>0.642869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+    3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.591755  0.659712  0.687627  0.64959  0.642883   0.611912   0.648062   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.612493   0.611739   0.677608   0.703081   0.657231   0.642869  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a9cdf3e5d04f3dbb8194a82305a993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.60724</td>\n",
       "      <td>0.648357</td>\n",
       "      <td>0.68957</td>\n",
       "      <td>0.654884</td>\n",
       "      <td>0.647898</td>\n",
       "      <td>0.607184</td>\n",
       "      <td>0.651008</td>\n",
       "      <td>0.618495</td>\n",
       "      <td>0.617952</td>\n",
       "      <td>0.669206</td>\n",
       "      <td>0.704931</td>\n",
       "      <td>0.661014</td>\n",
       "      <td>0.647545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss     1m30+    2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.60724  0.648357  0.68957  0.654884  0.647898   0.607184   0.651008   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.618495   0.617952   0.669206   0.704931   0.661014   0.647545  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def eval_data(model):\n",
    "    global new_client, old_client\n",
    "\n",
    "    loss_list = []\n",
    "    y1_list, y2_list, y3_list, y4_list = [], [], [], []\n",
    "    label1_list, label2_list, label3_list, label4_list = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x, l1, l2, l3, l4 in test_loader:\n",
    "            loss, y1, y2, y3, y4, _ = model(x.to(device), l1.to(device), l2.to(device), l3.to(device), l4.to(device))\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "            y1_list.append(y1.cpu().detach().numpy())\n",
    "            y2_list.append(y2.cpu().detach().numpy())\n",
    "            y3_list.append(y3.cpu().detach().numpy())\n",
    "            y4_list.append(y4.cpu().detach().numpy())\n",
    "\n",
    "            label1_list.append(l1.long().cpu().detach().numpy())\n",
    "            label2_list.append(l2.long().cpu().detach().numpy())\n",
    "            label3_list.append(l3.long().cpu().detach().numpy())\n",
    "            label4_list.append(l4.long().cpu().detach().numpy())\n",
    "\n",
    "        loss = np.mean(loss_list)\n",
    "    \n",
    "    y1_np = np.concatenate(y1_list,  axis = 0)\n",
    "    y2_np = np.concatenate(y2_list,  axis = 0)\n",
    "    y3_np = np.concatenate(y3_list,  axis = 0)\n",
    "    y4_np = np.concatenate(y4_list,  axis = 0)\n",
    "\n",
    "    labels1_np = np.concatenate(label1_list,  axis = 0)\n",
    "    labels2_np = np.concatenate(label2_list,  axis = 0)\n",
    "    labels3_np = np.concatenate(label3_list,  axis = 0)\n",
    "    labels4_np = np.concatenate(label4_list,  axis = 0)\n",
    "\n",
    "    auc1 = roc_auc_score(labels1_np, y1_np[:, 1])\n",
    "    auc2 = roc_auc_score(labels2_np, y2_np[:, 1])\n",
    "    auc3 = roc_auc_score(labels3_np, y3_np[:, 1])\n",
    "    auc4 = roc_auc_score(labels4_np, y4_np[:, 1])\n",
    "    auc_all = [auc1, auc2, auc3, auc4]\n",
    "    \n",
    "    new_client_auc1 = roc_auc_score(labels1_np[new_client], y1_np[:, 1][new_client])\n",
    "    new_client_auc2 = roc_auc_score(labels2_np[new_client], y2_np[:, 1][new_client])\n",
    "    new_client_auc3 = roc_auc_score(labels3_np[new_client], y3_np[:, 1][new_client])\n",
    "    new_client_auc4 = roc_auc_score(labels4_np[new_client], y4_np[:, 1][new_client])\n",
    "    auc_new_client = [new_client_auc1, new_client_auc2, new_client_auc3, new_client_auc4]\n",
    "\n",
    "    old_client_auc1 = roc_auc_score(labels1_np[old_client], y1_np[:, 1][old_client])\n",
    "    old_client_auc2 = roc_auc_score(labels2_np[old_client], y2_np[:, 1][old_client])\n",
    "    old_client_auc3 = roc_auc_score(labels3_np[old_client], y3_np[:, 1][old_client])\n",
    "    old_client_auc4 = roc_auc_score(labels4_np[old_client], y4_np[:, 1][old_client])\n",
    "    auc_old_client = [old_client_auc1, old_client_auc2, old_client_auc3, old_client_auc4]\n",
    "\n",
    "    return {\n",
    "        'loss' : loss,\n",
    "        '1m30+' : auc1,\n",
    "        '2m30+' : auc2,\n",
    "        '3m30+' : auc3,\n",
    "        '4m30+' : auc4,\n",
    "        'new_1m30+' : new_client_auc1,\n",
    "        'new_2m30+' : new_client_auc2,\n",
    "        'new_3m30+' : new_client_auc3,\n",
    "        'new_4m30+' : new_client_auc4,\n",
    "        'old_1m30+' : old_client_auc1,\n",
    "        'old_2m30+' : old_client_auc2,\n",
    "        'old_3m30+' : old_client_auc3,\n",
    "        'old_4m30+' : old_client_auc4,\n",
    "    }\n",
    "    \n",
    "epoch = 12\n",
    "output_model = OutputLayer().to(device)\n",
    "optimizer = AdamW(output_model.parameters(), lr = 0.001, weight_decay = 0)\n",
    "\n",
    "for i in range(epoch):\n",
    "    output_model.train()\n",
    "\n",
    "    for x, l1, l2, l3, l4 in tqdm(train_loader):\n",
    "        loss, y1, y2, y3, y4, _ = output_model(x.to(device), l1.to(device), l2.to(device), l3.to(device), l4.to(device))\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "#         loss.backward(retain_graph=True)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(output_model.parameters(), max_norm = 2)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "    output_model.eval()\n",
    "    \n",
    "#     train_ret_dict = eval_data(output_model)\n",
    "    test_ret_dict = eval_data(output_model)\n",
    "    df_ret = pd.DataFrame([\n",
    "        test_ret_dict\n",
    "    ], index = ['test'])\n",
    "    ipd.display(df_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPM-Nets: Cross Partial Multi-View Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "class GeLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1. + torch.tanh(x * 0.7978845608 * (1. + 0.044715 * x * x)))\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super().__init__()\n",
    "        hidden = 64\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_feature, hidden),\n",
    "            GeLU(),\n",
    "            nn.Dropout(0),\n",
    "            nn.Linear(hidden, out_feature)\n",
    "        )\n",
    "        self.dense.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)\n",
    "\n",
    "class CPM(torch.nn.Module):\n",
    "    def __init__(self, n_train, n_test, n_hidden, n_view):\n",
    "        super().__init__()\n",
    "\n",
    "        n_factors = 64\n",
    "        self.n_view = n_view\n",
    "        self.h_train = nn.Embedding(n_train, n_factors)\n",
    "        self.h_test = nn.Embedding(n_test, n_factors)\n",
    "        self.pro_list = nn.ModuleList([Dense(n_factors, n_hidden) for i in range(n_view)])\n",
    "        \n",
    "        self.dense1 = Dense(n_factors, 2)\n",
    "        self.dense2 = Dense(n_factors, 2)\n",
    "        self.dense3 = Dense(n_factors, 2)\n",
    "        self.dense4 = Dense(n_factors, 2)\n",
    "    \n",
    "    def train_forward(self, **param):\n",
    "\n",
    "        train_hidden = self.h_train(param['train_idx'])\n",
    "        test_hidden = self.h_test(param['test_idx'])\n",
    "        reconstruction_loss = 0\n",
    "        for i in range(self.n_view):\n",
    "            rebuild_train = self.pro_list[i](train_hidden)\n",
    "            rebuild_test = self.pro_list[i](test_hidden)\n",
    "            train_exist_idx_v_i = param['train_exist_idx_%d'%i]\n",
    "            test_exist_idx_v_i = param['test_exist_idx_%d'%i]\n",
    "\n",
    "            loss_rebuild_train = (rebuild_train[train_exist_idx_v_i] - param['view_train_%d' % i][train_exist_idx_v_i]) ** 2\n",
    "            loss_rebuild_test = (rebuild_train[test_exist_idx_v_i] - param['view_test_%d' % i][test_exist_idx_v_i]) ** 2\n",
    "            reconstruction_loss += torch.mean(loss_rebuild_train) + torch.mean(loss_rebuild_test)\n",
    "            \n",
    "        y1 = self.dense1(train_hidden)\n",
    "        y2 = self.dense2(train_hidden)\n",
    "        y3 = self.dense3(train_hidden)\n",
    "        y4 = self.dense4(train_hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, param['labels1'].long())\n",
    "        loss2 = loss_func(y2, param['labels2'].long())\n",
    "        loss3 = loss_func(y3, param['labels3'].long())\n",
    "        loss4 = loss_func(y4, param['labels4'].long())\n",
    "        \n",
    "        classification_loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return reconstruction_loss, classification_loss, reconstruction_loss + classification_loss \n",
    "\n",
    "    def test_forward(self, **param):\n",
    "        test_hidden = self.h_test(param['test_idx'])\n",
    "        \n",
    "        y1 = self.dense1(test_hidden)\n",
    "        y2 = self.dense2(test_hidden)\n",
    "        y3 = self.dense3(test_hidden)\n",
    "        y4 = self.dense4(test_hidden)\n",
    "        \n",
    "        return y1, y2, y3, y4\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(user_attribute_dict['train_id'])\n",
    "num_test = len(user_attribute_dict['test_id'])\n",
    "v0_exist_set = set(user_attribute_exsit_idx)\n",
    "v1_exist_set = set(app_behaviors_exsit_idx)\n",
    "v2_exist_set = set(app_list_exsit_idx)\n",
    "v3_exist_set = set(user_log_exsit_idx)\n",
    "\n",
    "v0_train_m, v0_test_m = user_attribute_matrix[:num_train], user_attribute_matrix[num_train:]\n",
    "v1_train_m, v1_test_m = app_behaviors_matrix[:num_train], app_behaviors_matrix[num_train:]\n",
    "v2_train_m, v2_test_m = app_list_matrix[:num_train], app_list_matrix[num_train:]\n",
    "v3_train_m, v3_test_m = user_log_matrix[:num_train], user_log_matrix[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_view_train_0 = torch.tensor(v0_train_m).to(device),\n",
    "# tensor_view_train_1 = torch.tensor(v1_train_m).to(device),\n",
    "# tensor_view_train_2 = torch.tensor(v2_train_m).to(device),\n",
    "# tensor_view_train_3 = torch.tensor(v3_train_m).to(device),\n",
    "\n",
    "# tensor_view_test_0 = torch.tensor(v0_test_m).to(device),\n",
    "# tensor_view_test_1 = torch.tensor(v1_test_m).to(device),\n",
    "# tensor_view_test_2 = torch.tensor(v2_test_m).to(device),\n",
    "# tensor_view_test_3 = torch.tensor(v3_test_m).to(device),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CPM(num_train, num_test, 256, 4).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 18:36:43,154 - INFO - start\n",
      "2020-11-23 18:37:31,970 - INFO - epoch: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.502058</td>\n",
       "      <td>0.492916</td>\n",
       "      <td>0.502679</td>\n",
       "      <td>0.498056</td>\n",
       "      <td>0.500511</td>\n",
       "      <td>0.487835</td>\n",
       "      <td>0.504407</td>\n",
       "      <td>0.498584</td>\n",
       "      <td>0.516572</td>\n",
       "      <td>0.502705</td>\n",
       "      <td>0.501803</td>\n",
       "      <td>0.496965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  new_3m30+  \\\n",
       "test  0.502058  0.492916  0.502679  0.498056   0.500511   0.487835   0.504407   \n",
       "\n",
       "      new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.498584   0.516572   0.502705   0.501803   0.496965  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 19:03:01,072 - INFO - epoch: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.503241</td>\n",
       "      <td>0.493192</td>\n",
       "      <td>0.501987</td>\n",
       "      <td>0.499009</td>\n",
       "      <td>0.503259</td>\n",
       "      <td>0.489124</td>\n",
       "      <td>0.502838</td>\n",
       "      <td>0.498433</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.501631</td>\n",
       "      <td>0.502643</td>\n",
       "      <td>0.499262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  new_3m30+  \\\n",
       "test  0.503241  0.493192  0.501987  0.499009   0.503259   0.489124   0.502838   \n",
       "\n",
       "      new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.498433       0.51   0.501631   0.502643   0.499262  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 19:28:47,752 - INFO - epoch: 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.500381</td>\n",
       "      <td>0.493798</td>\n",
       "      <td>0.501184</td>\n",
       "      <td>0.499196</td>\n",
       "      <td>0.498724</td>\n",
       "      <td>0.48916</td>\n",
       "      <td>0.499341</td>\n",
       "      <td>0.497088</td>\n",
       "      <td>0.51223</td>\n",
       "      <td>0.504048</td>\n",
       "      <td>0.504392</td>\n",
       "      <td>0.501158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  new_3m30+  \\\n",
       "test  0.500381  0.493798  0.501184  0.499196   0.498724    0.48916   0.499341   \n",
       "\n",
       "      new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.497088    0.51223   0.504048   0.504392   0.501158  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 19:52:59,212 - INFO - epoch: 96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.498181</td>\n",
       "      <td>0.496107</td>\n",
       "      <td>0.500747</td>\n",
       "      <td>0.498528</td>\n",
       "      <td>0.497585</td>\n",
       "      <td>0.491072</td>\n",
       "      <td>0.498068</td>\n",
       "      <td>0.496577</td>\n",
       "      <td>0.507452</td>\n",
       "      <td>0.507723</td>\n",
       "      <td>0.504806</td>\n",
       "      <td>0.500552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  new_3m30+  \\\n",
       "test  0.498181  0.496107  0.500747  0.498528   0.497585   0.491072   0.498068   \n",
       "\n",
       "      new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.496577   0.507452   0.507723   0.504806   0.500552  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 20:15:51,287 - INFO - epoch: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.498171</td>\n",
       "      <td>0.497586</td>\n",
       "      <td>0.499423</td>\n",
       "      <td>0.497676</td>\n",
       "      <td>0.498249</td>\n",
       "      <td>0.493514</td>\n",
       "      <td>0.498349</td>\n",
       "      <td>0.496379</td>\n",
       "      <td>0.50489</td>\n",
       "      <td>0.507852</td>\n",
       "      <td>0.500415</td>\n",
       "      <td>0.500023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  new_3m30+  \\\n",
       "test  0.498171  0.497586  0.499423  0.497676   0.498249   0.493514   0.498349   \n",
       "\n",
       "      new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.496379    0.50489   0.507852   0.500415   0.500023  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 20:40:52,340 - INFO - epoch: 160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.496918</td>\n",
       "      <td>0.499254</td>\n",
       "      <td>0.499318</td>\n",
       "      <td>0.497359</td>\n",
       "      <td>0.497834</td>\n",
       "      <td>0.49633</td>\n",
       "      <td>0.496394</td>\n",
       "      <td>0.497243</td>\n",
       "      <td>0.501786</td>\n",
       "      <td>0.507382</td>\n",
       "      <td>0.502255</td>\n",
       "      <td>0.49862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  new_3m30+  \\\n",
       "test  0.496918  0.499254  0.499318  0.497359   0.497834    0.49633   0.496394   \n",
       "\n",
       "      new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.497243   0.501786   0.507382   0.502255    0.49862  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 21:06:21,064 - INFO - epoch: 192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.495584</td>\n",
       "      <td>0.499907</td>\n",
       "      <td>0.49874</td>\n",
       "      <td>0.496838</td>\n",
       "      <td>0.498259</td>\n",
       "      <td>0.496635</td>\n",
       "      <td>0.494042</td>\n",
       "      <td>0.496408</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.507942</td>\n",
       "      <td>0.503473</td>\n",
       "      <td>0.498538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1m30+     2m30+    3m30+     4m30+  new_1m30+  new_2m30+  new_3m30+  \\\n",
       "test  0.495584  0.499907  0.49874  0.496838   0.498259   0.496635   0.494042   \n",
       "\n",
       "      new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.496408   0.493777   0.507942   0.503473   0.498538  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 21:31:27,519 - INFO - epoch: 224\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.495836</td>\n",
       "      <td>0.500083</td>\n",
       "      <td>0.499203</td>\n",
       "      <td>0.495914</td>\n",
       "      <td>0.498477</td>\n",
       "      <td>0.496664</td>\n",
       "      <td>0.494481</td>\n",
       "      <td>0.496023</td>\n",
       "      <td>0.494147</td>\n",
       "      <td>0.508318</td>\n",
       "      <td>0.50406</td>\n",
       "      <td>0.497223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  new_3m30+  \\\n",
       "test  0.495836  0.500083  0.499203  0.495914   0.498477   0.496664   0.494481   \n",
       "\n",
       "      new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.496023   0.494147   0.508318    0.50406   0.497223  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging.info('start')\n",
    "\n",
    "def train():\n",
    "    batch_size = 256\n",
    "    epoch = 1024\n",
    "\n",
    "    for epoch in range(epoch):\n",
    "        model.train()\n",
    "        idxs = list(range(user_attribute_matrix.shape[0]))\n",
    "        random.shuffle(idxs)\n",
    "\n",
    "#         for i in tqdm(range(0, user_attribute_matrix.shape[0], batch_size)):\n",
    "        for i in (range(0, user_attribute_matrix.shape[0], batch_size)):\n",
    "            select_idx = idxs[i:i+batch_size]\n",
    "            train_idx = [idx for idx in select_idx if idx < num_train]\n",
    "            test_idx = [idx - num_train for idx in select_idx if idx >= num_train]\n",
    "\n",
    "            loss1, loss2, loss = model.train_forward(\n",
    "                train_exist_idx_0 = torch.tensor([i for i, idx in enumerate(train_idx) if idx in v0_exist_set]).long().to(device),\n",
    "                train_exist_idx_1 = torch.tensor([i for i, idx in enumerate(train_idx) if idx in v1_exist_set]).long().to(device),\n",
    "                train_exist_idx_2 = torch.tensor([i for i, idx in enumerate(train_idx) if idx in v2_exist_set]).long().to(device),\n",
    "                train_exist_idx_3 = torch.tensor([i for i, idx in enumerate(train_idx) if idx in v3_exist_set]).long().to(device),\n",
    "\n",
    "                test_exist_idx_0 = torch.tensor([i for i, idx in enumerate(test_idx) if idx in v0_exist_set]).long().to(device),\n",
    "                test_exist_idx_1 = torch.tensor([i for i, idx in enumerate(test_idx) if idx in v1_exist_set]).long().to(device),\n",
    "                test_exist_idx_2 = torch.tensor([i for i, idx in enumerate(test_idx) if idx in v2_exist_set]).long().to(device),\n",
    "                test_exist_idx_3 = torch.tensor([i for i, idx in enumerate(test_idx) if idx in v3_exist_set]).long().to(device),\n",
    "\n",
    "                view_train_0 = torch.tensor(v0_train_m[train_idx].astype('float32')).to(device),\n",
    "                view_train_1 = torch.tensor(v1_train_m[train_idx].astype('float32')).to(device),\n",
    "                view_train_2 = torch.tensor(v2_train_m[train_idx].astype('float32')).to(device),\n",
    "                view_train_3 = torch.tensor(v3_train_m[train_idx].astype('float32')).to(device),\n",
    "\n",
    "                view_test_0 = torch.tensor(v0_test_m[test_idx].astype('float32')).to(device),\n",
    "                view_test_1 = torch.tensor(v1_test_m[test_idx].astype('float32')).to(device),\n",
    "                view_test_2 = torch.tensor(v2_test_m[test_idx].astype('float32')).to(device),\n",
    "                view_test_3 = torch.tensor(v3_test_m[test_idx].astype('float32')).to(device),\n",
    "\n",
    "                train_idx = torch.tensor(train_idx).long().to(device),\n",
    "                test_idx = torch.tensor(test_idx).long().to(device),\n",
    "                labels1 = torch.tensor(y1[train_idx]).long().to(device),\n",
    "                labels2 = torch.tensor(y2[train_idx]).long().to(device),\n",
    "                labels3 = torch.tensor(y3[train_idx]).long().to(device),\n",
    "                labels4 = torch.tensor(y4[train_idx]).long().to(device)\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 2)\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "\n",
    "        y1_list, y2_list, y3_list, y4_list = [], [], [], []\n",
    "        with torch.no_grad():\n",
    "            idxs = list(range(num_test))\n",
    "            for i in range(0, num_test, batch_size):\n",
    "                select_idx = idxs[i:i+batch_size]\n",
    "                y1_tensor, y2_tensor, y3_tensor, y4_tensor= model.test_forward(test_idx = torch.tensor(select_idx).long().to(device))\n",
    "                y1_list.append(y1_tensor.cpu().detach().numpy())\n",
    "                y2_list.append(y2_tensor.cpu().detach().numpy())\n",
    "                y3_list.append(y3_tensor.cpu().detach().numpy())\n",
    "                y4_list.append(y4_tensor.cpu().detach().numpy())\n",
    "\n",
    "        y1_np = np.concatenate(y1_list,  axis = 0)\n",
    "        y2_np = np.concatenate(y2_list,  axis = 0)\n",
    "        y3_np = np.concatenate(y3_list,  axis = 0)\n",
    "        y4_np = np.concatenate(y4_list,  axis = 0)\n",
    "        \n",
    "        labels1_np = y1[-num_test:]\n",
    "        labels2_np = y2[-num_test:]\n",
    "        labels3_np = y3[-num_test:]\n",
    "        labels4_np = y4[-num_test:]\n",
    "\n",
    "        auc1 = roc_auc_score(labels1_np, y1_np[:, 1])\n",
    "        auc2 = roc_auc_score(labels2_np, y2_np[:, 1])\n",
    "        auc3 = roc_auc_score(labels3_np, y3_np[:, 1])\n",
    "        auc4 = roc_auc_score(labels4_np, y4_np[:, 1])\n",
    "        auc_all = [auc1, auc2, auc3, auc4]\n",
    "\n",
    "        new_client_auc1 = roc_auc_score(labels1_np[new_client], y1_np[:, 1][new_client])\n",
    "        new_client_auc2 = roc_auc_score(labels2_np[new_client], y2_np[:, 1][new_client])\n",
    "        new_client_auc3 = roc_auc_score(labels3_np[new_client], y3_np[:, 1][new_client])\n",
    "        new_client_auc4 = roc_auc_score(labels4_np[new_client], y4_np[:, 1][new_client])\n",
    "        auc_new_client = [new_client_auc1, new_client_auc2, new_client_auc3, new_client_auc4]\n",
    "\n",
    "        old_client_auc1 = roc_auc_score(labels1_np[old_client], y1_np[:, 1][old_client])\n",
    "        old_client_auc2 = roc_auc_score(labels2_np[old_client], y2_np[:, 1][old_client])\n",
    "        old_client_auc3 = roc_auc_score(labels3_np[old_client], y3_np[:, 1][old_client])\n",
    "        old_client_auc4 = roc_auc_score(labels4_np[old_client], y4_np[:, 1][old_client])\n",
    "        auc_old_client = [old_client_auc1, old_client_auc2, old_client_auc3, old_client_auc4]\n",
    "\n",
    "        df_ret = pd.DataFrame([{\n",
    "            '1m30+' : auc1,\n",
    "            '2m30+' : auc2,\n",
    "            '3m30+' : auc3,\n",
    "            '4m30+' : auc4,\n",
    "            'new_1m30+' : new_client_auc1,\n",
    "            'new_2m30+' : new_client_auc2,\n",
    "            'new_3m30+' : new_client_auc3,\n",
    "            'new_4m30+' : new_client_auc4,\n",
    "            'old_1m30+' : old_client_auc1,\n",
    "            'old_2m30+' : old_client_auc2,\n",
    "            'old_3m30+' : old_client_auc3,\n",
    "            'old_4m30+' : old_client_auc4,\n",
    "        }], index = ['test'])\n",
    "        \n",
    "        if epoch % 32 == 0:\n",
    "            logging.info('epoch: %d' % epoch)\n",
    "            ipd.display(df_ret)\n",
    "train()\n",
    "logging.info('end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(select_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((401978, 256), (401978, 256), (401978, 256), (401978, 256))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_attribute_matrix.shape, app_behaviors_matrix.shape, app_list_matrix.shape, user_log_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size = 256, output_size = 256, n_view = 4):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map_list = nn.ModuleList([nn.Linear(input_size, output_size) for _ in range(n_view)])\n",
    "        self.map = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, v1, v2, v3, v4):\n",
    "#         v1_generation = self.map_list[0](v1)\n",
    "#         v2_generation = self.map_list[1](v2)\n",
    "#         v3_generation = self.map_list[2](v3)\n",
    "#         v4_generation = self.map_list[3](v4)\n",
    "        v1_generation = self.map(v1)\n",
    "        v2_generation = self.map(v2)\n",
    "        v3_generation = self.map(v3)\n",
    "        v4_generation = self.map(v4)\n",
    "\n",
    "        return torch.cat([v1_generation, v2_generation, v3_generation, v4_generation])\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size = 256):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, 1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_real_data(batch_size):\n",
    "    global user_attribute_matrix, app_behaviors_matrix, app_list_matrix, user_log_matrix,\\\n",
    "    user_attribute_exsit_idx, app_behaviors_exsit_idx, app_list_exsit_idx, user_log_exsit_idx\n",
    "    assert batch_size % 4 == 0\n",
    "    idx1 = random.sample(user_attribute_exsit_idx, batch_size // 4)\n",
    "    idx2 = random.sample(app_behaviors_exsit_idx, batch_size // 4)\n",
    "    idx3 = random.sample(app_list_exsit_idx, batch_size // 4)\n",
    "    idx4 = random.sample(user_log_exsit_idx, batch_size // 4)\n",
    "    v1 = torch.tensor(user_attribute_matrix[idx1]).to(device)\n",
    "    v2 = torch.tensor(app_behaviors_matrix[idx2]).to(device)\n",
    "    v3 = torch.tensor(app_list_matrix[idx3]).to(device)\n",
    "    v4 = torch.tensor(user_log_matrix[idx4]).to(device)\n",
    "\n",
    "    return torch.cat([v1, v2, v3, v4])\n",
    "\n",
    "def sample_generate_data(G_net, batch_size):\n",
    "    global user_attribute_matrix, app_behaviors_matrix, app_list_matrix, user_log_matrix\n",
    "    assert batch_size % 4 == 0\n",
    "    \n",
    "    idx = random.sample(range(user_attribute_matrix.shape[0]), batch_size // 4)\n",
    "    v1 = torch.tensor(user_attribute_matrix[idx]).to(device)\n",
    "    v2 = torch.tensor(app_behaviors_matrix[idx]).to(device)\n",
    "    v3 = torch.tensor(app_list_matrix[idx]).to(device)\n",
    "    v4 = torch.tensor(user_log_matrix[idx]).to(device)\n",
    "    \n",
    "    v_stack = G_net(v1, v2, v3, v4)\n",
    "    return v_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-30 14:53:24,230 - INFO - epoch:0 D loss:0.676382 G loss:0.716103\n",
      "2020-11-30 14:53:24,921 - INFO - epoch:108 D loss:1.153681 G loss:0.449096\n",
      "2020-11-30 14:53:25,595 - INFO - epoch:216 D loss:0.744273 G loss:0.649895\n",
      "2020-11-30 14:53:26,261 - INFO - epoch:324 D loss:0.642466 G loss:0.760303\n",
      "2020-11-30 14:53:26,846 - INFO - epoch:432 D loss:0.692199 G loss:0.704992\n",
      "2020-11-30 14:53:27,485 - INFO - epoch:540 D loss:0.699379 G loss:0.691551\n",
      "2020-11-30 14:53:28,139 - INFO - epoch:648 D loss:0.674989 G loss:0.716080\n",
      "2020-11-30 14:53:28,801 - INFO - epoch:756 D loss:0.667237 G loss:0.723604\n",
      "2020-11-30 14:53:29,488 - INFO - epoch:864 D loss:0.731232 G loss:0.669571\n",
      "2020-11-30 14:53:30,039 - INFO - epoch:972 D loss:0.715942 G loss:0.677786\n"
     ]
    }
   ],
   "source": [
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "d_learning_rate = 2e-4  \n",
    "g_learning_rate = 2e-4  \n",
    "optim_betas = (0.9, 0.999)\n",
    "num_epochs = 1024\n",
    "d_steps = 1\n",
    "g_steps = 1\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)\n",
    "batch_size = 256\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for d_index in range(d_steps):\n",
    "        # 1. Train D on real+fake\n",
    "        D.zero_grad()\n",
    "\n",
    "        #  1A: Train D on real\n",
    "        d_real_data = sample_real_data(batch_size)\n",
    "        d_real_decision = D(d_real_data)\n",
    "        d_real_error = criterion(d_real_decision, torch.ones((batch_size, 1)).to(device))  # ones = true\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        #  1B: Train D on fake\n",
    "        d_gen_input = sample_generate_data(G, batch_size)\n",
    "        d_fake_data = d_gen_input.detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = D(d_fake_data)\n",
    "        d_fake_error = criterion(d_fake_decision, torch.zeros((batch_size, 1)).to(device)) # zeros = fake\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "    for g_index in range(g_steps):\n",
    "        # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "        G.zero_grad()\n",
    "\n",
    "        gen_input = sample_generate_data(G, batch_size)\n",
    "        g_fake_data = gen_input\n",
    "        dg_fake_decision = D(g_fake_data)\n",
    "        g_error = criterion(dg_fake_decision, torch.ones((batch_size, 1)).to(device)) # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "    if epoch % 108 == 0:\n",
    "        logging.info('epoch:%d D loss:%f G loss:%f' % (epoch, d_fake_error.item(), g_error.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 256\n",
    "v1_list, v2_list, v3_list, v4_list = [], [], [], []\n",
    "for i in range(0, user_attribute_matrix.shape[0], batch):\n",
    "    v1 = torch.tensor(user_attribute_matrix[i : i + batch]).to(device)\n",
    "    v2 = torch.tensor(app_behaviors_matrix[i : i + batch]).to(device)\n",
    "    v3 = torch.tensor(app_list_matrix[i : i + batch]).to(device)\n",
    "    v4 = torch.tensor(user_log_matrix[i : i + batch]).to(device)\n",
    "    \n",
    "    v_generation = G(v1, v2, v3, v4)\n",
    "    n = v_generation.shape[0] // 4\n",
    "    v1_list.append(v_generation[:n].cpu().detach().numpy())\n",
    "    v2_list.append(v_generation[n:n*2].cpu().detach().numpy())\n",
    "    v3_list.append(v_generation[n*2:n*3].cpu().detach().numpy())\n",
    "    v4_list.append(v_generation[n*3:].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_attribute_generation = np.concatenate(v1_list)\n",
    "app_behaviors_generation = np.concatenate(v2_list)\n",
    "app_list_exsit_generation = np.concatenate(v3_list)\n",
    "user_log_exsit_generation = np.concatenate(v4_list)\n",
    "user_attribute_generation[user_attribute_exsit_idx] = user_attribute_matrix[user_attribute_exsit_idx] \n",
    "app_behaviors_generation[app_behaviors_exsit_idx] = app_behaviors_matrix[app_behaviors_exsit_idx]\n",
    "app_list_exsit_generation[app_list_exsit_idx] = app_list_matrix[app_list_exsit_idx]\n",
    "user_log_exsit_generation[user_log_exsit_idx]  = user_log_matrix[user_log_exsit_idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_dict = {\n",
    "    'user_attribute' : user_attribute_generation,\n",
    "    'app_behaviors' : app_behaviors_generation,\n",
    "    'app_list' : app_list_exsit_generation,\n",
    "    'user_log' : user_log_exsit_generation,\n",
    "    'y1' : y1,\n",
    "    'y2' : y2,\n",
    "    'y3' : y3,\n",
    "    'y4' : y4,\n",
    "}\n",
    "pickle.dump(generation_dict, open('5_data/GAN_generation_views.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classificaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_dict = pickle.load(open('5_data/GAN_generation_views.pickle', 'rb'))\n",
    "user_attribute_generation = generation_dict['user_attribute']\n",
    "app_behaviors_generation = generation_dict['app_behaviors']\n",
    "app_list_exsit_generation = generation_dict['app_list']\n",
    "user_log_exsit_generation = generation_dict['user_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401978, 1024)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_x = np.concatenate([\n",
    "    user_attribute_generation,\n",
    "    app_behaviors_generation,\n",
    "    app_list_exsit_generation,\n",
    "    user_log_exsit_generation,\n",
    "], axis=1)\n",
    "\n",
    "label1, label2, label3, label4 = y1.astype('float32'), y2.astype('float32'), y3.astype('float32'), y4.astype('float32')\n",
    "full_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "code_folding": [
     0,
     4,
     24
    ]
   },
   "outputs": [],
   "source": [
    "class GeLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1. + torch.tanh(x * 0.7978845608 * (1. + 0.044715 * x * x)))\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super().__init__()\n",
    "        hidden = 64\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_feature, hidden),\n",
    "            GeLU(),\n",
    "            nn.Dropout(0),\n",
    "            nn.Linear(hidden, out_feature)\n",
    "        )\n",
    "        self.dense.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)\n",
    "    \n",
    "class OutputLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        n_dim = 1024\n",
    "        self.dense_hidden = Dense(n_dim, 64)\n",
    "\n",
    "        self.dense1 = Dense(64, 2)\n",
    "        self.dense2 = Dense(64, 2)\n",
    "        self.dense3 = Dense(64, 2)\n",
    "        self.dense4 = Dense(64, 2)\n",
    "        \n",
    "    def forward(self, x, labels1, labels2, labels3, labels4 ):\n",
    "                \n",
    "        hidden = self.dense_hidden(x)\n",
    "        \n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "        \n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return loss, y1, y2, y3, y4, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(user_attribute_dict['train_id'])\n",
    "# train_x, test_x = tensor_x[:num_train].clone(), tensor_x[num_train:].clone()\n",
    "# train_y1, test_y1 = label1[:num_train].clone(), label1[num_train:].clone()\n",
    "# train_y2, test_y2 = label2[:num_train].clone(), label2[num_train:].clone()\n",
    "# train_y3, test_y3 = label3[:num_train].clone(), label3[num_train:].clone()\n",
    "# train_y4, test_y4 = label4[:num_train].clone(), label4[num_train:].clone()\n",
    "\n",
    "# train_x, test_x = tensor_x[:num_train].clone().detach().requires_grad_(True), tensor_x[num_train:].clone().detach().requires_grad_(True)\n",
    "# train_y1, test_y1 = label1[:num_train].clone().detach().requires_grad_(True), label1[num_train:].clone().detach().requires_grad_(True)\n",
    "# train_y2, test_y2 = label2[:num_train].clone().detach().requires_grad_(True), label2[num_train:].clone().detach().requires_grad_(True)\n",
    "# train_y3, test_y3 = label3[:num_train].clone().detach().requires_grad_(True), label3[num_train:].clone().detach().requires_grad_(True)\n",
    "# train_y4, test_y4 = label4[:num_train].clone().detach().requires_grad_(True), label4[num_train:].clone().detach().requires_grad_(True)\n",
    "\n",
    "train_x, test_x = torch.tensor(full_x[:num_train]), torch.tensor(full_x[num_train:])\n",
    "train_y1, test_y1 = torch.tensor(label1[:num_train]), torch.tensor(label1[num_train:])\n",
    "train_y2, test_y2 = torch.tensor(label2[:num_train]), torch.tensor(label2[num_train:])\n",
    "train_y3, test_y3 = torch.tensor(label3[:num_train]), torch.tensor(label3[num_train:])\n",
    "train_y4, test_y4 = torch.tensor(label4[:num_train]), torch.tensor(label4[num_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_x, train_y1, train_y2, train_y3, train_y4)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers = 0)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(test_x, test_y1, test_y2, test_y3, test_y4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "code_folding": [
     0,
     71
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0778f194c954d36b2b4f76e392052b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.824231</td>\n",
       "      <td>0.690625</td>\n",
       "      <td>0.682533</td>\n",
       "      <td>0.647844</td>\n",
       "      <td>0.639239</td>\n",
       "      <td>0.645825</td>\n",
       "      <td>0.641671</td>\n",
       "      <td>0.613371</td>\n",
       "      <td>0.609908</td>\n",
       "      <td>0.728512</td>\n",
       "      <td>0.702274</td>\n",
       "      <td>0.657053</td>\n",
       "      <td>0.640635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.824231  0.690625  0.682533  0.647844  0.639239   0.645825   0.641671   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.613371   0.609908   0.728512   0.702274   0.657053   0.640635  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e74ac36c44465b8e8475614cd2bbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.826756</td>\n",
       "      <td>0.688596</td>\n",
       "      <td>0.676777</td>\n",
       "      <td>0.648415</td>\n",
       "      <td>0.638095</td>\n",
       "      <td>0.643746</td>\n",
       "      <td>0.639141</td>\n",
       "      <td>0.615236</td>\n",
       "      <td>0.611416</td>\n",
       "      <td>0.723171</td>\n",
       "      <td>0.695667</td>\n",
       "      <td>0.660072</td>\n",
       "      <td>0.639143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.826756  0.688596  0.676777  0.648415  0.638095   0.643746   0.639141   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.615236   0.611416   0.723171   0.695667   0.660072   0.639143  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd02f0ed45849d688a870a864c00c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.722456</td>\n",
       "      <td>0.692176</td>\n",
       "      <td>0.68001</td>\n",
       "      <td>0.654967</td>\n",
       "      <td>0.633422</td>\n",
       "      <td>0.646952</td>\n",
       "      <td>0.640612</td>\n",
       "      <td>0.618646</td>\n",
       "      <td>0.60831</td>\n",
       "      <td>0.721475</td>\n",
       "      <td>0.698396</td>\n",
       "      <td>0.664992</td>\n",
       "      <td>0.634209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+    2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.722456  0.692176  0.68001  0.654967  0.633422   0.646952   0.640612   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.618646    0.60831   0.721475   0.698396   0.664992   0.634209  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d42717278e44070ad2d53ab62250aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.880579</td>\n",
       "      <td>0.686954</td>\n",
       "      <td>0.679458</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.626016</td>\n",
       "      <td>0.641966</td>\n",
       "      <td>0.638369</td>\n",
       "      <td>0.618082</td>\n",
       "      <td>0.601779</td>\n",
       "      <td>0.720029</td>\n",
       "      <td>0.699083</td>\n",
       "      <td>0.664453</td>\n",
       "      <td>0.625106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.880579  0.686954  0.679458  0.655556  0.626016   0.641966   0.638369   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.618082   0.601779   0.720029   0.699083   0.664453   0.625106  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a443609bf324ee6b2cd104e790d2880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.895509</td>\n",
       "      <td>0.692046</td>\n",
       "      <td>0.673201</td>\n",
       "      <td>0.653375</td>\n",
       "      <td>0.619673</td>\n",
       "      <td>0.647832</td>\n",
       "      <td>0.634601</td>\n",
       "      <td>0.617062</td>\n",
       "      <td>0.59807</td>\n",
       "      <td>0.726653</td>\n",
       "      <td>0.694838</td>\n",
       "      <td>0.663655</td>\n",
       "      <td>0.618005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.895509  0.692046  0.673201  0.653375  0.619673   0.647832   0.634601   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.617062    0.59807   0.726653   0.694838   0.663655   0.618005  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58dbacbb403f49f3a2023bd98cf114f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.943532</td>\n",
       "      <td>0.683997</td>\n",
       "      <td>0.673623</td>\n",
       "      <td>0.652448</td>\n",
       "      <td>0.615861</td>\n",
       "      <td>0.638325</td>\n",
       "      <td>0.633489</td>\n",
       "      <td>0.615917</td>\n",
       "      <td>0.592127</td>\n",
       "      <td>0.717461</td>\n",
       "      <td>0.693702</td>\n",
       "      <td>0.662312</td>\n",
       "      <td>0.61388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.943532  0.683997  0.673623  0.652448  0.615861   0.638325   0.633489   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.615917   0.592127   0.717461   0.693702   0.662312    0.61388  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb91552b0a2c429bac960139064d2f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.934742</td>\n",
       "      <td>0.675038</td>\n",
       "      <td>0.674272</td>\n",
       "      <td>0.645555</td>\n",
       "      <td>0.617882</td>\n",
       "      <td>0.629865</td>\n",
       "      <td>0.635151</td>\n",
       "      <td>0.611403</td>\n",
       "      <td>0.596796</td>\n",
       "      <td>0.706874</td>\n",
       "      <td>0.694657</td>\n",
       "      <td>0.658495</td>\n",
       "      <td>0.6155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.934742  0.675038  0.674272  0.645555  0.617882   0.629865   0.635151   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.611403   0.596796   0.706874   0.694657   0.658495     0.6155  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f443d370930344cb862fc5ecbf726461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.919719</td>\n",
       "      <td>0.681362</td>\n",
       "      <td>0.661486</td>\n",
       "      <td>0.647126</td>\n",
       "      <td>0.614579</td>\n",
       "      <td>0.636949</td>\n",
       "      <td>0.625403</td>\n",
       "      <td>0.612902</td>\n",
       "      <td>0.594761</td>\n",
       "      <td>0.714581</td>\n",
       "      <td>0.67991</td>\n",
       "      <td>0.659654</td>\n",
       "      <td>0.613146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.919719  0.681362  0.661486  0.647126  0.614579   0.636949   0.625403   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.612902   0.594761   0.714581    0.67991   0.659654   0.613146  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf0beb4c8c84cd9b1e689e5045a03b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.92576</td>\n",
       "      <td>0.678106</td>\n",
       "      <td>0.667885</td>\n",
       "      <td>0.652179</td>\n",
       "      <td>0.627929</td>\n",
       "      <td>0.630609</td>\n",
       "      <td>0.627362</td>\n",
       "      <td>0.614618</td>\n",
       "      <td>0.60223</td>\n",
       "      <td>0.706477</td>\n",
       "      <td>0.686191</td>\n",
       "      <td>0.665921</td>\n",
       "      <td>0.624855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.92576  0.678106  0.667885  0.652179  0.627929   0.630609   0.627362   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.614618    0.60223   0.706477   0.686191   0.665921   0.624855  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a83d02b33f4c4fae80ddbe11b0a3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1.932008</td>\n",
       "      <td>0.673133</td>\n",
       "      <td>0.667157</td>\n",
       "      <td>0.648758</td>\n",
       "      <td>0.622965</td>\n",
       "      <td>0.625979</td>\n",
       "      <td>0.627597</td>\n",
       "      <td>0.613749</td>\n",
       "      <td>0.597579</td>\n",
       "      <td>0.703879</td>\n",
       "      <td>0.686898</td>\n",
       "      <td>0.662445</td>\n",
       "      <td>0.621369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  1.932008  0.673133  0.667157  0.648758  0.622965   0.625979   0.627597   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.613749   0.597579   0.703879   0.686898   0.662445   0.621369  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff670f9fb6d43deb8627c41840a3942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2.043947</td>\n",
       "      <td>0.675056</td>\n",
       "      <td>0.667792</td>\n",
       "      <td>0.653011</td>\n",
       "      <td>0.628561</td>\n",
       "      <td>0.628734</td>\n",
       "      <td>0.629216</td>\n",
       "      <td>0.61574</td>\n",
       "      <td>0.599152</td>\n",
       "      <td>0.708561</td>\n",
       "      <td>0.687234</td>\n",
       "      <td>0.66664</td>\n",
       "      <td>0.628938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  2.043947  0.675056  0.667792  0.653011  0.628561   0.628734   0.629216   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test    0.61574   0.599152   0.708561   0.687234    0.66664   0.628938  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf150db966134b73ac1913ff3d9f32ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1274), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2.024772</td>\n",
       "      <td>0.674132</td>\n",
       "      <td>0.661583</td>\n",
       "      <td>0.651505</td>\n",
       "      <td>0.626883</td>\n",
       "      <td>0.628826</td>\n",
       "      <td>0.624427</td>\n",
       "      <td>0.615327</td>\n",
       "      <td>0.598705</td>\n",
       "      <td>0.705947</td>\n",
       "      <td>0.678912</td>\n",
       "      <td>0.666669</td>\n",
       "      <td>0.626609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
       "test  2.024772  0.674132  0.661583  0.651505  0.626883   0.628826   0.624427   \n",
       "\n",
       "      new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
       "test   0.615327   0.598705   0.705947   0.678912   0.666669   0.626609  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def eval_data(model):\n",
    "    global new_client, old_client\n",
    "\n",
    "    loss_list = []\n",
    "    y1_list, y2_list, y3_list, y4_list = [], [], [], []\n",
    "    label1_list, label2_list, label3_list, label4_list = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x, l1, l2, l3, l4 in test_loader:\n",
    "            loss, y1, y2, y3, y4, _ = model(x.to(device), l1.to(device), l2.to(device), l3.to(device), l4.to(device))\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "            y1_list.append(y1.cpu().detach().numpy())\n",
    "            y2_list.append(y2.cpu().detach().numpy())\n",
    "            y3_list.append(y3.cpu().detach().numpy())\n",
    "            y4_list.append(y4.cpu().detach().numpy())\n",
    "\n",
    "            label1_list.append(l1.long().cpu().detach().numpy())\n",
    "            label2_list.append(l2.long().cpu().detach().numpy())\n",
    "            label3_list.append(l3.long().cpu().detach().numpy())\n",
    "            label4_list.append(l4.long().cpu().detach().numpy())\n",
    "\n",
    "        loss = np.mean(loss_list)\n",
    "    \n",
    "    y1_np = np.concatenate(y1_list,  axis = 0)\n",
    "    y2_np = np.concatenate(y2_list,  axis = 0)\n",
    "    y3_np = np.concatenate(y3_list,  axis = 0)\n",
    "    y4_np = np.concatenate(y4_list,  axis = 0)\n",
    "\n",
    "    labels1_np = np.concatenate(label1_list,  axis = 0)\n",
    "    labels2_np = np.concatenate(label2_list,  axis = 0)\n",
    "    labels3_np = np.concatenate(label3_list,  axis = 0)\n",
    "    labels4_np = np.concatenate(label4_list,  axis = 0)\n",
    "\n",
    "    auc1 = roc_auc_score(labels1_np, y1_np[:, 1])\n",
    "    auc2 = roc_auc_score(labels2_np, y2_np[:, 1])\n",
    "    auc3 = roc_auc_score(labels3_np, y3_np[:, 1])\n",
    "    auc4 = roc_auc_score(labels4_np, y4_np[:, 1])\n",
    "    auc_all = [auc1, auc2, auc3, auc4]\n",
    "    \n",
    "    new_client_auc1 = roc_auc_score(labels1_np[new_client], y1_np[:, 1][new_client])\n",
    "    new_client_auc2 = roc_auc_score(labels2_np[new_client], y2_np[:, 1][new_client])\n",
    "    new_client_auc3 = roc_auc_score(labels3_np[new_client], y3_np[:, 1][new_client])\n",
    "    new_client_auc4 = roc_auc_score(labels4_np[new_client], y4_np[:, 1][new_client])\n",
    "    auc_new_client = [new_client_auc1, new_client_auc2, new_client_auc3, new_client_auc4]\n",
    "\n",
    "    old_client_auc1 = roc_auc_score(labels1_np[old_client], y1_np[:, 1][old_client])\n",
    "    old_client_auc2 = roc_auc_score(labels2_np[old_client], y2_np[:, 1][old_client])\n",
    "    old_client_auc3 = roc_auc_score(labels3_np[old_client], y3_np[:, 1][old_client])\n",
    "    old_client_auc4 = roc_auc_score(labels4_np[old_client], y4_np[:, 1][old_client])\n",
    "    auc_old_client = [old_client_auc1, old_client_auc2, old_client_auc3, old_client_auc4]\n",
    "\n",
    "    return {\n",
    "        'loss' : loss,\n",
    "        '1m30+' : auc1,\n",
    "        '2m30+' : auc2,\n",
    "        '3m30+' : auc3,\n",
    "        '4m30+' : auc4,\n",
    "        'new_1m30+' : new_client_auc1,\n",
    "        'new_2m30+' : new_client_auc2,\n",
    "        'new_3m30+' : new_client_auc3,\n",
    "        'new_4m30+' : new_client_auc4,\n",
    "        'old_1m30+' : old_client_auc1,\n",
    "        'old_2m30+' : old_client_auc2,\n",
    "        'old_3m30+' : old_client_auc3,\n",
    "        'old_4m30+' : old_client_auc4,\n",
    "    }\n",
    "    \n",
    "epoch = 12\n",
    "output_model = OutputLayer().to(device)\n",
    "optimizer = AdamW(output_model.parameters(), lr = 0.001, weight_decay = 0)\n",
    "\n",
    "for i in range(epoch):\n",
    "    output_model.train()\n",
    "\n",
    "    for x, l1, l2, l3, l4 in tqdm(train_loader):\n",
    "        loss, y1, y2, y3, y4, _ = output_model(x.to(device), l1.to(device), l2.to(device), l3.to(device), l4.to(device))\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "#         loss.backward(retain_graph=True)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(output_model.parameters(), max_norm = 2)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "    output_model.eval()\n",
    "    \n",
    "#     train_ret_dict = eval_data(output_model)\n",
    "    test_ret_dict = eval_data(output_model)\n",
    "    df_ret = pd.DataFrame([\n",
    "        test_ret_dict\n",
    "    ], index = ['test'])\n",
    "    ipd.display(df_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-paced_Multi-view_Co-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC,SVC, NuSVC\n",
    "from copy import deepcopy\n",
    "from sklearn import linear_model, svm, neural_network, ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def sel_ids_y(score, add_num = 10):\n",
    "    ids_sort = np.argsort(score)\n",
    "    add_id = np.zeros(score.shape[0])\n",
    "    add_id[ids_sort[:add_num]] = -1\n",
    "    add_id[ids_sort[-add_num:]] = 1\n",
    "    return add_id\n",
    "    \n",
    "def update_train_untrain(sel_ids, train_data, train_labels, untrain_data, weights=None):\n",
    "#     sel_ids = np.array(sel_ids, dtype='bool')\n",
    "    add_ids = np.where(np.array(sel_ids) != 0)[0]\n",
    "    untrain_ids = np.where(np.array(sel_ids) == 0)[0]\n",
    "    add_datas = [d[add_ids] for d in untrain_data]\n",
    "    new_train_data = [np.concatenate([d1, d2]) for d1,d2 in zip(train_data, add_datas)]\n",
    "    add_y = [1 if sel_ids[idx] > 0 else 0 for idx in add_ids]\n",
    "    new_train_y = np.concatenate([train_labels, add_y])\n",
    "    new_untrain_data = [d[untrain_ids] for d in untrain_data]\n",
    "    return new_train_data, new_train_y, new_untrain_data\n",
    "\n",
    "\n",
    "def cotrain(labeled_data, labels, unlabeled_data, iter_step=1):\n",
    "    lbls = copy.deepcopy(labels)\n",
    "    for step in range(iter_step):\n",
    "        scores = []\n",
    "        add_ids = []\n",
    "        add_ys = []\n",
    "        clfs = []\n",
    "        for view in range(2):\n",
    "            clfs.append(LinearSVC())\n",
    "            clfs[view].fit(labeled_data[view], lbls)\n",
    "            scores.append(clfs[view].decision_function(unlabeled_data[view]))\n",
    "            add_id = sel_ids_y(scores[view], 6)\n",
    "            add_ids.append(add_id)\n",
    "        add_id = sum(add_ids)\n",
    "        labeled_data, lbls, unlabeled_data = update_train_untrain(add_id, labeled_data, lbls, unlabeled_data)\n",
    "        if len(unlabeled_data[view]) <= 0:\n",
    "            break\n",
    "    return clfs\n",
    "        \n",
    "\n",
    "\n",
    "def update_train(sel_ids, train_data, train_labels, untrain_data, pred_y):\n",
    "    add_ids = np.where(np.array(sel_ids) != 0)[0]\n",
    "    add_data = [d[add_ids] for d in untrain_data]\n",
    "    new_train_data = [np.concatenate([d1, d2]) for d1,d2 in zip(train_data, add_data)]\n",
    "    add_y = pred_y[add_ids]\n",
    "    new_train_y = np.concatenate([train_labels, pred_y[add_ids]])\n",
    "    return new_train_data, new_train_y\n",
    "\n",
    "\n",
    "def spaco(l_data, lbls, u_data, iter_step = 1, gamma = 0.5):\n",
    "    \n",
    "    # initiate classifier\n",
    "    clfs = []\n",
    "    scores = []\n",
    "    add_ids = []\n",
    "    add_num = 6\n",
    "    clfss = []\n",
    "    for view in range(4):\n",
    "        clfs.append(ensemble.GradientBoostingClassifier())\n",
    "        clfs[view].fit(l_data[view], lbls)\n",
    "        scores.append(clfs[view].decision_function(u_data[view]))\n",
    "        add_ids.append(sel_ids_y(scores[view], add_num))\n",
    "        py = [0  if s < 0 else 1 for s in scores[view]]\n",
    "    score = sum(scores)\n",
    "    pred_y = np.array([0  if s < 0 else 1 for s in score])\n",
    "    for step in range(iter_step):\n",
    "        for view in range(4):\n",
    "            if add_num * 2 > u_data[0].shape[0]: break\n",
    "            #update v\n",
    "            ov = np.where(add_ids[1-view] != 0)[0]\n",
    "            scores[view][ov] += add_ids[1-view][ov] * gamma\n",
    "            add_ids[view] = sel_ids_y(scores[view], add_num)\n",
    "            \n",
    "            \n",
    "            #update w\n",
    "            nl_data, nlbls = update_train(add_ids[view], l_data, lbls, u_data, pred_y)\n",
    "            clfs[view].fit(nl_data[view], nlbls)\n",
    "            \n",
    "            # update y, v\n",
    "            scores[view] = clfs[view].decision_function(u_data[view])\n",
    "            add_num += 6\n",
    "            scores[view][ov] += add_ids[1-view][ov] * gamma\n",
    "            add_ids[view] = sel_ids_y(scores[view], add_num)\n",
    "            \n",
    "            \n",
    "            score = sum(scores)\n",
    "            \n",
    "            pred_y = np.array([0  if s < 0 else 1 for s in score])\n",
    "            py = [0  if s < 0 else 1 for s in scores[view]]\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_id = np.array(df_master_records.loc[user_attribute_dict['train_id']]['loan_sequence']==1)\n",
    "test_new_id = np.array(df_master_records.loc[user_attribute_dict['test_id']]['loan_sequence']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_used = -1\n",
    "train_y_list = [train_y1, train_y2, train_y3, train_y4]\n",
    "test_y_list = [test_y1, test_y2, test_y3, test_y4]\n",
    "\n",
    "train_x_list = [train_x_user_attribute[:n_used], train_x_app_list[:n_used], train_x_app_behavior[:n_used], train_x_user_log[:n_used]]\n",
    "test_x_list = [test_x_user_attribute[:n_used], test_x_app_list[:n_used], test_x_app_behavior[:n_used], test_x_user_log[:n_used]]\n",
    "\n",
    "for i, y_n in enumerate(train_y_list): \n",
    "    clfs = spaco(\n",
    "        train_x_list, \n",
    "        y_n[:n_used], \n",
    "        test_x_list, \n",
    "        iter_step=5, gamma=3)\n",
    "\n",
    "    score = 0\n",
    "    for t, view in enumerate(test_x_list):\n",
    "        score += clfs[t].decision_function(view)\n",
    "    auc = roc_auc_score(test_y_list[i][:n_used].astype('int'), score)\n",
    "    new_auc = roc_auc_score(test_y_list[i][:n_used].astype('int')[test_new_id[:n_used]], score[test_new_id[:n_used]])\n",
    "    old_auc = roc_auc_score(test_y_list[i][:n_used].astype('int')[~test_new_id[:n_used]], score[~test_new_id[:n_used]])\n",
    "\n",
    "    print('%d auc:%f, new auc:%f, old auc:%f'%(i, auc, new_auc, old_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Partial Multi-View Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1. + torch.tanh(x * 0.7978845608 * (1. + 0.044715 * x * x)))\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super().__init__()\n",
    "        hidden = 64\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_feature, hidden),\n",
    "            GeLU(),\n",
    "            nn.Dropout(0),\n",
    "            nn.Linear(hidden, out_feature)\n",
    "        )\n",
    "        self.dense.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)\n",
    "\n",
    "class CPM(torch.nn.Module):\n",
    "    def __init__(self, n_train, n_test, n_hidden, n_view):\n",
    "        super().__init__()\n",
    "\n",
    "        n_factors = 64\n",
    "        self.n_view = n_view\n",
    "        self.h_train = nn.Embedding(n_train, n_factors)\n",
    "        self.h_test = nn.Embedding(n_test, n_factors)\n",
    "        self.pro_list = nn.ModuleList([Dense(n_factors, n_hidden) for i in range(n_view)])\n",
    "        \n",
    "        self.dense1 = Dense(1088, 2)\n",
    "        self.dense2 = Dense(1088, 2)\n",
    "        self.dense3 = Dense(1088, 2)\n",
    "        self.dense4 = Dense(1088, 2)\n",
    "    \n",
    "    def train_forward(self, **param):\n",
    "\n",
    "        train_hidden = self.h_train(param['train_idx'])\n",
    "        test_hidden = self.h_test(param['test_idx'])\n",
    "        reconstruction_loss = 0\n",
    "        for i in range(self.n_view):\n",
    "            rebuild_train = self.pro_list[i](train_hidden)\n",
    "            rebuild_test = self.pro_list[i](test_hidden)\n",
    "            train_exist_idx_v_i = param['train_exist_idx_%d'%i]\n",
    "            test_exist_idx_v_i = param['test_exist_idx_%d'%i]\n",
    "\n",
    "            loss_rebuild_train = (rebuild_train[train_exist_idx_v_i] - param['view_train_%d' % i][train_exist_idx_v_i]) ** 2\n",
    "            loss_rebuild_test = (rebuild_train[test_exist_idx_v_i] - param['view_test_%d' % i][test_exist_idx_v_i]) ** 2\n",
    "            reconstruction_loss += torch.mean(loss_rebuild_train) + torch.mean(loss_rebuild_test)\n",
    "        \n",
    "        train_hidden = torch.cat([train_hidden, param['view_train_0'], \n",
    "                                     param['view_train_1'], param['view_train_2'],\n",
    "                                     param['view_train_3']], -1)\n",
    "        \n",
    "        y1 = self.dense1(train_hidden)\n",
    "        y2 = self.dense2(train_hidden)\n",
    "        y3 = self.dense3(train_hidden)\n",
    "        y4 = self.dense4(train_hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, param['labels1'].long())\n",
    "        loss2 = loss_func(y2, param['labels2'].long())\n",
    "        loss3 = loss_func(y3, param['labels3'].long())\n",
    "        loss4 = loss_func(y4, param['labels4'].long())\n",
    "        \n",
    "        classification_loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return reconstruction_loss, classification_loss, reconstruction_loss + classification_loss \n",
    "\n",
    "    def test_forward(self, **param):\n",
    "        test_hidden = self.h_test(param['test_idx'])\n",
    "\n",
    "        test_hidden = torch.cat([test_hidden, param['view_test_0'], \n",
    "                                    param['view_test_1'], \n",
    "                                    param['view_test_2'],\n",
    "                                    param['view_test_3']], -1)        \n",
    "        y1 = self.dense1(test_hidden)\n",
    "        y2 = self.dense2(test_hidden)\n",
    "        y3 = self.dense3(test_hidden)\n",
    "        y4 = self.dense4(test_hidden)\n",
    "        \n",
    "        return y1, y2, y3, y4\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(user_attribute_dict['train_id'])\n",
    "num_test = len(user_attribute_dict['test_id'])\n",
    "v0_exist_set = set(user_attribute_exsit_idx)\n",
    "v1_exist_set = set(app_behaviors_exsit_idx)\n",
    "v2_exist_set = set(app_list_exsit_idx)\n",
    "v3_exist_set = set(user_log_exsit_idx)\n",
    "\n",
    "v0_train_m, v0_test_m = user_attribute_matrix[:num_train], user_attribute_matrix[num_train:]\n",
    "v1_train_m, v1_test_m = app_behaviors_matrix[:num_train], app_behaviors_matrix[num_train:]\n",
    "v2_train_m, v2_test_m = app_list_matrix[:num_train], app_list_matrix[num_train:]\n",
    "v3_train_m, v3_test_m = user_log_matrix[:num_train], user_log_matrix[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda:1\")\n",
    "model = CPM(num_train, num_test, 256, 4).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('start')\n",
    "\n",
    "def train():\n",
    "    batch_size = 256\n",
    "    epoch = 12\n",
    "\n",
    "    for epoch in range(epoch):\n",
    "        model.train()\n",
    "        idxs = list(range(user_attribute_matrix.shape[0]))\n",
    "        random.shuffle(idxs)\n",
    "\n",
    "        for i in tqdm(range(0, user_attribute_matrix.shape[0], batch_size)):\n",
    "#         for i in (range(0, user_attribute_matrix.shape[0], batch_size)):\n",
    "            select_idx = idxs[i:i+batch_size]\n",
    "            train_idx = [idx for idx in select_idx if idx < num_train]\n",
    "            test_idx = [idx - num_train for idx in select_idx if idx >= num_train]\n",
    "\n",
    "            loss1, loss2, loss = model.train_forward(\n",
    "                train_exist_idx_0 = torch.tensor([i for i, idx in enumerate(train_idx) if idx in v0_exist_set]).long().to(device),\n",
    "                train_exist_idx_1 = torch.tensor([i for i, idx in enumerate(train_idx) if idx in v1_exist_set]).long().to(device),\n",
    "                train_exist_idx_2 = torch.tensor([i for i, idx in enumerate(train_idx) if idx in v2_exist_set]).long().to(device),\n",
    "                train_exist_idx_3 = torch.tensor([i for i, idx in enumerate(train_idx) if idx in v3_exist_set]).long().to(device),\n",
    "\n",
    "                test_exist_idx_0 = torch.tensor([i for i, idx in enumerate(test_idx) if idx in v0_exist_set]).long().to(device),\n",
    "                test_exist_idx_1 = torch.tensor([i for i, idx in enumerate(test_idx) if idx in v1_exist_set]).long().to(device),\n",
    "                test_exist_idx_2 = torch.tensor([i for i, idx in enumerate(test_idx) if idx in v2_exist_set]).long().to(device),\n",
    "                test_exist_idx_3 = torch.tensor([i for i, idx in enumerate(test_idx) if idx in v3_exist_set]).long().to(device),\n",
    "\n",
    "                view_train_0 = torch.tensor(v0_train_m[train_idx].astype('float32')).to(device),\n",
    "                view_train_1 = torch.tensor(v1_train_m[train_idx].astype('float32')).to(device),\n",
    "                view_train_2 = torch.tensor(v2_train_m[train_idx].astype('float32')).to(device),\n",
    "                view_train_3 = torch.tensor(v3_train_m[train_idx].astype('float32')).to(device),\n",
    "\n",
    "                view_test_0 = torch.tensor(v0_test_m[test_idx].astype('float32')).to(device),\n",
    "                view_test_1 = torch.tensor(v1_test_m[test_idx].astype('float32')).to(device),\n",
    "                view_test_2 = torch.tensor(v2_test_m[test_idx].astype('float32')).to(device),\n",
    "                view_test_3 = torch.tensor(v3_test_m[test_idx].astype('float32')).to(device),\n",
    "\n",
    "                train_idx = torch.tensor(train_idx).long().to(device),\n",
    "                test_idx = torch.tensor(test_idx).long().to(device),\n",
    "                labels1 = torch.tensor(y1[train_idx]).long().to(device),\n",
    "                labels2 = torch.tensor(y2[train_idx]).long().to(device),\n",
    "                labels3 = torch.tensor(y3[train_idx]).long().to(device),\n",
    "                labels4 = torch.tensor(y4[train_idx]).long().to(device)\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 2)\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "\n",
    "        y1_list, y2_list, y3_list, y4_list = [], [], [], []\n",
    "        with torch.no_grad():\n",
    "            idxs = list(range(num_test))\n",
    "            for i in range(0, num_test, batch_size):\n",
    "                select_idx = idxs[i:i+batch_size]\n",
    "                y1_tensor, y2_tensor, y3_tensor, y4_tensor= model.test_forward(\n",
    "                    test_idx = torch.tensor(select_idx).long().to(device),\n",
    "                    view_test_0 = torch.tensor(v0_test_m[select_idx].astype('float32')).to(device),\n",
    "                    view_test_1 = torch.tensor(v1_test_m[select_idx].astype('float32')).to(device),\n",
    "                    view_test_2 = torch.tensor(v2_test_m[select_idx].astype('float32')).to(device),\n",
    "                    view_test_3 = torch.tensor(v3_test_m[select_idx].astype('float32')).to(device)\n",
    "\n",
    "                )\n",
    "                y1_list.append(y1_tensor.cpu().detach().numpy())\n",
    "                y2_list.append(y2_tensor.cpu().detach().numpy())\n",
    "                y3_list.append(y3_tensor.cpu().detach().numpy())\n",
    "                y4_list.append(y4_tensor.cpu().detach().numpy())\n",
    "\n",
    "        y1_np = np.concatenate(y1_list,  axis = 0)\n",
    "        y2_np = np.concatenate(y2_list,  axis = 0)\n",
    "        y3_np = np.concatenate(y3_list,  axis = 0)\n",
    "        y4_np = np.concatenate(y4_list,  axis = 0)\n",
    "        \n",
    "        labels1_np = y1[-num_test:]\n",
    "        labels2_np = y2[-num_test:]\n",
    "        labels3_np = y3[-num_test:]\n",
    "        labels4_np = y4[-num_test:]\n",
    "\n",
    "        auc1 = roc_auc_score(labels1_np, y1_np[:, 1])\n",
    "        auc2 = roc_auc_score(labels2_np, y2_np[:, 1])\n",
    "        auc3 = roc_auc_score(labels3_np, y3_np[:, 1])\n",
    "        auc4 = roc_auc_score(labels4_np, y4_np[:, 1])\n",
    "        auc_all = [auc1, auc2, auc3, auc4]\n",
    "\n",
    "        new_client_auc1 = roc_auc_score(labels1_np[new_client], y1_np[:, 1][new_client])\n",
    "        new_client_auc2 = roc_auc_score(labels2_np[new_client], y2_np[:, 1][new_client])\n",
    "        new_client_auc3 = roc_auc_score(labels3_np[new_client], y3_np[:, 1][new_client])\n",
    "        new_client_auc4 = roc_auc_score(labels4_np[new_client], y4_np[:, 1][new_client])\n",
    "        auc_new_client = [new_client_auc1, new_client_auc2, new_client_auc3, new_client_auc4]\n",
    "\n",
    "        old_client_auc1 = roc_auc_score(labels1_np[old_client], y1_np[:, 1][old_client])\n",
    "        old_client_auc2 = roc_auc_score(labels2_np[old_client], y2_np[:, 1][old_client])\n",
    "        old_client_auc3 = roc_auc_score(labels3_np[old_client], y3_np[:, 1][old_client])\n",
    "        old_client_auc4 = roc_auc_score(labels4_np[old_client], y4_np[:, 1][old_client])\n",
    "        auc_old_client = [old_client_auc1, old_client_auc2, old_client_auc3, old_client_auc4]\n",
    "\n",
    "        df_ret = pd.DataFrame([{\n",
    "            '1m30+' : auc1,\n",
    "            '2m30+' : auc2,\n",
    "            '3m30+' : auc3,\n",
    "            '4m30+' : auc4,\n",
    "            'new_1m30+' : new_client_auc1,\n",
    "            'new_2m30+' : new_client_auc2,\n",
    "            'new_3m30+' : new_client_auc3,\n",
    "            'new_4m30+' : new_client_auc4,\n",
    "            'old_1m30+' : old_client_auc1,\n",
    "            'old_2m30+' : old_client_auc2,\n",
    "            'old_3m30+' : old_client_auc3,\n",
    "            'old_4m30+' : old_client_auc4,\n",
    "        }], index = ['test'])\n",
    "        \n",
    "#         if epoch % 32 == 0:\n",
    "        logging.info('epoch: %d' % epoch)\n",
    "        ipd.display(df_ret)\n",
    "train()\n",
    "logging.info('end')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Incomplete Multi-View Prognosis Predictor for Breast Cancer: GIMPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size = 256, output_size = 256, n_view = 4):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map_list = nn.ModuleList([nn.Linear(input_size, output_size) for _ in range(n_view)])\n",
    "        self.map = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, v1, v2, v3, v4):\n",
    "#         v1_generation = self.map_list[0](v1)\n",
    "#         v2_generation = self.map_list[1](v2)\n",
    "#         v3_generation = self.map_list[2](v3)\n",
    "#         v4_generation = self.map_list[3](v4)\n",
    "        v1_generation = self.map(v1)\n",
    "        v2_generation = self.map(v2)\n",
    "        v3_generation = self.map(v3)\n",
    "        v4_generation = self.map(v4)\n",
    "\n",
    "        return torch.cat([v1_generation, v2_generation, v3_generation, v4_generation])\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size = 256):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, 1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_real_data(batch_size):\n",
    "    global user_attribute_matrix, app_behaviors_matrix, app_list_matrix, user_log_matrix,\\\n",
    "    user_attribute_exsit_idx, app_behaviors_exsit_idx, app_list_exsit_idx, user_log_exsit_idx\n",
    "    assert batch_size % 4 == 0\n",
    "    idx1 = random.sample(user_attribute_exsit_idx, batch_size // 4)\n",
    "    idx2 = random.sample(app_behaviors_exsit_idx, batch_size // 4)\n",
    "    idx3 = random.sample(app_list_exsit_idx, batch_size // 4)\n",
    "    idx4 = random.sample(user_log_exsit_idx, batch_size // 4)\n",
    "    v1 = torch.tensor(user_attribute_matrix[idx1]).to(device)\n",
    "    v2 = torch.tensor(app_behaviors_matrix[idx2]).to(device)\n",
    "    v3 = torch.tensor(app_list_matrix[idx3]).to(device)\n",
    "    v4 = torch.tensor(user_log_matrix[idx4]).to(device)\n",
    "\n",
    "    return torch.cat([v1, v2, v3, v4])\n",
    "\n",
    "def sample_generate_data(G_net, batch_size):\n",
    "    global user_attribute_matrix, app_behaviors_matrix, app_list_matrix, user_log_matrix\n",
    "    assert batch_size % 4 == 0\n",
    "    \n",
    "    idx = random.sample(range(user_attribute_matrix.shape[0]), batch_size // 4)\n",
    "    v1 = torch.tensor(user_attribute_matrix[idx]).to(device)\n",
    "    v2 = torch.tensor(app_behaviors_matrix[idx]).to(device)\n",
    "    v3 = torch.tensor(app_list_matrix[idx]).to(device)\n",
    "    v4 = torch.tensor(user_log_matrix[idx]).to(device)\n",
    "    \n",
    "    v_stack = G_net(v1, v2, v3, v4)\n",
    "    return v_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "d_learning_rate = 2e-4  \n",
    "g_learning_rate = 2e-4  \n",
    "optim_betas = (0.9, 0.999)\n",
    "num_epochs = 1024\n",
    "d_steps = 1\n",
    "g_steps = 1\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)\n",
    "batch_size = 256\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for d_index in range(d_steps):\n",
    "        # 1. Train D on real+fake\n",
    "        D.zero_grad()\n",
    "\n",
    "        #  1A: Train D on real\n",
    "        d_real_data = sample_real_data(batch_size)\n",
    "        d_real_decision = D(d_real_data)\n",
    "        d_real_error = criterion(d_real_decision, torch.ones((batch_size, 1)).to(device))  # ones = true\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        #  1B: Train D on fake\n",
    "        d_gen_input = sample_generate_data(G, batch_size)\n",
    "        d_fake_data = d_gen_input.detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = D(d_fake_data)\n",
    "        d_fake_error = criterion(d_fake_decision, torch.zeros((batch_size, 1)).to(device)) # zeros = fake\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "    for g_index in range(g_steps):\n",
    "        # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "        G.zero_grad()\n",
    "\n",
    "        gen_input = sample_generate_data(G, batch_size)\n",
    "        g_fake_data = gen_input\n",
    "        dg_fake_decision = D(g_fake_data)\n",
    "        #gan loss\n",
    "        g_error = criterion(dg_fake_decision, torch.ones((batch_size, 1)).to(device)) # we want to fool, so pretend it's all genuine\n",
    "        \n",
    "        #mse loss\n",
    "        g_error += torch.sum((gen_input-gen_input)**2)\n",
    "        \n",
    "        #STACKED RF loss \n",
    "        labels = torch.ones((batch_size, 1))\n",
    "        g_error += criterion(dg_fake_decision, labels.to(device))\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "    if epoch % 108 == 0:\n",
    "        logging.info('epoch:%d D loss:%f G loss:%f' % (epoch, d_fake_error.item(), g_error.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 256\n",
    "v1_list, v2_list, v3_list, v4_list = [], [], [], []\n",
    "for i in range(0, user_attribute_matrix.shape[0], batch):\n",
    "    v1 = torch.tensor(user_attribute_matrix[i : i + batch]).to(device)\n",
    "    v2 = torch.tensor(app_behaviors_matrix[i : i + batch]).to(device)\n",
    "    v3 = torch.tensor(app_list_matrix[i : i + batch]).to(device)\n",
    "    v4 = torch.tensor(user_log_matrix[i : i + batch]).to(device)\n",
    "    \n",
    "    v_generation = G(v1, v2, v3, v4)\n",
    "    n = v_generation.shape[0] // 4\n",
    "    v1_list.append(v_generation[:n].cpu().detach().numpy())\n",
    "    v2_list.append(v_generation[n:n*2].cpu().detach().numpy())\n",
    "    v3_list.append(v_generation[n*2:n*3].cpu().detach().numpy())\n",
    "    v4_list.append(v_generation[n*3:].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_attribute_generation = np.concatenate(v1_list)\n",
    "app_behaviors_generation = np.concatenate(v2_list)\n",
    "app_list_exsit_generation = np.concatenate(v3_list)\n",
    "user_log_exsit_generation = np.concatenate(v4_list)\n",
    "user_attribute_generation[user_attribute_exsit_idx] = user_attribute_matrix[user_attribute_exsit_idx] \n",
    "app_behaviors_generation[app_behaviors_exsit_idx] = app_behaviors_matrix[app_behaviors_exsit_idx]\n",
    "app_list_exsit_generation[app_list_exsit_idx] = app_list_matrix[app_list_exsit_idx]\n",
    "user_log_exsit_generation[user_log_exsit_idx]  = user_log_matrix[user_log_exsit_idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_dict = {\n",
    "    'user_attribute' : user_attribute_generation,\n",
    "    'app_behaviors' : app_behaviors_generation,\n",
    "    'app_list' : app_list_exsit_generation,\n",
    "    'user_log' : user_log_exsit_generation,\n",
    "    'y1' : y1,\n",
    "    'y2' : y2,\n",
    "    'y3' : y3,\n",
    "    'y4' : y4,\n",
    "}\n",
    "# pickle.dump(generation_dict, open('5_data/GAN_generation_views.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation_dict = pickle.load(open('5_data/GAN_generation_views.pickle', 'rb'))\n",
    "user_attribute_generation = generation_dict['user_attribute']\n",
    "app_behaviors_generation = generation_dict['app_behaviors']\n",
    "app_list_exsit_generation = generation_dict['app_list']\n",
    "user_log_exsit_generation = generation_dict['user_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_x = np.concatenate([\n",
    "    user_attribute_generation,\n",
    "    app_behaviors_generation,\n",
    "    app_list_exsit_generation,\n",
    "    user_log_exsit_generation,\n",
    "], axis=1)\n",
    "\n",
    "label1, label2, label3, label4 = y1.astype('float32'), y2.astype('float32'), y3.astype('float32'), y4.astype('float32')\n",
    "full_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1. + torch.tanh(x * 0.7978845608 * (1. + 0.044715 * x * x)))\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super().__init__()\n",
    "        hidden = 64\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_feature, hidden),\n",
    "            GeLU(),\n",
    "            nn.Dropout(0),\n",
    "            nn.Linear(hidden, out_feature)\n",
    "        )\n",
    "        self.dense.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)\n",
    "    \n",
    "class OutputLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        n_dim = 1024\n",
    "        self.dense_hidden = Dense(n_dim, 64)\n",
    "\n",
    "        self.dense1 = Dense(64, 2)\n",
    "        self.dense2 = Dense(64, 2)\n",
    "        self.dense3 = Dense(64, 2)\n",
    "        self.dense4 = Dense(64, 2)\n",
    "        \n",
    "    def forward(self, x, labels1, labels2, labels3, labels4 ):\n",
    "                \n",
    "        hidden = self.dense_hidden(x)\n",
    "        \n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "        \n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return loss, y1, y2, y3, y4, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(user_attribute_dict['train_id'])\n",
    "# train_x, test_x = tensor_x[:num_train].clone(), tensor_x[num_train:].clone()\n",
    "# train_y1, test_y1 = label1[:num_train].clone(), label1[num_train:].clone()\n",
    "# train_y2, test_y2 = label2[:num_train].clone(), label2[num_train:].clone()\n",
    "# train_y3, test_y3 = label3[:num_train].clone(), label3[num_train:].clone()\n",
    "# train_y4, test_y4 = label4[:num_train].clone(), label4[num_train:].clone()\n",
    "\n",
    "# train_x, test_x = tensor_x[:num_train].clone().detach().requires_grad_(True), tensor_x[num_train:].clone().detach().requires_grad_(True)\n",
    "# train_y1, test_y1 = label1[:num_train].clone().detach().requires_grad_(True), label1[num_train:].clone().detach().requires_grad_(True)\n",
    "# train_y2, test_y2 = label2[:num_train].clone().detach().requires_grad_(True), label2[num_train:].clone().detach().requires_grad_(True)\n",
    "# train_y3, test_y3 = label3[:num_train].clone().detach().requires_grad_(True), label3[num_train:].clone().detach().requires_grad_(True)\n",
    "# train_y4, test_y4 = label4[:num_train].clone().detach().requires_grad_(True), label4[num_train:].clone().detach().requires_grad_(True)\n",
    "\n",
    "train_x, test_x = torch.tensor(full_x[:num_train]), torch.tensor(full_x[num_train:])\n",
    "train_y1, test_y1 = torch.tensor(label1[:num_train]), torch.tensor(label1[num_train:])\n",
    "train_y2, test_y2 = torch.tensor(label2[:num_train]), torch.tensor(label2[num_train:])\n",
    "train_y3, test_y3 = torch.tensor(label3[:num_train]), torch.tensor(label3[num_train:])\n",
    "train_y4, test_y4 = torch.tensor(label4[:num_train]), torch.tensor(label4[num_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(train_x, train_y1, train_y2, train_y3, train_y4)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers = 0)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(test_x, test_y1, test_y2, test_y3, test_y4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_data(model):\n",
    "    global new_client, old_client\n",
    "\n",
    "    loss_list = []\n",
    "    y1_list, y2_list, y3_list, y4_list = [], [], [], []\n",
    "    label1_list, label2_list, label3_list, label4_list = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x, l1, l2, l3, l4 in test_loader:\n",
    "            loss, y1, y2, y3, y4, _ = model(x.to(device), l1.to(device), l2.to(device), l3.to(device), l4.to(device))\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "            y1_list.append(y1.cpu().detach().numpy())\n",
    "            y2_list.append(y2.cpu().detach().numpy())\n",
    "            y3_list.append(y3.cpu().detach().numpy())\n",
    "            y4_list.append(y4.cpu().detach().numpy())\n",
    "\n",
    "            label1_list.append(l1.long().cpu().detach().numpy())\n",
    "            label2_list.append(l2.long().cpu().detach().numpy())\n",
    "            label3_list.append(l3.long().cpu().detach().numpy())\n",
    "            label4_list.append(l4.long().cpu().detach().numpy())\n",
    "\n",
    "        loss = np.mean(loss_list)\n",
    "    \n",
    "    y1_np = np.concatenate(y1_list,  axis = 0)\n",
    "    y2_np = np.concatenate(y2_list,  axis = 0)\n",
    "    y3_np = np.concatenate(y3_list,  axis = 0)\n",
    "    y4_np = np.concatenate(y4_list,  axis = 0)\n",
    "\n",
    "    labels1_np = np.concatenate(label1_list,  axis = 0)\n",
    "    labels2_np = np.concatenate(label2_list,  axis = 0)\n",
    "    labels3_np = np.concatenate(label3_list,  axis = 0)\n",
    "    labels4_np = np.concatenate(label4_list,  axis = 0)\n",
    "\n",
    "    auc1 = roc_auc_score(labels1_np, y1_np[:, 1])\n",
    "    auc2 = roc_auc_score(labels2_np, y2_np[:, 1])\n",
    "    auc3 = roc_auc_score(labels3_np, y3_np[:, 1])\n",
    "    auc4 = roc_auc_score(labels4_np, y4_np[:, 1])\n",
    "    auc_all = [auc1, auc2, auc3, auc4]\n",
    "    \n",
    "    new_client_auc1 = roc_auc_score(labels1_np[new_client], y1_np[:, 1][new_client])\n",
    "    new_client_auc2 = roc_auc_score(labels2_np[new_client], y2_np[:, 1][new_client])\n",
    "    new_client_auc3 = roc_auc_score(labels3_np[new_client], y3_np[:, 1][new_client])\n",
    "    new_client_auc4 = roc_auc_score(labels4_np[new_client], y4_np[:, 1][new_client])\n",
    "    auc_new_client = [new_client_auc1, new_client_auc2, new_client_auc3, new_client_auc4]\n",
    "\n",
    "    old_client_auc1 = roc_auc_score(labels1_np[old_client], y1_np[:, 1][old_client])\n",
    "    old_client_auc2 = roc_auc_score(labels2_np[old_client], y2_np[:, 1][old_client])\n",
    "    old_client_auc3 = roc_auc_score(labels3_np[old_client], y3_np[:, 1][old_client])\n",
    "    old_client_auc4 = roc_auc_score(labels4_np[old_client], y4_np[:, 1][old_client])\n",
    "    auc_old_client = [old_client_auc1, old_client_auc2, old_client_auc3, old_client_auc4]\n",
    "\n",
    "    return {\n",
    "        'loss' : loss,\n",
    "        '1m30+' : auc1,\n",
    "        '2m30+' : auc2,\n",
    "        '3m30+' : auc3,\n",
    "        '4m30+' : auc4,\n",
    "        'new_1m30+' : new_client_auc1,\n",
    "        'new_2m30+' : new_client_auc2,\n",
    "        'new_3m30+' : new_client_auc3,\n",
    "        'new_4m30+' : new_client_auc4,\n",
    "        'old_1m30+' : old_client_auc1,\n",
    "        'old_2m30+' : old_client_auc2,\n",
    "        'old_3m30+' : old_client_auc3,\n",
    "        'old_4m30+' : old_client_auc4,\n",
    "    }\n",
    "    \n",
    "epoch = 12\n",
    "output_model = OutputLayer().to(device)\n",
    "optimizer = AdamW(output_model.parameters(), lr = 0.001, weight_decay = 0)\n",
    "\n",
    "for i in range(epoch):\n",
    "    output_model.train()\n",
    "\n",
    "    for x, l1, l2, l3, l4 in tqdm(train_loader):\n",
    "        loss, y1, y2, y3, y4, _ = output_model(x.to(device), l1.to(device), l2.to(device), l3.to(device), l4.to(device))\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "#         loss.backward(retain_graph=True)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(output_model.parameters(), max_norm = 2)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "    output_model.eval()\n",
    "    \n",
    "#     train_ret_dict = eval_data(output_model)\n",
    "    test_ret_dict = eval_data(output_model)\n",
    "    df_ret = pd.DataFrame([\n",
    "        test_ret_dict\n",
    "    ], index = ['test'])\n",
    "    ipd.display(df_ret)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(hyr)\n",
   "language": "python",
   "name": "hyr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "361.163px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
