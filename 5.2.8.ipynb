{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import datetime\n",
    "import pickle\n",
    "import scipy.sparse as ss\n",
    "import logging\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n",
    "import os\n",
    "from sklearn import linear_model, svm, neural_network, ensemble\n",
    "\n",
    "\n",
    "import IPython.display as ipd\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-17 20:59:31,229 - INFO - start read\n",
      "2020-09-17 20:59:58,386 - INFO - finish read\n"
     ]
    }
   ],
   "source": [
    "logging.info('start read')\n",
    "df_master_records = pickle.load(open('../data_sortout/df_master_records.pickle', 'rb'))\n",
    "se_id_install_list = pickle.load(open('../data_sortout/se_id_install_list.pickle', 'rb'))\n",
    "df_install_behave = pickle.load(open('../data_sortout/df_install_behave_no_date.pickle', 'rb'))\n",
    "df_behave_time = pickle.load(open('../data_sortout/df_time_cut.pickle', 'rb'))\n",
    "se_userlog_cross = pickle.load(open('../data_sortout/se_userlog_cross_id.pickle', 'rb'))\n",
    "logging.info('finish read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR_SAVE = 'var/baseline_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_master_user_discrete(df_master_records):\n",
    "    \n",
    "    df_master_records['qcut_amount_bin'] = pd.qcut(df_master_records['amount_bin'], 5)\n",
    "    df_master_records['new_client'] = df_master_records['loan_sequence'] == 1\n",
    "    df_master_records['qcut_age'] = pd.qcut(df_master_records['age'], 5, duplicates='drop')\n",
    "    \n",
    "    df_master_records['qcut_min_income'] = pd.qcut(df_master_records['min_income'], 6, duplicates='drop')\n",
    "    df_master_records['qcut_max_income'] = pd.qcut(df_master_records['max_income'].apply(int), 6, duplicates='drop')\n",
    "    \n",
    "#     df_master_records['qcut_loan_sequence'] = pd.qcut(df_master_records['loan_sequence'], 6, duplicates='drop')\n",
    "\n",
    "    pne_hot_cols = [ 'months', 'gender', 'educationid', 'marriagestatusid', 'income', \n",
    "                    'qcut_amount_bin', 'qcut_age', 'qcut_min_income', 'qcut_max_income']\n",
    "    \n",
    "    return  pd.get_dummies(df_master_records[pne_hot_cols], columns = pne_hot_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MutualInfoSelection():\n",
    "    \n",
    "    def __init__(self, topN):\n",
    "        self.topN = topN\n",
    "    \n",
    "    def get_select_vector(self, pkgs):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        v = np.zeros(len(self.mp_select_feature_order))\n",
    "        for pkg in pkgs:\n",
    "            if pkg in self.mp_select_feature_order:\n",
    "                v[self.mp_select_feature_order[pkg]] = 1\n",
    "        return v\n",
    "\n",
    "    def fit(self, train_se_id_pkg_list, train_y):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for i in range(train_se_id_pkg_list.shape[0]):\n",
    "            pkg_list = train_se_id_pkg_list.iloc[i]\n",
    "            cols.extend(pkg_list)\n",
    "            rows.extend([i] * len(pkg_list))\n",
    "            data.extend([1] * len(pkg_list))\n",
    "        train_sparse = ss.coo_matrix((data,(rows,cols)))\n",
    "\n",
    "        mutual_weight = mutual_info_classif(train_sparse, train_y)\n",
    "        select_feature = np.argsort(mutual_weight)[-self.topN:]\n",
    "        self.mp_select_feature_order = {}\n",
    "        self.mp_order_select_feature = {}\n",
    "\n",
    "        for i, feature in enumerate(select_feature):\n",
    "            self.mp_select_feature_order[feature] = i\n",
    "            self.mp_order_select_feature[i] = feature\n",
    "    \n",
    "    def transform(self, se_id_pkg_list):\n",
    "        se_app_feature = se_id_pkg_list.apply(self.get_select_vector)\n",
    "        df_app_feature = pd.DataFrame(np.array(list(se_app_feature)))\n",
    "        df_app_feature.index = se_app_feature.index\n",
    "\n",
    "        return df_app_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-17 20:59:58,723 - INFO - Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2020-09-17 20:59:58,724 - INFO - NumExpr defaulting to 8 threads.\n",
      "2020-09-17 20:59:58,820 - INFO - all_train_id len :326082, all_test_id: 75896\n"
     ]
    }
   ],
   "source": [
    "split_date = datetime.datetime(2019, 8, 31)\n",
    "end_date = datetime.datetime(2019, 9, 30)\n",
    "\n",
    "df_master_records = df_master_records.dropna(axis=0, how='any')\n",
    "df_train_master = df_master_records.query('loan_date <= @split_date')\n",
    "df_test_master = df_master_records.query('loan_date > @split_date & loan_date <= @end_date')\n",
    "all_train_id = list(df_train_master.index)\n",
    "all_test_id = list(df_test_master.index)\n",
    "logging.info('all_train_id len :%d, all_test_id: %d' % (len(all_train_id), len(all_test_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(prefix, dataset_dict, model):\n",
    "    \n",
    "    train_x = dataset_dict['train_x']\n",
    "    train_y = dataset_dict['train_y']\n",
    "    test_x = dataset_dict['test_x']\n",
    "    test_y = dataset_dict['test_y']\n",
    "    train_new_client = dataset_dict['train_new_client'].values\n",
    "    test_new_client = dataset_dict['test_new_client'].values\n",
    "    \n",
    "#     sc = StandardScaler()\n",
    "#     sc.fit(train_x)\n",
    "#     train_x = sc.transform(train_x)\n",
    "#     test_x = sc.transform(test_x)\n",
    "    \n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    predict_train = model.predict_proba(train_x)\n",
    "    predict_test = model.predict_proba(test_x)\n",
    "    \n",
    "    auc_train = roc_auc_score(train_y, predict_train[:, 1])\n",
    "    auc_test = roc_auc_score(test_y, predict_test[:, 1])\n",
    "    \n",
    "    new_auc_train = roc_auc_score(train_y[train_new_client], predict_train[:, 1][train_new_client])\n",
    "    new_auc_test = roc_auc_score(test_y[test_new_client], predict_test[:, 1][test_new_client])\n",
    "\n",
    "    old_auc_train = roc_auc_score(train_y[~train_new_client], predict_train[:, 1][~train_new_client])\n",
    "    old_auc_test = roc_auc_score(test_y[~test_new_client], predict_test[:, 1][~test_new_client])\n",
    "\n",
    "    train_ret_dict = {\n",
    "        prefix : auc_train,\n",
    "        \"new_%s\" % prefix: new_auc_train,\n",
    "        \"old_%s\" % prefix : old_auc_train\n",
    "    }\n",
    "    \n",
    "    test_ret_dict = {\n",
    "        prefix : auc_test,\n",
    "        \"new_%s\" % prefix: new_auc_test,\n",
    "        \"old_%s\" % prefix : old_auc_test\n",
    "    }\n",
    "    return train_ret_dict, test_ret_dict\n",
    "\n",
    "def get_dataset_user(df_feature, target_name, save_name, load_from_file = True):\n",
    "    data_path = VAR_SAVE + save_name + target_name + '.pickle'\n",
    "    if load_from_file and (os.path.exists(data_path)):\n",
    "        return pickle.load(open(data_path, 'rb'))\n",
    "    \n",
    "    select_id = df_feature.index\n",
    "    select_train_id = list( set(select_id) & set(all_train_id) )\n",
    "    select_test_id = list( set(select_id) & set(all_test_id) )\n",
    "    select_df_train = df_feature.loc[select_train_id]\n",
    "    select_df_test = df_feature.loc[select_test_id]\n",
    "    select_train_y = df_master_records.loc[select_train_id][target_name]\n",
    "    select_test_y = df_master_records.loc[select_test_id][target_name]\n",
    "    \n",
    "    ret = {\n",
    "        'train_x' : np.array(select_df_train),\n",
    "        'train_y' : np.array(select_train_y),\n",
    "        'test_x' : np.array(select_df_test),\n",
    "        'test_y' : np.array(select_test_y),\n",
    "        'train_new_client' : df_master_records.loc[select_train_id]['loan_sequence'] == 1,\n",
    "        'test_new_client' : df_master_records.loc[select_test_id]['loan_sequence'] == 1\n",
    "    }, select_df_train, select_df_test\n",
    "    \n",
    "    pickle.dump(ret, open(data_path, 'wb'), protocol = 4)\n",
    "    return ret\n",
    "\n",
    "def get_dataset_app(se_id_pkg, target_name, save_name, load_from_file = True):\n",
    "    \n",
    "    data_path = VAR_SAVE + save_name + target_name + '.pickle'\n",
    "    if(load_from_file and os.path.exists(data_path)):\n",
    "        return pickle.load(open(data_path, 'rb'))\n",
    "\n",
    "    select_id = se_id_pkg.index\n",
    "    select_train_id = list( set(select_id) & set(all_train_id) )\n",
    "    select_test_id = list( set(select_id) & set(all_test_id) )\n",
    "    \n",
    "    app_selection = MutualInfoSelection(3000)\n",
    "    select_train_y = df_master_records.loc[select_train_id][target_name]\n",
    "    \n",
    "    app_selection.fit(se_id_pkg.loc[select_train_id], select_train_y.values)\n",
    "    logging.info('finish fit app_selection :%s' % target_name)\n",
    "    select_df_train = app_selection.transform(se_id_pkg.loc[select_train_id])\n",
    "    select_df_test = app_selection.transform(se_id_pkg.loc[select_test_id])\n",
    "    \n",
    "    select_test_y = df_master_records.loc[select_test_id][target_name]\n",
    "    \n",
    "    ret = {\n",
    "        'train_x' : np.array(select_df_train),\n",
    "        'train_y' : np.array(select_train_y),\n",
    "        'test_x' : np.array(select_df_test),\n",
    "        'test_y' : np.array(select_test_y),\n",
    "        'train_new_client' : df_master_records.loc[select_train_id]['loan_sequence'] == 1,\n",
    "        'test_new_client' : df_master_records.loc[select_test_id]['loan_sequence'] == 1\n",
    "    }, select_df_train, select_df_test\n",
    "    \n",
    "    pickle.dump(ret, open(data_path, 'wb'), protocol = 4)\n",
    "    return ret\n",
    "\n",
    "def get_dataset_userlog(se_id_pkg, target_name, save_name, load_from_file = True):\n",
    "    data_path = VAR_SAVE + save_name + target_name + '.pickle'\n",
    "    if(load_from_file and os.path.exists(data_path)):\n",
    "        return pickle.load(open(data_path, 'rb'))\n",
    "\n",
    "    select_id = se_id_pkg.index\n",
    "    select_train_id = list( set(select_id) & set(all_train_id) )\n",
    "    select_test_id = list( set(select_id) & set(all_test_id) )\n",
    "    \n",
    "    se_train = se_id_pkg.loc[select_train_id]\n",
    "    se_test = se_id_pkg.loc[select_test_id]\n",
    "    \n",
    "    userlog_action = 137\n",
    "    train_np = np.zeros((se_train.shape[0], userlog_action))\n",
    "    test_np = np.zeros((se_test.shape[0], userlog_action))\n",
    "    \n",
    "    for i in tqdm(range(se_train.shape[0])):\n",
    "        for item in se_train.iloc[i]:\n",
    "            train_np[i][item-1] += 1\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(se_test.shape[0])):\n",
    "        for item in se_test.iloc[i]:\n",
    "            test_np[i][item-1] += 1\n",
    "    \n",
    "    select_df_train = pd.DataFrame(train_np, index=se_train.index)\n",
    "    select_df_test = pd.DataFrame(test_np, index=se_test.index)\n",
    "    select_train_y = df_master_records.loc[select_train_id][target_name]\n",
    "    select_test_y = df_master_records.loc[select_test_id][target_name]\n",
    "\n",
    "    ret = {\n",
    "        'train_x' : np.array(select_df_train),\n",
    "        'train_y' : np.array(select_train_y),\n",
    "        'test_x' : np.array(select_df_test),\n",
    "        'test_y' : np.array(select_test_y),\n",
    "        'train_new_client' : df_master_records.loc[select_train_id]['loan_sequence'] == 1,\n",
    "        'test_new_client' : df_master_records.loc[select_test_id]['loan_sequence'] == 1\n",
    "    }, select_df_train, select_df_test\n",
    "    \n",
    "    pickle.dump(ret, open(data_path, 'wb'), protocol = 4)\n",
    "    return ret\n",
    "\n",
    "def get_dataset_merge(df_feature, target_name):\n",
    "    \n",
    "    select_id = df_feature.index\n",
    "    select_train_id = list( set(select_id) & set(all_train_id) )\n",
    "    select_test_id = list( set(select_id) & set(all_test_id) )\n",
    "    select_df_train = df_feature.loc[select_train_id]\n",
    "    select_df_test = df_feature.loc[select_test_id]\n",
    "    select_train_y = df_master_records.loc[select_train_id][target_name]\n",
    "    select_test_y = df_master_records.loc[select_test_id][target_name]\n",
    "    \n",
    "    ret = {\n",
    "        'train_x' : np.array(select_df_train),\n",
    "        'train_y' : np.array(select_train_y),\n",
    "        'test_x' : np.array(select_df_test),\n",
    "        'test_y' : np.array(select_test_y),\n",
    "        'train_new_client' : df_master_records.loc[select_train_id]['loan_sequence'] == 1,\n",
    "        'test_new_client' : df_master_records.loc[select_test_id]['loan_sequence'] == 1\n",
    "    }\n",
    "    \n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 13:51:27,273 - INFO - start train user attribute:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 13:51:31,602 - INFO - start train user attribute:2m30+\n",
      "2020-09-15 13:51:35,948 - INFO - start train user attribute:3m30+\n",
      "2020-09-15 13:51:40,680 - INFO - start train user attribute:4m30+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.625875</td>\n",
       "      <td>0.618872</td>\n",
       "      <td>0.630604</td>\n",
       "      <td>0.626575</td>\n",
       "      <td>0.628666</td>\n",
       "      <td>0.632849</td>\n",
       "      <td>0.610282</td>\n",
       "      <td>0.613838</td>\n",
       "      <td>0.605459</td>\n",
       "      <td>0.611324</td>\n",
       "      <td>0.610458</td>\n",
       "      <td>0.607270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.596442</td>\n",
       "      <td>0.603697</td>\n",
       "      <td>0.626734</td>\n",
       "      <td>0.597912</td>\n",
       "      <td>0.612690</td>\n",
       "      <td>0.603555</td>\n",
       "      <td>0.584626</td>\n",
       "      <td>0.596219</td>\n",
       "      <td>0.587037</td>\n",
       "      <td>0.592436</td>\n",
       "      <td>0.593697</td>\n",
       "      <td>0.598568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.625875   0.618872   0.630604  0.626575   0.628666   0.632849   \n",
       "test   0.596442   0.603697   0.626734  0.597912   0.612690   0.603555   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.610282   0.613838   0.605459  0.611324   0.610458   0.607270  \n",
       "test   0.584626   0.596219   0.587037  0.592436   0.593697   0.598568  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 13:51:44,988 - INFO - start train user attribute:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=100, probability=True, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-15 13:53:27,665 - INFO - start train user attribute:2m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-15 13:55:11,171 - INFO - start train user attribute:3m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-15 13:56:54,717 - INFO - start train user attribute:4m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.466032</td>\n",
       "      <td>0.470679</td>\n",
       "      <td>0.471594</td>\n",
       "      <td>0.515544</td>\n",
       "      <td>0.508919</td>\n",
       "      <td>0.500475</td>\n",
       "      <td>0.508196</td>\n",
       "      <td>0.496428</td>\n",
       "      <td>0.498951</td>\n",
       "      <td>0.500405</td>\n",
       "      <td>0.496168</td>\n",
       "      <td>0.493729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.466145</td>\n",
       "      <td>0.473965</td>\n",
       "      <td>0.455562</td>\n",
       "      <td>0.496123</td>\n",
       "      <td>0.491159</td>\n",
       "      <td>0.500639</td>\n",
       "      <td>0.490338</td>\n",
       "      <td>0.472428</td>\n",
       "      <td>0.492247</td>\n",
       "      <td>0.482682</td>\n",
       "      <td>0.473608</td>\n",
       "      <td>0.481206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.466032   0.470679   0.471594  0.515544   0.508919   0.500475   \n",
       "test   0.466145   0.473965   0.455562  0.496123   0.491159   0.500639   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.508196   0.496428   0.498951  0.500405   0.496168   0.493729  \n",
       "test   0.490338   0.472428   0.492247  0.482682   0.473608   0.481206  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 13:58:38,219 - INFO - start train user attribute:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 14:04:18,796 - INFO - start train user attribute:2m30+\n",
      "2020-09-15 14:12:49,012 - INFO - start train user attribute:3m30+\n",
      "2020-09-15 14:25:36,471 - INFO - start train user attribute:4m30+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.690940</td>\n",
       "      <td>0.671622</td>\n",
       "      <td>0.709116</td>\n",
       "      <td>0.672593</td>\n",
       "      <td>0.663464</td>\n",
       "      <td>0.687571</td>\n",
       "      <td>0.657897</td>\n",
       "      <td>0.647829</td>\n",
       "      <td>0.662453</td>\n",
       "      <td>0.656693</td>\n",
       "      <td>0.642248</td>\n",
       "      <td>0.663474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.578484</td>\n",
       "      <td>0.578145</td>\n",
       "      <td>0.581842</td>\n",
       "      <td>0.592899</td>\n",
       "      <td>0.603298</td>\n",
       "      <td>0.603046</td>\n",
       "      <td>0.588560</td>\n",
       "      <td>0.592383</td>\n",
       "      <td>0.592671</td>\n",
       "      <td>0.595166</td>\n",
       "      <td>0.590465</td>\n",
       "      <td>0.605129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.690940   0.671622   0.709116  0.672593   0.663464   0.687571   \n",
       "test   0.578484   0.578145   0.581842  0.592899   0.603298   0.603046   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.657897   0.647829   0.662453  0.656693   0.642248   0.663474  \n",
       "test   0.588560   0.592383   0.592671  0.595166   0.590465   0.605129  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 14:32:52,938 - INFO - start train user attribute:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=0, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 14:33:58,922 - INFO - start train user attribute:2m30+\n",
      "2020-09-15 14:35:04,572 - INFO - start train user attribute:3m30+\n",
      "2020-09-15 14:36:09,905 - INFO - start train user attribute:4m30+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.638518</td>\n",
       "      <td>0.626485</td>\n",
       "      <td>0.644690</td>\n",
       "      <td>0.634032</td>\n",
       "      <td>0.633305</td>\n",
       "      <td>0.641076</td>\n",
       "      <td>0.617661</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>0.613377</td>\n",
       "      <td>0.618672</td>\n",
       "      <td>0.614344</td>\n",
       "      <td>0.615477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.601561</td>\n",
       "      <td>0.606003</td>\n",
       "      <td>0.626293</td>\n",
       "      <td>0.604467</td>\n",
       "      <td>0.617741</td>\n",
       "      <td>0.609384</td>\n",
       "      <td>0.590246</td>\n",
       "      <td>0.600103</td>\n",
       "      <td>0.592491</td>\n",
       "      <td>0.597673</td>\n",
       "      <td>0.597783</td>\n",
       "      <td>0.603107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.638518   0.626485   0.644690  0.634032   0.633305   0.641076   \n",
       "test   0.601561   0.606003   0.626293  0.604467   0.617741   0.609384   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.617661   0.618238   0.613377  0.618672   0.614344   0.615477  \n",
       "test   0.590246   0.600103   0.592491  0.597673   0.597783   0.603107  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_user_one_hot = get_master_user_discrete(df_master_records)\n",
    "user_train_df_list, user_test_df_list = [], []\n",
    "\n",
    "for i, model in enumerate([\n",
    "    linear_model.LogisticRegression(), \n",
    "    svm.SVC(probability=True, max_iter = 100),\n",
    "    neural_network.MLPClassifier(random_state=0, max_iter=300),\n",
    "    ensemble.GradientBoostingClassifier(random_state=0),\n",
    "]):\n",
    "    print(model)\n",
    "    \n",
    "    train_ret_dict, test_ret_dict = {}, {}\n",
    "    \n",
    "\n",
    "    for j, target_name in enumerate(['1m30+', '2m30+', '3m30+', '4m30+']):\n",
    "        user_dataset_dict, user_train_df, user_test_df = get_dataset_user(df_user_one_hot, 'target_%s' % target_name, 'user_info_')\n",
    "        if i == 0:\n",
    "            user_train_df_list.append(user_train_df)\n",
    "            user_test_df_list.append(user_test_df)\n",
    "        \n",
    "        logging.info('start train user attribute:%s' % target_name)\n",
    "        use_rets = train(target_name, user_dataset_dict, model)\n",
    "        train_ret_dict.update(use_rets[0])\n",
    "        test_ret_dict.update(use_rets[1])\n",
    "    \n",
    "    df_ret = pd.DataFrame([\n",
    "        train_ret_dict, test_ret_dict\n",
    "    ], index = ['train', 'test'])\n",
    "    ipd.display(df_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 14:37:15,335 - INFO - start train app list:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 15:08:27,910 - INFO - finish fit app_selection :target_1m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-15 15:09:43,105 - INFO - start train app list:2m30+\n",
      "2020-09-15 15:41:07,197 - INFO - finish fit app_selection :target_2m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-15 15:42:26,777 - INFO - start train app list:3m30+\n",
      "2020-09-15 16:13:51,380 - INFO - finish fit app_selection :target_3m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-15 16:15:03,692 - INFO - start train app list:4m30+\n",
      "2020-09-15 16:46:40,936 - INFO - finish fit app_selection :target_4m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.795124</td>\n",
       "      <td>0.756913</td>\n",
       "      <td>0.826056</td>\n",
       "      <td>0.762485</td>\n",
       "      <td>0.718350</td>\n",
       "      <td>0.795502</td>\n",
       "      <td>0.758677</td>\n",
       "      <td>0.707241</td>\n",
       "      <td>0.794341</td>\n",
       "      <td>0.752685</td>\n",
       "      <td>0.699539</td>\n",
       "      <td>0.784836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.624672</td>\n",
       "      <td>0.590205</td>\n",
       "      <td>0.630476</td>\n",
       "      <td>0.632811</td>\n",
       "      <td>0.612104</td>\n",
       "      <td>0.624475</td>\n",
       "      <td>0.630766</td>\n",
       "      <td>0.601225</td>\n",
       "      <td>0.628878</td>\n",
       "      <td>0.624073</td>\n",
       "      <td>0.595976</td>\n",
       "      <td>0.616754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.795124   0.756913   0.826056  0.762485   0.718350   0.795502   \n",
       "test   0.624672   0.590205   0.630476  0.632811   0.612104   0.624475   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.758677   0.707241   0.794341  0.752685   0.699539   0.784836  \n",
       "test   0.630766   0.601225   0.628878  0.624073   0.595976   0.616754  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 16:47:49,212 - INFO - start train app list:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=100, probability=True, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-15 16:59:11,748 - INFO - start train app list:2m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-15 17:10:36,598 - INFO - start train app list:3m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-15 17:21:59,872 - INFO - start train app list:4m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.412215</td>\n",
       "      <td>0.432604</td>\n",
       "      <td>0.350330</td>\n",
       "      <td>0.415563</td>\n",
       "      <td>0.441434</td>\n",
       "      <td>0.374660</td>\n",
       "      <td>0.417187</td>\n",
       "      <td>0.442403</td>\n",
       "      <td>0.382053</td>\n",
       "      <td>0.420171</td>\n",
       "      <td>0.445889</td>\n",
       "      <td>0.385122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.484909</td>\n",
       "      <td>0.492839</td>\n",
       "      <td>0.479898</td>\n",
       "      <td>0.473113</td>\n",
       "      <td>0.472893</td>\n",
       "      <td>0.487103</td>\n",
       "      <td>0.474587</td>\n",
       "      <td>0.472199</td>\n",
       "      <td>0.489061</td>\n",
       "      <td>0.475069</td>\n",
       "      <td>0.476781</td>\n",
       "      <td>0.481612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.412215   0.432604   0.350330  0.415563   0.441434   0.374660   \n",
       "test   0.484909   0.492839   0.479898  0.473113   0.472893   0.487103   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.417187   0.442403   0.382053  0.420171   0.445889   0.385122  \n",
       "test   0.474587   0.472199   0.489061  0.475069   0.476781   0.481612  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 17:33:21,327 - INFO - start train app list:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 17:36:45,995 - INFO - start train app list:2m30+\n",
      "2020-09-15 17:39:51,964 - INFO - start train app list:3m30+\n",
      "2020-09-15 17:43:15,253 - INFO - start train app list:4m30+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.977760</td>\n",
       "      <td>0.977451</td>\n",
       "      <td>0.969665</td>\n",
       "      <td>0.982641</td>\n",
       "      <td>0.980343</td>\n",
       "      <td>0.983993</td>\n",
       "      <td>0.981999</td>\n",
       "      <td>0.982164</td>\n",
       "      <td>0.978482</td>\n",
       "      <td>0.978154</td>\n",
       "      <td>0.979823</td>\n",
       "      <td>0.972661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.577342</td>\n",
       "      <td>0.557984</td>\n",
       "      <td>0.569117</td>\n",
       "      <td>0.613408</td>\n",
       "      <td>0.600338</td>\n",
       "      <td>0.607838</td>\n",
       "      <td>0.632747</td>\n",
       "      <td>0.608012</td>\n",
       "      <td>0.639399</td>\n",
       "      <td>0.639594</td>\n",
       "      <td>0.613674</td>\n",
       "      <td>0.641670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.977760   0.977451   0.969665  0.982641   0.980343   0.983993   \n",
       "test   0.577342   0.557984   0.569117  0.613408   0.600338   0.607838   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.981999   0.982164   0.978482  0.978154   0.979823   0.972661  \n",
       "test   0.632747   0.608012   0.639399  0.639594   0.613674   0.641670  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 17:46:21,479 - INFO - start train app list:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=0, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 18:10:31,529 - INFO - start train app list:2m30+\n",
      "2020-09-15 18:38:39,973 - INFO - start train app list:3m30+\n",
      "2020-09-15 19:07:17,146 - INFO - start train app list:4m30+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.677222</td>\n",
       "      <td>0.634601</td>\n",
       "      <td>0.722254</td>\n",
       "      <td>0.685252</td>\n",
       "      <td>0.650932</td>\n",
       "      <td>0.715057</td>\n",
       "      <td>0.680150</td>\n",
       "      <td>0.640452</td>\n",
       "      <td>0.703444</td>\n",
       "      <td>0.674307</td>\n",
       "      <td>0.634275</td>\n",
       "      <td>0.691556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.612065</td>\n",
       "      <td>0.584718</td>\n",
       "      <td>0.591118</td>\n",
       "      <td>0.642356</td>\n",
       "      <td>0.622704</td>\n",
       "      <td>0.641459</td>\n",
       "      <td>0.629333</td>\n",
       "      <td>0.604197</td>\n",
       "      <td>0.624565</td>\n",
       "      <td>0.619844</td>\n",
       "      <td>0.595450</td>\n",
       "      <td>0.609771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.677222   0.634601   0.722254  0.685252   0.650932   0.715057   \n",
       "test   0.612065   0.584718   0.591118  0.642356   0.622704   0.641459   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.680150   0.640452   0.703444  0.674307   0.634275   0.691556  \n",
       "test   0.629333   0.604197   0.624565  0.619844   0.595450   0.609771  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "applist_train_df_list, applist_test_df_list = [], []\n",
    "\n",
    "for i, model in enumerate([\n",
    "    linear_model.LogisticRegression(), \n",
    "    svm.SVC(probability=True, max_iter = 100),\n",
    "    neural_network.MLPClassifier(random_state=0, max_iter=300),\n",
    "    ensemble.GradientBoostingClassifier(random_state=0), \n",
    "]):\n",
    "    print(model)\n",
    "    train_ret_dict, test_ret_dict = {}, {}\n",
    "\n",
    "    for j, target_name in enumerate(['1m30+', '2m30+', '3m30+', '4m30+']):\n",
    "        logging.info('start train app list:%s' % target_name)\n",
    "        app_list_dataset_dict, applist_train_df, applist_test_df = \\\n",
    "        get_dataset_app(se_id_install_list, 'target_%s' % target_name, 'app_list_')\n",
    "\n",
    "        if i == 0:\n",
    "            applist_train_df_list.append(applist_train_df)\n",
    "            applist_test_df_list.append(applist_test_df)\n",
    "            \n",
    "        use_rets = train(target_name, app_list_dataset_dict, model)\n",
    "        train_ret_dict.update(use_rets[0])\n",
    "        test_ret_dict.update(use_rets[1])\n",
    "    df_ret = pd.DataFrame([\n",
    "        train_ret_dict, test_ret_dict\n",
    "    ], index = ['train', 'test'])\n",
    "    ipd.display(df_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App install behave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 19:37:38,760 - INFO - start train app behave:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-15 20:46:25,740 - INFO - finish fit app_selection :target_1m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-15 20:47:43,176 - INFO - start train app behave:2m30+\n",
      "2020-09-15 21:55:34,190 - INFO - finish fit app_selection :target_2m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-15 21:56:55,188 - INFO - start train app behave:3m30+\n",
      "2020-09-15 23:06:17,711 - INFO - finish fit app_selection :target_3m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-15 23:07:33,045 - INFO - start train app behave:4m30+\n",
      "2020-09-16 00:17:54,794 - INFO - finish fit app_selection :target_4m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.746595</td>\n",
       "      <td>0.716207</td>\n",
       "      <td>0.788276</td>\n",
       "      <td>0.710741</td>\n",
       "      <td>0.671820</td>\n",
       "      <td>0.738240</td>\n",
       "      <td>0.706321</td>\n",
       "      <td>0.665432</td>\n",
       "      <td>0.733955</td>\n",
       "      <td>0.700920</td>\n",
       "      <td>0.658793</td>\n",
       "      <td>0.727018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.586649</td>\n",
       "      <td>0.557882</td>\n",
       "      <td>0.614600</td>\n",
       "      <td>0.592539</td>\n",
       "      <td>0.570734</td>\n",
       "      <td>0.586963</td>\n",
       "      <td>0.584595</td>\n",
       "      <td>0.562763</td>\n",
       "      <td>0.578391</td>\n",
       "      <td>0.584154</td>\n",
       "      <td>0.563281</td>\n",
       "      <td>0.577076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.746595   0.716207   0.788276  0.710741   0.671820   0.738240   \n",
       "test   0.586649   0.557882   0.614600  0.592539   0.570734   0.586963   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.706321   0.665432   0.733955  0.700920   0.658793   0.727018  \n",
       "test   0.584595   0.562763   0.578391  0.584154   0.563281   0.577076  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 00:19:14,328 - INFO - start train app behave:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=100, probability=True, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-16 00:34:58,436 - INFO - start train app behave:2m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-16 00:49:59,792 - INFO - start train app behave:3m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-16 01:03:59,986 - INFO - start train app behave:4m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.425224</td>\n",
       "      <td>0.445364</td>\n",
       "      <td>0.385909</td>\n",
       "      <td>0.436548</td>\n",
       "      <td>0.455509</td>\n",
       "      <td>0.418632</td>\n",
       "      <td>0.438638</td>\n",
       "      <td>0.457111</td>\n",
       "      <td>0.422337</td>\n",
       "      <td>0.440876</td>\n",
       "      <td>0.461306</td>\n",
       "      <td>0.428274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.474151</td>\n",
       "      <td>0.489914</td>\n",
       "      <td>0.454706</td>\n",
       "      <td>0.458818</td>\n",
       "      <td>0.463325</td>\n",
       "      <td>0.466735</td>\n",
       "      <td>0.463404</td>\n",
       "      <td>0.466753</td>\n",
       "      <td>0.471079</td>\n",
       "      <td>0.465130</td>\n",
       "      <td>0.467310</td>\n",
       "      <td>0.476979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.425224   0.445364   0.385909  0.436548   0.455509   0.418632   \n",
       "test   0.474151   0.489914   0.454706  0.458818   0.463325   0.466735   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.438638   0.457111   0.422337  0.440876   0.461306   0.428274  \n",
       "test   0.463404   0.466753   0.471079  0.465130   0.467310   0.476979  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 01:17:55,954 - INFO - start train app behave:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 01:21:05,445 - INFO - start train app behave:2m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-16 02:23:28,761 - INFO - start train app behave:3m30+\n",
      "2020-09-16 02:49:15,849 - INFO - start train app behave:4m30+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.967563</td>\n",
       "      <td>0.968410</td>\n",
       "      <td>0.957748</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.996083</td>\n",
       "      <td>0.993663</td>\n",
       "      <td>0.993781</td>\n",
       "      <td>0.994940</td>\n",
       "      <td>0.992477</td>\n",
       "      <td>0.993694</td>\n",
       "      <td>0.995779</td>\n",
       "      <td>0.991014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.548351</td>\n",
       "      <td>0.534258</td>\n",
       "      <td>0.565948</td>\n",
       "      <td>0.598249</td>\n",
       "      <td>0.587642</td>\n",
       "      <td>0.594681</td>\n",
       "      <td>0.615758</td>\n",
       "      <td>0.599314</td>\n",
       "      <td>0.616125</td>\n",
       "      <td>0.623532</td>\n",
       "      <td>0.597470</td>\n",
       "      <td>0.633484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.967563   0.968410   0.957748  0.995129   0.996083   0.993663   \n",
       "test   0.548351   0.534258   0.565948  0.598249   0.587642   0.594681   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.993781   0.994940   0.992477  0.993694   0.995779   0.991014  \n",
       "test   0.615758   0.599314   0.616125  0.623532   0.597470   0.633484  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 03:39:24,172 - INFO - start train app behave:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=0, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 04:10:06,121 - INFO - start train app behave:2m30+\n",
      "2020-09-16 04:41:45,827 - INFO - start train app behave:3m30+\n",
      "2020-09-16 05:13:32,509 - INFO - start train app behave:4m30+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.627226</td>\n",
       "      <td>0.589601</td>\n",
       "      <td>0.651348</td>\n",
       "      <td>0.634683</td>\n",
       "      <td>0.603308</td>\n",
       "      <td>0.651643</td>\n",
       "      <td>0.630418</td>\n",
       "      <td>0.596342</td>\n",
       "      <td>0.644108</td>\n",
       "      <td>0.627819</td>\n",
       "      <td>0.597356</td>\n",
       "      <td>0.634972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.592185</td>\n",
       "      <td>0.548605</td>\n",
       "      <td>0.611608</td>\n",
       "      <td>0.594711</td>\n",
       "      <td>0.565668</td>\n",
       "      <td>0.590668</td>\n",
       "      <td>0.588176</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0.575235</td>\n",
       "      <td>0.585659</td>\n",
       "      <td>0.563029</td>\n",
       "      <td>0.569546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.627226   0.589601   0.651348  0.634683   0.603308   0.651643   \n",
       "test   0.592185   0.548605   0.611608  0.594711   0.565668   0.590668   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.630418   0.596342   0.644108  0.627819   0.597356   0.634972  \n",
       "test   0.588176   0.562709   0.575235  0.585659   0.563029   0.569546  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "appbehave_df_train, appbehave_df_test = [], []\n",
    "\n",
    "for i, model in enumerate([\n",
    "    linear_model.LogisticRegression(),\n",
    "    svm.SVC(probability=True, max_iter = 100),\n",
    "    neural_network.MLPClassifier(random_state=0, max_iter=300),\n",
    "    ensemble.GradientBoostingClassifier(random_state=0),\n",
    "]):\n",
    "    print(model)\n",
    "    train_ret_dict, test_ret_dict = {}, {}\n",
    "    for j, target_name in enumerate(['1m30+', '2m30+', '3m30+', '4m30+']):\n",
    "        logging.info('start train app behave:%s' % target_name)\n",
    "        app_behave_dataset_dict, behave_df_train, behave_df_test = \\\n",
    "            get_dataset_app(df_install_behave['pkg_id'], 'target_%s' % target_name, 'app_behave_')\n",
    "\n",
    "        if i == 0:\n",
    "            appbehave_df_train.append(behave_df_train)\n",
    "            appbehave_df_test.append(behave_df_test)\n",
    "            \n",
    "        use_rets = train(target_name, app_behave_dataset_dict, model)\n",
    "        train_ret_dict.update(use_rets[0])\n",
    "        test_ret_dict.update(use_rets[1])\n",
    "    df_ret = pd.DataFrame([\n",
    "        train_ret_dict, test_ret_dict\n",
    "    ], index = ['train', 'test'])\n",
    "    ipd.display(df_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## userlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 05:45:12,584 - INFO - start train user log:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb16faab4b45459c92a6f928bf144ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=253808), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0dc1251fb742218de2949b89b06f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=65313), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-16 05:47:41,695 - INFO - start train user log:2m30+\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af3c403692645f89d4e01528b2a2497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=253808), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6042ae1c8b24bb6b645d7389dd36cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=65313), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-16 05:50:09,795 - INFO - start train user log:3m30+\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d84c113e7be44b9aa6c3c7d5cbff54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=253808), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332f1386a725457bb4201df6c20240dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=65313), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-16 05:52:40,478 - INFO - start train user log:4m30+\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33bf9c0778d44bfc8a05852de2126684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=253808), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda6c1a0219446789754ed4bf3651817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=65313), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.670357</td>\n",
       "      <td>0.647684</td>\n",
       "      <td>0.692049</td>\n",
       "      <td>0.686689</td>\n",
       "      <td>0.684467</td>\n",
       "      <td>0.712586</td>\n",
       "      <td>0.657725</td>\n",
       "      <td>0.660818</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>0.640196</td>\n",
       "      <td>0.651464</td>\n",
       "      <td>0.633464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.677535</td>\n",
       "      <td>0.649340</td>\n",
       "      <td>0.685492</td>\n",
       "      <td>0.694044</td>\n",
       "      <td>0.689807</td>\n",
       "      <td>0.704260</td>\n",
       "      <td>0.653343</td>\n",
       "      <td>0.659637</td>\n",
       "      <td>0.650362</td>\n",
       "      <td>0.633021</td>\n",
       "      <td>0.647971</td>\n",
       "      <td>0.622910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.670357   0.647684   0.692049  0.686689   0.684467   0.712586   \n",
       "test   0.677535   0.649340   0.685492  0.694044   0.689807   0.704260   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.657725   0.660818   0.663594  0.640196   0.651464   0.633464  \n",
       "test   0.653343   0.659637   0.650362  0.633021   0.647971   0.622910  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 05:55:09,652 - INFO - start train user log:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=100, probability=True, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-16 05:56:49,165 - INFO - start train user log:2m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-16 05:58:27,487 - INFO - start train user log:3m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-16 06:00:04,330 - INFO - start train user log:4m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.468255</td>\n",
       "      <td>0.413685</td>\n",
       "      <td>0.350659</td>\n",
       "      <td>0.418801</td>\n",
       "      <td>0.370847</td>\n",
       "      <td>0.351716</td>\n",
       "      <td>0.438333</td>\n",
       "      <td>0.393950</td>\n",
       "      <td>0.381842</td>\n",
       "      <td>0.443509</td>\n",
       "      <td>0.400053</td>\n",
       "      <td>0.400339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.423146</td>\n",
       "      <td>0.380822</td>\n",
       "      <td>0.302727</td>\n",
       "      <td>0.394535</td>\n",
       "      <td>0.358702</td>\n",
       "      <td>0.340035</td>\n",
       "      <td>0.418202</td>\n",
       "      <td>0.383935</td>\n",
       "      <td>0.371883</td>\n",
       "      <td>0.426765</td>\n",
       "      <td>0.389576</td>\n",
       "      <td>0.394943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.468255   0.413685   0.350659  0.418801   0.370847   0.351716   \n",
       "test   0.423146   0.380822   0.302727  0.394535   0.358702   0.340035   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.438333   0.393950   0.381842  0.443509   0.400053   0.400339  \n",
       "test   0.418202   0.383935   0.371883  0.426765   0.389576   0.394943  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 06:01:42,575 - INFO - start train user log:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 06:19:03,583 - INFO - start train user log:2m30+\n",
      "2020-09-16 06:33:51,203 - INFO - start train user log:3m30+\n",
      "2020-09-16 06:45:17,147 - INFO - start train user log:4m30+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.901060</td>\n",
       "      <td>0.861956</td>\n",
       "      <td>0.951442</td>\n",
       "      <td>0.847345</td>\n",
       "      <td>0.801905</td>\n",
       "      <td>0.896954</td>\n",
       "      <td>0.822848</td>\n",
       "      <td>0.77205</td>\n",
       "      <td>0.859428</td>\n",
       "      <td>0.809958</td>\n",
       "      <td>0.763863</td>\n",
       "      <td>0.843430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.559621</td>\n",
       "      <td>0.529833</td>\n",
       "      <td>0.505122</td>\n",
       "      <td>0.622999</td>\n",
       "      <td>0.606327</td>\n",
       "      <td>0.617535</td>\n",
       "      <td>0.622039</td>\n",
       "      <td>0.60529</td>\n",
       "      <td>0.619803</td>\n",
       "      <td>0.618987</td>\n",
       "      <td>0.609627</td>\n",
       "      <td>0.617266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.901060   0.861956   0.951442  0.847345   0.801905   0.896954   \n",
       "test   0.559621   0.529833   0.505122  0.622999   0.606327   0.617535   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.822848    0.77205   0.859428  0.809958   0.763863   0.843430  \n",
       "test   0.622039    0.60529   0.619803  0.618987   0.609627   0.617266  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 06:56:31,720 - INFO - start train user log:1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=0, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 07:00:53,622 - INFO - start train user log:2m30+\n",
      "2020-09-16 07:05:09,699 - INFO - start train user log:3m30+\n",
      "2020-09-16 07:09:24,519 - INFO - start train user log:4m30+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.712533</td>\n",
       "      <td>0.670420</td>\n",
       "      <td>0.748762</td>\n",
       "      <td>0.715196</td>\n",
       "      <td>0.70528</td>\n",
       "      <td>0.745675</td>\n",
       "      <td>0.685342</td>\n",
       "      <td>0.678060</td>\n",
       "      <td>0.694815</td>\n",
       "      <td>0.668651</td>\n",
       "      <td>0.668979</td>\n",
       "      <td>0.665436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.687336</td>\n",
       "      <td>0.652753</td>\n",
       "      <td>0.704740</td>\n",
       "      <td>0.702833</td>\n",
       "      <td>0.69805</td>\n",
       "      <td>0.708206</td>\n",
       "      <td>0.661784</td>\n",
       "      <td>0.665527</td>\n",
       "      <td>0.658889</td>\n",
       "      <td>0.642620</td>\n",
       "      <td>0.654038</td>\n",
       "      <td>0.634551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.712533   0.670420   0.748762  0.715196    0.70528   0.745675   \n",
       "test   0.687336   0.652753   0.704740  0.702833    0.69805   0.708206   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.685342   0.678060   0.694815  0.668651   0.668979   0.665436  \n",
       "test   0.661784   0.665527   0.658889  0.642620   0.654038   0.634551  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "userlog_df_train_list, userlog_df_test_list, userlog_dataset_dict_list = [], [], []\n",
    "for i, model in enumerate([\n",
    "    linear_model.LogisticRegression(), \n",
    "    svm.SVC(probability=True, max_iter = 100),\n",
    "    neural_network.MLPClassifier(random_state=0, max_iter=300),\n",
    "    ensemble.GradientBoostingClassifier(random_state=0),\n",
    "]):\n",
    "    print(model)\n",
    "    \n",
    "    train_ret_dict, test_ret_dict = {}, {}\n",
    "    for j,target_name in enumerate(['1m30+', '2m30+', '3m30+', '4m30+']):\n",
    "        logging.info('start train user log:%s' % target_name)\n",
    "        userlog_dataset_dict, userlog_df_train, userlog_df_test = \\\n",
    "        get_dataset_userlog(se_userlog_cross, 'target_%s' % target_name, 'user_log_')\n",
    "\n",
    "        if  i == 0:\n",
    "            userlog_df_train_list.append(userlog_df_train)\n",
    "            userlog_df_test_list.append(userlog_df_test)\n",
    "    \n",
    "        use_rets = train(target_name, userlog_dataset_dict, model)\n",
    "        train_ret_dict.update(use_rets[0])\n",
    "        test_ret_dict.update(use_rets[1])\n",
    "    df_ret = pd.DataFrame([\n",
    "        train_ret_dict, test_ret_dict\n",
    "    ], index = ['train', 'test'])\n",
    "    ipd.display(df_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge (drop missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df_list(user_df_list, applist_df_list, appbehave_df, userlog_list, drop = True):\n",
    "    df_merge_list = []\n",
    "    logging.info('start merge')\n",
    "    for (df_user_attribute, df_applist, df_appbehave, df_userlog) in zip(user_df_list, applist_df_list, appbehave_df, userlog_list):\n",
    "        df_merge = pd.concat([df_user_attribute, df_applist, df_appbehave, df_userlog], axis=1)\n",
    "        if drop:\n",
    "            df_merge = df_merge.dropna()\n",
    "        else:\n",
    "            df_merge = df_merge.fillna(0)\n",
    "        df_merge_list.append(df_merge)\n",
    "    logging.info('finish merge')\n",
    "    return df_merge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_train_list = merge_df_list(user_train_df_list, applist_train_df_list, appbehave_df_train, userlog_df_train_list)\n",
    "df_merge_test_list = merge_df_list(user_test_df_list, applist_test_df_list, appbehave_df_test, userlog_df_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 07:18:26,900 - INFO - start train merge attribute:1m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-16 07:19:29,479 - INFO - start train merge attribute:2m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-16 07:20:45,499 - INFO - start train merge attribute:3m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-16 07:21:53,254 - INFO - start train merge attribute:4m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.911924</td>\n",
       "      <td>0.888882</td>\n",
       "      <td>0.934762</td>\n",
       "      <td>0.869140</td>\n",
       "      <td>0.828170</td>\n",
       "      <td>0.897205</td>\n",
       "      <td>0.859146</td>\n",
       "      <td>0.811956</td>\n",
       "      <td>0.888970</td>\n",
       "      <td>0.856215</td>\n",
       "      <td>0.804395</td>\n",
       "      <td>0.885391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.637375</td>\n",
       "      <td>0.602558</td>\n",
       "      <td>0.664680</td>\n",
       "      <td>0.685467</td>\n",
       "      <td>0.662471</td>\n",
       "      <td>0.690375</td>\n",
       "      <td>0.670715</td>\n",
       "      <td>0.649591</td>\n",
       "      <td>0.665974</td>\n",
       "      <td>0.669940</td>\n",
       "      <td>0.648682</td>\n",
       "      <td>0.662887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.911924   0.888882   0.934762  0.869140   0.828170   0.897205   \n",
       "test   0.637375   0.602558   0.664680  0.685467   0.662471   0.690375   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.859146   0.811956   0.888970  0.856215   0.804395   0.885391  \n",
       "test   0.670715   0.649591   0.665974  0.669940   0.648682   0.662887  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=100, probability=True, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 07:23:09,980 - INFO - start train merge attribute:1m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-16 07:39:08,523 - INFO - start train merge attribute:2m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-16 07:55:35,885 - INFO - start train merge attribute:3m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-16 08:13:11,013 - INFO - start train merge attribute:4m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.334913</td>\n",
       "      <td>0.369515</td>\n",
       "      <td>0.271054</td>\n",
       "      <td>0.357524</td>\n",
       "      <td>0.396753</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.357186</td>\n",
       "      <td>0.396335</td>\n",
       "      <td>0.326581</td>\n",
       "      <td>0.368850</td>\n",
       "      <td>0.407499</td>\n",
       "      <td>0.340712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.459456</td>\n",
       "      <td>0.475816</td>\n",
       "      <td>0.428783</td>\n",
       "      <td>0.441378</td>\n",
       "      <td>0.446286</td>\n",
       "      <td>0.455207</td>\n",
       "      <td>0.438533</td>\n",
       "      <td>0.439692</td>\n",
       "      <td>0.452909</td>\n",
       "      <td>0.448837</td>\n",
       "      <td>0.450406</td>\n",
       "      <td>0.461057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.334913   0.369515   0.271054  0.357524   0.396753   0.329146   \n",
       "test   0.459456   0.475816   0.428783  0.441378   0.446286   0.455207   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.357186   0.396335   0.326581  0.368850   0.407499   0.340712  \n",
       "test   0.438533   0.439692   0.452909  0.448837   0.450406   0.461057  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 08:31:04,528 - INFO - start train merge attribute:1m30+\n",
      "2020-09-16 08:35:22,359 - INFO - start train merge attribute:2m30+\n",
      "2020-09-16 08:46:00,958 - INFO - start train merge attribute:3m30+\n",
      "2020-09-16 08:59:28,221 - INFO - start train merge attribute:4m30+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.992900</td>\n",
       "      <td>0.994499</td>\n",
       "      <td>0.986414</td>\n",
       "      <td>0.999261</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.998661</td>\n",
       "      <td>0.998939</td>\n",
       "      <td>0.999435</td>\n",
       "      <td>0.998288</td>\n",
       "      <td>0.999068</td>\n",
       "      <td>0.999694</td>\n",
       "      <td>0.998340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.638879</td>\n",
       "      <td>0.614047</td>\n",
       "      <td>0.648293</td>\n",
       "      <td>0.680080</td>\n",
       "      <td>0.663298</td>\n",
       "      <td>0.695996</td>\n",
       "      <td>0.673979</td>\n",
       "      <td>0.649748</td>\n",
       "      <td>0.683797</td>\n",
       "      <td>0.682228</td>\n",
       "      <td>0.664569</td>\n",
       "      <td>0.681397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.992900   0.994499   0.986414  0.999261   0.999756   0.998661   \n",
       "test   0.638879   0.614047   0.648293  0.680080   0.663298   0.695996   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.998939   0.999435   0.998288  0.999068   0.999694   0.998340  \n",
       "test   0.673979   0.649748   0.683797  0.682228   0.664569   0.681397  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=0, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 09:15:42,950 - INFO - start train merge attribute:1m30+\n",
      "2020-09-16 09:29:40,542 - INFO - start train merge attribute:2m30+\n",
      "2020-09-16 09:44:18,154 - INFO - start train merge attribute:3m30+\n",
      "2020-09-16 09:59:03,332 - INFO - start train merge attribute:4m30+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.752037</td>\n",
       "      <td>0.704672</td>\n",
       "      <td>0.823028</td>\n",
       "      <td>0.764735</td>\n",
       "      <td>0.732800</td>\n",
       "      <td>0.805373</td>\n",
       "      <td>0.746147</td>\n",
       "      <td>0.710043</td>\n",
       "      <td>0.772522</td>\n",
       "      <td>0.743735</td>\n",
       "      <td>0.708155</td>\n",
       "      <td>0.762506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.694404</td>\n",
       "      <td>0.649703</td>\n",
       "      <td>0.710970</td>\n",
       "      <td>0.719814</td>\n",
       "      <td>0.701277</td>\n",
       "      <td>0.728671</td>\n",
       "      <td>0.687447</td>\n",
       "      <td>0.672858</td>\n",
       "      <td>0.680801</td>\n",
       "      <td>0.686749</td>\n",
       "      <td>0.675220</td>\n",
       "      <td>0.680211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.752037   0.704672   0.823028  0.764735   0.732800   0.805373   \n",
       "test   0.694404   0.649703   0.710970  0.719814   0.701277   0.728671   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.746147   0.710043   0.772522  0.743735   0.708155   0.762506  \n",
       "test   0.687447   0.672858   0.680801  0.686749   0.675220   0.680211  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, model in enumerate([\n",
    "    linear_model.LogisticRegression(), \n",
    "    svm.SVC(probability=True, max_iter = 100),\n",
    "    neural_network.MLPClassifier(random_state=0, max_iter=300),\n",
    "    ensemble.GradientBoostingClassifier(random_state=0),\n",
    "]):\n",
    "    print(model)\n",
    "    train_ret_dict, test_ret_dict = {}, {}\n",
    "    for j, target_name in enumerate(['1m30+', '2m30+', '3m30+', '4m30+']):\n",
    "        df_merge = pd.concat([df_merge_train_list[j], df_merge_test_list[j]])\n",
    "        merge_dataset = get_dataset_merge(df_merge, 'target_%s' % target_name)\n",
    "        logging.info('start train merge attribute:%s' % target_name)\n",
    "        merge_rets = train(target_name, merge_dataset, model)\n",
    "        train_ret_dict.update(merge_rets[0])\n",
    "        test_ret_dict.update(merge_rets[1])\n",
    "\n",
    "    df_ret = pd.DataFrame([\n",
    "        train_ret_dict, test_ret_dict\n",
    "    ], index = ['train', 'test'])\n",
    "    ipd.display(df_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge fill zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 10:13:46,458 - INFO - start merge\n"
     ]
    }
   ],
   "source": [
    "# df_merge_train_list = merge_df_list(user_train_df_list, applist_train_df_list, appbehave_df_train, userlog_df_train_list, False)\n",
    "# df_merge_test_list = merge_df_list(user_test_df_list, applist_test_df_list, appbehave_df_test, userlog_df_test_list,  False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_dataset_list = []\n",
    "# for i, model in enumerate([\n",
    "#     linear_model.LogisticRegression(), \n",
    "#     svm.SVC(probability=True, max_iter = 100),\n",
    "#     neural_network.MLPClassifier(random_state=0, max_iter=300),\n",
    "#     ensemble.GradientBoostingClassifier(random_state=0),\n",
    "# ]):\n",
    "#     print(model)\n",
    "#     train_ret_dict, test_ret_dict = {}, {}\n",
    "#     for j, target_name in enumerate(['1m30+', '2m30+', '3m30+', '4m30+']):\n",
    "#         df_merge = pd.concat([df_merge_train_list[j], df_merge_test_list[j]])\n",
    "#         merge_dataset = get_dataset_merge(df_merge, 'target_%s' % target_name)\n",
    "#         merge_dataset_list.append(merge_dataset)\n",
    "\n",
    "#         logging.info('start train merge fill zeros attribute:%s' % target_name)\n",
    "#         merge_rets = train(target_name, user_dataset_dict, model)\n",
    "#         train_ret_dict.update(merge_rets[0])\n",
    "#         test_ret_dict.update(merge_rets[1])\n",
    "\n",
    "#     df_ret = pd.DataFrame([\n",
    "#         train_ret_dict, test_ret_dict\n",
    "#     ], index = ['train', 'test'])\n",
    "#     ipd.display(df_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_merge_dataset(target_name):\n",
    "    logging.info('start loading %s' % target_name)\n",
    "    _, df_train_user_info, df_test_user_info = pickle.load(open('var/baseline_user_info_%s.pickle' % target_name, 'rb'))\n",
    "    _, df_train_app_list, df_test_app_list = pickle.load(open('var/baseline_app_list_%s.pickle' % target_name, 'rb'))\n",
    "    _, df_train_app_behave, df_test_app_behave = pickle.load(open('var/baseline_app_behave_%s.pickle' % target_name, 'rb')) \n",
    "    _, df_train_user_log, df_test_user_log = pickle.load(open('var/baseline_user_log_%s.pickle' % target_name, 'rb')) \n",
    "    df_merge_train = pd.concat([df_train_user_info, df_train_app_list, df_train_app_behave, df_train_user_log], axis=1)\n",
    "    df_merge_train = df_merge_train.fillna(0)\n",
    "    df_merge_test = pd.concat([df_test_user_info, df_test_app_list, df_test_app_behave, df_test_user_log], axis=1)\n",
    "    df_merge_test = df_merge_test.fillna(0)\n",
    " \n",
    "    select_train_id = df_merge_train.index\n",
    "    select_test_id = df_merge_test.index \n",
    "    select_train_y = df_master_records.loc[select_train_id][target_name]\n",
    "    select_test_y = df_master_records.loc[select_test_id][target_name]\n",
    "    \n",
    "    ret = {\n",
    "        'train_x' : np.array(df_merge_train),\n",
    "        'train_y' : np.array(select_train_y),\n",
    "        'test_x' : np.array(df_merge_test),\n",
    "        'test_y' : np.array(select_test_y),\n",
    "        'train_new_client' : df_master_records.loc[select_train_id]['loan_sequence'] == 1,\n",
    "        'test_new_client' : df_master_records.loc[select_test_id]['loan_sequence'] == 1\n",
    "    }\n",
    "\n",
    "    logging.info('finish loading %s' % target_name)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 23:03:11,477 - INFO - start loading target_1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 23:05:56,859 - INFO - finish loading target_1m30+\n",
      "2020-09-16 23:05:57,141 - INFO - start train merge fill zeros attribute:1m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-16 23:09:03,738 - INFO - start loading target_2m30+\n",
      "2020-09-16 23:13:33,458 - INFO - finish loading target_2m30+\n",
      "2020-09-16 23:13:33,818 - INFO - start train merge fill zeros attribute:2m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-16 23:16:37,842 - INFO - start loading target_3m30+\n",
      "2020-09-16 23:18:32,294 - INFO - finish loading target_3m30+\n",
      "2020-09-16 23:18:32,669 - INFO - start train merge fill zeros attribute:3m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "2020-09-16 23:21:35,514 - INFO - start loading target_4m30+\n",
      "2020-09-16 23:26:01,795 - INFO - finish loading target_4m30+\n",
      "2020-09-16 23:26:02,154 - INFO - start train merge fill zeros attribute:4m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.649282</td>\n",
       "      <td>0.610092</td>\n",
       "      <td>0.627930</td>\n",
       "      <td>0.650687</td>\n",
       "      <td>0.635481</td>\n",
       "      <td>0.677163</td>\n",
       "      <td>0.640359</td>\n",
       "      <td>0.632646</td>\n",
       "      <td>0.643596</td>\n",
       "      <td>0.599035</td>\n",
       "      <td>0.603866</td>\n",
       "      <td>0.596196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.639917</td>\n",
       "      <td>0.599173</td>\n",
       "      <td>0.631661</td>\n",
       "      <td>0.667272</td>\n",
       "      <td>0.658869</td>\n",
       "      <td>0.690338</td>\n",
       "      <td>0.641780</td>\n",
       "      <td>0.637250</td>\n",
       "      <td>0.645740</td>\n",
       "      <td>0.607867</td>\n",
       "      <td>0.616288</td>\n",
       "      <td>0.611415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.649282   0.610092   0.627930  0.650687   0.635481   0.677163   \n",
       "test   0.639917   0.599173   0.631661  0.667272   0.658869   0.690338   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.640359   0.632646   0.643596  0.599035   0.603866   0.596196  \n",
       "test   0.641780   0.637250   0.645740  0.607867   0.616288   0.611415  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 23:29:06,808 - INFO - start loading target_1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=100, probability=True, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 23:32:02,755 - INFO - finish loading target_1m30+\n",
      "2020-09-16 23:32:03,149 - INFO - start train merge fill zeros attribute:1m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-17 00:26:18,048 - INFO - start loading target_2m30+\n",
      "2020-09-17 00:30:48,225 - INFO - finish loading target_2m30+\n",
      "2020-09-17 00:30:48,625 - INFO - start train merge fill zeros attribute:2m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-17 01:25:13,421 - INFO - start loading target_3m30+\n",
      "2020-09-17 01:29:55,996 - INFO - finish loading target_3m30+\n",
      "2020-09-17 01:29:56,399 - INFO - start train merge fill zeros attribute:3m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-17 02:24:07,904 - INFO - start loading target_4m30+\n",
      "2020-09-17 02:29:21,052 - INFO - finish loading target_4m30+\n",
      "2020-09-17 02:29:21,467 - INFO - start train merge fill zeros attribute:4m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.501867</td>\n",
       "      <td>0.443054</td>\n",
       "      <td>0.299989</td>\n",
       "      <td>0.424183</td>\n",
       "      <td>0.395770</td>\n",
       "      <td>0.318497</td>\n",
       "      <td>0.451554</td>\n",
       "      <td>0.413589</td>\n",
       "      <td>0.360563</td>\n",
       "      <td>0.489084</td>\n",
       "      <td>0.462056</td>\n",
       "      <td>0.407093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.425417</td>\n",
       "      <td>0.374139</td>\n",
       "      <td>0.300584</td>\n",
       "      <td>0.391074</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.342503</td>\n",
       "      <td>0.423772</td>\n",
       "      <td>0.384508</td>\n",
       "      <td>0.385690</td>\n",
       "      <td>0.453559</td>\n",
       "      <td>0.413899</td>\n",
       "      <td>0.412410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.501867   0.443054   0.299989  0.424183   0.395770   0.318497   \n",
       "test   0.425417   0.374139   0.300584  0.391074   0.360075   0.342503   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.451554   0.413589   0.360563  0.489084   0.462056   0.407093  \n",
       "test   0.423772   0.384508   0.385690  0.453559   0.413899   0.412410  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-17 03:23:35,393 - INFO - start loading target_1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-17 03:27:10,666 - INFO - finish loading target_1m30+\n",
      "2020-09-17 03:27:11,069 - INFO - start train merge fill zeros attribute:1m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "2020-09-17 08:31:40,102 - INFO - start loading target_2m30+\n"
     ]
    }
   ],
   "source": [
    "for i, model_orgin in enumerate([\n",
    "    linear_model.LogisticRegression(), \n",
    "    svm.SVC(probability=True, max_iter = 100),\n",
    "    neural_network.MLPClassifier(random_state=0, max_iter=300),\n",
    "    ensemble.GradientBoostingClassifier(random_state=0),\n",
    "]):\n",
    "    model = copy.deepcopy(model_orgin)\n",
    "    print(model)\n",
    "    train_ret_dict, test_ret_dict = {}, {}\n",
    "    for j, target_name in enumerate(['1m30+', '2m30+', '3m30+', '4m30+']):\n",
    "        merge_dataset_dict = get_df_merge_dataset('target_%s' % target_name)\n",
    "        logging.info('start train merge fill zeros attribute:%s' % target_name)\n",
    "        merge_rets = train(target_name, merge_dataset_dict, model)\n",
    "        train_ret_dict.update(merge_rets[0])\n",
    "        test_ret_dict.update(merge_rets[1])\n",
    "\n",
    "    df_ret = pd.DataFrame([\n",
    "        train_ret_dict, test_ret_dict\n",
    "    ], index = ['train', 'test'])\n",
    "    ipd.display(df_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-17 08:33:40,929 - INFO - start loading target_1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=0, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-17 08:35:52,158 - INFO - finish loading target_1m30+\n",
      "2020-09-17 08:35:52,462 - INFO - start train merge fill zeros attribute:1m30+\n",
      "2020-09-17 09:27:48,502 - INFO - start loading target_2m30+\n",
      "2020-09-17 09:31:40,280 - INFO - finish loading target_2m30+\n",
      "2020-09-17 09:31:40,688 - INFO - start train merge fill zeros attribute:2m30+\n",
      "2020-09-17 10:22:39,173 - INFO - start loading target_3m30+\n",
      "2020-09-17 10:26:55,550 - INFO - finish loading target_3m30+\n",
      "2020-09-17 10:26:55,954 - INFO - start train merge fill zeros attribute:3m30+\n",
      "2020-09-17 11:16:54,330 - INFO - start loading target_4m30+\n",
      "2020-09-17 11:19:18,437 - INFO - finish loading target_4m30+\n",
      "2020-09-17 11:19:18,826 - INFO - start train merge fill zeros attribute:4m30+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.723536</td>\n",
       "      <td>0.666592</td>\n",
       "      <td>0.752051</td>\n",
       "      <td>0.724728</td>\n",
       "      <td>0.691111</td>\n",
       "      <td>0.760201</td>\n",
       "      <td>0.701055</td>\n",
       "      <td>0.669679</td>\n",
       "      <td>0.717257</td>\n",
       "      <td>0.692881</td>\n",
       "      <td>0.666683</td>\n",
       "      <td>0.698521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.685207</td>\n",
       "      <td>0.639755</td>\n",
       "      <td>0.697357</td>\n",
       "      <td>0.702941</td>\n",
       "      <td>0.683918</td>\n",
       "      <td>0.713975</td>\n",
       "      <td>0.672260</td>\n",
       "      <td>0.661397</td>\n",
       "      <td>0.671495</td>\n",
       "      <td>0.669371</td>\n",
       "      <td>0.662018</td>\n",
       "      <td>0.668073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.723536   0.666592   0.752051  0.724728   0.691111   0.760201   \n",
       "test   0.685207   0.639755   0.697357  0.702941   0.683918   0.713975   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.701055   0.669679   0.717257  0.692881   0.666683   0.698521  \n",
       "test   0.672260   0.661397   0.671495  0.669371   0.662018   0.668073  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, model_orgin in enumerate([\n",
    "    ensemble.GradientBoostingClassifier(random_state=0),\n",
    "]):\n",
    "    model = copy.deepcopy(model_orgin)\n",
    "    print(model)\n",
    "    train_ret_dict, test_ret_dict = {}, {}\n",
    "    for j, target_name in enumerate(['1m30+', '2m30+', '3m30+', '4m30+']):\n",
    "        merge_dataset_dict = get_df_merge_dataset('target_%s' % target_name)\n",
    "        logging.info('start train merge fill zeros attribute:%s' % target_name)\n",
    "        merge_rets = train(target_name, merge_dataset_dict, model)\n",
    "        train_ret_dict.update(merge_rets[0])\n",
    "        test_ret_dict.update(merge_rets[1])\n",
    "\n",
    "    df_ret = pd.DataFrame([\n",
    "        train_ret_dict, test_ret_dict\n",
    "    ], index = ['train', 'test'])\n",
    "    ipd.display(df_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     7,
     31,
     34,
     63
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "from transformers import *\n",
    "\n",
    "class GeLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1. + torch.tanh(x * 0.7978845608 * (1. + 0.044715 * x * x)))\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, in_feature):\n",
    "        super().__init__()\n",
    "        hidden = 128\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_feature, hidden),\n",
    "            GeLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden, 2)\n",
    "        )\n",
    "        self.dense.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)\n",
    "\n",
    "class DNNTrain():\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.model = DNN(X.shape[1]).cuda()\n",
    "        self.model.train()\n",
    "\n",
    "        torch_dataset = Data.TensorDataset(torch.tensor(X.astype('float32')), torch.tensor(y.astype('int')))\n",
    "        data_loader = Data.DataLoader(\n",
    "            dataset=torch_dataset,      \n",
    "            batch_size=1024,      \n",
    "            shuffle=True,\n",
    "            num_workers = 0,\n",
    "        )\n",
    "\n",
    "        optimizer = AdamW(self.model.parameters(), lr = 0.01, weight_decay = 0.01)\n",
    " \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(12):\n",
    "            self.model.train()\n",
    "            for i, (batch_x, batch_y) in enumerate(tqdm(data_loader)):\n",
    "                batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "                pre = self.model(batch_x)    \n",
    "                loss = loss_func(pre, batch_y.long())\n",
    "                #backward\n",
    "                S = time.time()\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm = 2)\n",
    "                optimizer.step()\n",
    "                \n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        torch_dataset = Data.TensorDataset(torch.tensor(X.astype('float32')))\n",
    "        data_loader = Data.DataLoader(\n",
    "            dataset=torch_dataset,      \n",
    "            batch_size=1024,      \n",
    "            shuffle=True,\n",
    "            num_workers = 0,\n",
    "        )\n",
    "        pre_list = []\n",
    "        for i, (batch_x,) in enumerate(tqdm(data_loader)):\n",
    "            pre = self.model(batch_x.cuda())    \n",
    "            pre_list.append(pre.cpu().detach().numpy())\n",
    "        return np.concatenate(pre_list,  axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-17 20:59:59,026 - INFO - start loading target_1m30+\n",
      "2020-09-17 21:03:39,444 - INFO - finish loading target_1m30+\n",
      "2020-09-17 21:03:39,793 - INFO - start train merge fill zeros attribute:1m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-18 00:33:15,522 - INFO - start loading target_2m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'1m30+': 0.9681381926324119, 'new_1m30+': 0.9661895860202934, 'old_1m30+': 0.9667543195498499}, {'1m30+': 0.6139951822743608, 'new_1m30+': 0.5984622938978599, 'old_1m30+': 0.6646996225146123})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-18 00:35:42,789 - INFO - finish loading target_2m30+\n",
      "2020-09-18 00:35:43,133 - INFO - start train merge fill zeros attribute:2m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-18 03:57:23,329 - INFO - start loading target_3m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'2m30+': 0.952655145976405, 'new_2m30+': 0.9533724411242775, 'old_2m30+': 0.9523938761926372}, {'2m30+': 0.6583299550320685, 'new_2m30+': 0.6424596104267862, 'old_2m30+': 0.6754701047573929})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-18 04:01:14,815 - INFO - finish loading target_3m30+\n",
      "2020-09-18 04:01:15,284 - INFO - start train merge fill zeros attribute:3m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "2020-09-18 07:02:24,217 - INFO - start loading target_4m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'3m30+': 0.9483469705596369, 'new_3m30+': 0.9483583472457046, 'old_3m30+': 0.9474853229647335}, {'3m30+': 0.6502197498254194, 'new_3m30+': 0.633652861195702, 'old_3m30+': 0.6753175402839878})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-18 07:06:49,856 - INFO - finish loading target_4m30+\n",
      "2020-09-18 07:06:50,309 - INFO - start train merge fill zeros attribute:4m30+\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'4m30+': 0.9457503700976314, 'new_4m30+': 0.9449680612526397, 'old_4m30+': 0.9446924681860115}, {'4m30+': 0.6434467779975812, 'new_4m30+': 0.6212707017692016, 'old_4m30+': 0.6686445813318918})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.968138</td>\n",
       "      <td>0.966190</td>\n",
       "      <td>0.966754</td>\n",
       "      <td>0.952655</td>\n",
       "      <td>0.953372</td>\n",
       "      <td>0.952394</td>\n",
       "      <td>0.948347</td>\n",
       "      <td>0.948358</td>\n",
       "      <td>0.947485</td>\n",
       "      <td>0.945750</td>\n",
       "      <td>0.944968</td>\n",
       "      <td>0.944692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.613995</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.664700</td>\n",
       "      <td>0.658330</td>\n",
       "      <td>0.642460</td>\n",
       "      <td>0.675470</td>\n",
       "      <td>0.650220</td>\n",
       "      <td>0.633653</td>\n",
       "      <td>0.675318</td>\n",
       "      <td>0.643447</td>\n",
       "      <td>0.621271</td>\n",
       "      <td>0.668645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.968138   0.966190   0.966754  0.952655   0.953372   0.952394   \n",
       "test   0.613995   0.598462   0.664700  0.658330   0.642460   0.675470   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.948347   0.948358   0.947485  0.945750   0.944968   0.944692  \n",
       "test   0.650220   0.633653   0.675318  0.643447   0.621271   0.668645  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ret_dict, test_ret_dict = {}, {}\n",
    "for j, target_name in enumerate(['1m30+', '2m30+', '3m30+', '4m30+']):\n",
    "    merge_dataset_dict = get_df_merge_dataset('target_%s' % target_name)\n",
    "    logging.info('start train merge fill zeros attribute:%s' % target_name)\n",
    "    merge_rets = train(target_name, merge_dataset_dict, neural_network.MLPClassifier(random_state=0, max_iter=100))\n",
    "    print(merge_rets)\n",
    "    train_ret_dict.update(merge_rets[0])\n",
    "    test_ret_dict.update(merge_rets[1])\n",
    "\n",
    "df_ret = pd.DataFrame([\n",
    "    train_ret_dict, test_ret_dict\n",
    "], index = ['train', 'test'])\n",
    "ipd.display(df_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## App concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_app_merge_dataset(target_name):\n",
    "    logging.info('start loading %s' % target_name)\n",
    "    _, df_train_app_list, df_test_app_list = pickle.load(open('var/baseline_app_list_%s.pickle' % target_name, 'rb'))\n",
    "    _, df_train_app_behave, df_test_app_behave = pickle.load(open('var/baseline_app_behave_%s.pickle' % target_name, 'rb')) \n",
    "    df_merge_train = pd.concat([df_train_app_list, df_train_app_behave], axis=1)\n",
    "    df_merge_train = df_merge_train.fillna(0)\n",
    "    df_merge_test = pd.concat([df_test_app_list, df_test_app_behave], axis=1)\n",
    "    df_merge_test = df_merge_test.fillna(0)\n",
    " \n",
    "    select_train_id = df_merge_train.index\n",
    "    select_test_id = df_merge_test.index \n",
    "    select_train_y = df_master_records.loc[select_train_id][target_name]\n",
    "    select_test_y = df_master_records.loc[select_test_id][target_name]\n",
    "    \n",
    "    ret = {\n",
    "        'train_x' : np.array(df_merge_train),\n",
    "        'train_y' : np.array(select_train_y),\n",
    "        'test_x' : np.array(df_merge_test),\n",
    "        'test_y' : np.array(select_test_y),\n",
    "        'train_new_client' : df_master_records.loc[select_train_id]['loan_sequence'] == 1,\n",
    "        'test_new_client' : df_master_records.loc[select_test_id]['loan_sequence'] == 1\n",
    "    }\n",
    "\n",
    "    logging.info('finish loading %s' % target_name)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 16:02:17,167 - INFO - start loading target_1m30+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
      "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "              warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-16 16:03:17,869 - INFO - finish loading target_1m30+\n",
      "2020-09-16 16:03:18,256 - INFO - start train merge fill zeros attribute:1m30+\n",
      "2020-09-16 17:47:00,529 - INFO - start loading target_2m30+\n",
      "2020-09-16 17:48:23,375 - INFO - finish loading target_2m30+\n",
      "2020-09-16 17:48:23,778 - INFO - start train merge fill zeros attribute:2m30+\n",
      "2020-09-16 19:02:26,982 - INFO - start loading target_3m30+\n",
      "2020-09-16 19:03:19,333 - INFO - finish loading target_3m30+\n",
      "2020-09-16 19:03:19,712 - INFO - start train merge fill zeros attribute:3m30+\n",
      "2020-09-16 20:55:02,725 - INFO - start loading target_4m30+\n",
      "2020-09-16 20:58:04,759 - INFO - finish loading target_4m30+\n",
      "2020-09-16 20:58:05,141 - INFO - start train merge fill zeros attribute:4m30+\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1m30+</th>\n",
       "      <th>new_1m30+</th>\n",
       "      <th>old_1m30+</th>\n",
       "      <th>2m30+</th>\n",
       "      <th>new_2m30+</th>\n",
       "      <th>old_2m30+</th>\n",
       "      <th>3m30+</th>\n",
       "      <th>new_3m30+</th>\n",
       "      <th>old_3m30+</th>\n",
       "      <th>4m30+</th>\n",
       "      <th>new_4m30+</th>\n",
       "      <th>old_4m30+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.999010</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>0.998299</td>\n",
       "      <td>0.998121</td>\n",
       "      <td>0.998862</td>\n",
       "      <td>0.996766</td>\n",
       "      <td>0.998782</td>\n",
       "      <td>0.99914</td>\n",
       "      <td>0.998453</td>\n",
       "      <td>0.998654</td>\n",
       "      <td>0.999141</td>\n",
       "      <td>0.998121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.599606</td>\n",
       "      <td>0.569888</td>\n",
       "      <td>0.629322</td>\n",
       "      <td>0.643056</td>\n",
       "      <td>0.616296</td>\n",
       "      <td>0.649195</td>\n",
       "      <td>0.654374</td>\n",
       "      <td>0.62952</td>\n",
       "      <td>0.655225</td>\n",
       "      <td>0.655701</td>\n",
       "      <td>0.633685</td>\n",
       "      <td>0.654798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1m30+  new_1m30+  old_1m30+     2m30+  new_2m30+  old_2m30+  \\\n",
       "train  0.999010   0.999395   0.998299  0.998121   0.998862   0.996766   \n",
       "test   0.599606   0.569888   0.629322  0.643056   0.616296   0.649195   \n",
       "\n",
       "          3m30+  new_3m30+  old_3m30+     4m30+  new_4m30+  old_4m30+  \n",
       "train  0.998782    0.99914   0.998453  0.998654   0.999141   0.998121  \n",
       "test   0.654374    0.62952   0.655225  0.655701   0.633685   0.654798  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, model_orgin in enumerate([\n",
    "#     linear_model.LogisticRegression(), \n",
    "#     svm.SVC(probability=True, max_iter = 100),\n",
    "    neural_network.MLPClassifier(random_state=0, max_iter=300),\n",
    "#     ensemble.GradientBoostingClassifier(random_state=0),\n",
    "]):\n",
    "    model = copy.deepcopy(model_orgin)\n",
    "    print(model)\n",
    "    \n",
    "    train_ret_dict, test_ret_dict = {}, {}\n",
    "    for j, target_name in enumerate(['1m30+', '2m30+', '3m30+', '4m30+']):\n",
    "        merge_dataset_dict = get_app_merge_dataset('target_%s' % target_name)\n",
    "        logging.info('start train merge fill zeros attribute:%s' % target_name)\n",
    "        merge_rets = train(target_name, merge_dataset_dict, model)\n",
    "        train_ret_dict.update(merge_rets[0])\n",
    "        test_ret_dict.update(merge_rets[1])\n",
    "\n",
    "    df_ret = pd.DataFrame([\n",
    "        train_ret_dict, test_ret_dict\n",
    "    ], index = ['train', 'test'])\n",
    "    ipd.display(df_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(hyr)\n",
   "language": "python",
   "name": "hyr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.087px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
