{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-13 17:49:40,672 - INFO - PyTorch version 1.1.0 available.\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import datetime\n",
    "import pickle\n",
    "import scipy.sparse as ss\n",
    "import logging\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '32'\n",
    "# import seaborn as sns\n",
    "\n",
    "import IPython.display as ipd\n",
    "import copy\n",
    "import random\n",
    "from pandarallel import pandarallel\n",
    "# Initialization\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "# df.parallel_apply(func)\n",
    "import time\n",
    "from gensim.models.word2vec import Word2Vec \n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "\n",
    "from transformers import *\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from transformers.modeling_bert import BertConfig, BertEncoder, BertAttention,\\\n",
    "BertSelfAttention,BertLayer,BertPooler,BertLayerNorm\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec \n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from scipy.special import softmax\n",
    "\n",
    "from category_encoders import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-13 17:49:42,685 - INFO - start read\n",
      "2020-11-13 17:50:43,178 - INFO - finish read\n"
     ]
    }
   ],
   "source": [
    "logging.info('start read')\n",
    "df_master_records = pickle.load(open('../data_sortout/df_master_records.pickle', 'rb'))\n",
    "se_id_install_list = pickle.load(open('../data_sortout/se_id_install_list.pickle', 'rb'))\n",
    "df_install_behave = pickle.load(open('../data_sortout/df_install_behave_no_date.pickle', 'rb'))\n",
    "df_behave_time = pickle.load(open('../data_sortout/df_time_cut.pickle', 'rb'))\n",
    "# df_userlog = pickle.load(open('../data_sortout/df_userlog_sequence_less.pickle', 'rb'))\n",
    "se_userlog_cross = pickle.load(open('../data_sortout/se_userlog_cross_id.pickle', 'rb'))\n",
    "df_userlog_time_seq = pickle.load(open('../data_sortout/df_userlog_time_seq.pickle', 'rb'))\n",
    "\n",
    "# df_app_list_te_sequence = pickle.load(open('../data_sortout/df_app_list_target_encode_sequence.pickle', 'rb'))\n",
    "# df_app_behave_te_sequence = pickle.load(open('../data_sortout/df_app_behave_target_encode_sequence.pickle', 'rb'))\n",
    "\n",
    "df_app_list_te_qcut = pickle.load(open('../data_sortout/df_app_list_target_qcut.pickle', 'rb'))\n",
    "df_app_behave_te_qcut = pickle.load(open('../data_sortout/df_app_behave_target_qcut.pickle', 'rb'))\n",
    "\n",
    "\n",
    "logging.info('finish read')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-13 17:51:39,538 - INFO - all_train_id len :326082, all_test_id: 75896\n"
     ]
    }
   ],
   "source": [
    "split_date = datetime.datetime(2019, 8, 31)\n",
    "end_date = datetime.datetime(2019, 9, 30)\n",
    "\n",
    "df_master_records = df_master_records.dropna(axis=0, how='any')\n",
    "df_train_master = df_master_records.query('loan_date <= @split_date')\n",
    "df_test_master = df_master_records.query('loan_date > @split_date & loan_date <= @end_date')\n",
    "all_train_id = list(df_train_master.index)\n",
    "all_test_id = list(df_test_master.index)\n",
    "logging.info('all_train_id len :%d, all_test_id: %d' % (len(all_train_id), len(all_test_id)))\n",
    "df_target = df_master_records[['target_1m30+', 'target_2m30+', 'target_3m30+', 'target_4m30+']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_app_list_id = max(se_id_install_list.apply(max))\n",
    "max_app_behave_id = max(df_install_behave['pkg_id'].apply(max))\n",
    "max_uselog_id = max(se_userlog_cross.apply(max))\n",
    "start_app_list_id = max_app_list_id + 1\n",
    "start_app_behave_id = max_app_behave_id + 1 \n",
    "start_uselog_id = max_uselog_id + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def get_master_user_discrete(df_master_records):\n",
    "    \n",
    "    df_master_records['qcut_amount_bin'] = pd.qcut(df_master_records['amount_bin'], 5)\n",
    "    df_master_records['new_client'] = df_master_records['loan_sequence'] == 1\n",
    "    df_master_records['qcut_age'] = pd.qcut(df_master_records['age'], 5, duplicates='drop')\n",
    "    \n",
    "    df_master_records['qcut_min_income'] = pd.qcut(df_master_records['min_income'], 6, duplicates='drop')\n",
    "    df_master_records['qcut_max_income'] = pd.qcut(df_master_records['max_income'].apply(int), 6, duplicates='drop')\n",
    "\n",
    "#     df_master_records['qcut_loan_sequence'] = pd.qcut(df_master_records['loan_sequence'], 6, duplicates='drop')\n",
    "#     pne_hot_cols = ['months', 'gender', 'educationid', 'marriagestatusid', 'income', \n",
    "#                     'qcut_amount_bin', 'new_client', 'qcut_loan_sequence', 'qcut_age', 'qcut_min_income', 'qcut_max_income']\n",
    "    pne_hot_cols = ['months', 'gender', 'educationid', 'marriagestatusid', 'income', \n",
    "                'qcut_amount_bin', 'qcut_age', 'qcut_min_income', 'qcut_max_income']\n",
    "\n",
    "    return  pd.get_dummies(df_master_records[pne_hot_cols], columns = pne_hot_cols)\n",
    "df_user_one_hot = get_master_user_discrete(df_master_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model_app_list = pickle.load(open('../data_sortout/wv_model_app_list.pickle', 'rb'))\n",
    "wv_model_app_behave = pickle.load(open('../data_sortout/wv_model_app_behave.pickle', 'rb'))\n",
    "wv_model_userlog = pickle.load(open('../data_sortout/wv_model_userlog_cross.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "ARG = namedtuple('ARG', [\n",
    "    'batch_size',\n",
    "    'epoch',\n",
    "    'lr',\n",
    "    'weight_decay',\n",
    "    'debug',\n",
    "    'n_embedding',\n",
    "    'app_install_list_max_length',\n",
    "    'app_behave_max_length',\n",
    "    'userlog_max_length',\n",
    "    'n_eval',\n",
    "    'dropout_rate',\n",
    "    'n_worker',\n",
    "    'use_cuda',\n",
    "    'n_gpu',\n",
    "    'device',\n",
    "    'card_list'\n",
    "])\n",
    " \n",
    "args = ARG(\n",
    "    batch_size = 256,\n",
    "    epoch = 16,\n",
    "    lr = 0.001,\n",
    "    weight_decay = 0.0,\n",
    "    dropout_rate = 0.,\n",
    "    debug = False,\n",
    "    n_embedding = 100,\n",
    "    app_install_list_max_length = 256,\n",
    "    app_behave_max_length = 256,\n",
    "    userlog_max_length = 256,\n",
    "    n_eval = len(all_test_id)+1,\n",
    "    n_worker = 0,\n",
    "    use_cuda = True,\n",
    "    n_gpu = 1,\n",
    "    card_list = [0, 1],\n",
    "    device=torch.device(\"cuda:1\"),\n",
    "#     device=torch.device(\"cpu\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_behave_set = set(df_install_behave.index) & (set(all_train_id) | set(all_test_id))\n",
    "install_list_set = set(se_id_install_list.index) & (set(all_train_id) | set(all_test_id))\n",
    "user_info_set = set(df_user_one_hot.index) & (set(all_train_id) | set(all_test_id))\n",
    "user_log_set = set(se_userlog_cross.index) & (set(all_train_id) | set(all_test_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(install_behave_set, open('install_behave_set.pickle', 'wb'))\n",
    "# pickle.dump(install_list_set, open('install_list_set.pickle', 'wb'))\n",
    "# pickle.dump(user_info_set, open('user_info_set.pickle', 'wb'))\n",
    "# pickle.dump(user_log_set, open('user_log_set.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": [
     0,
     10,
     37
    ]
   },
   "outputs": [],
   "source": [
    "class AppDataset(Data.Dataset):\n",
    "    def __init__(self, master_ids):\n",
    "        self.master_ids = list(master_ids)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.master_ids)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.master_ids[idx]\n",
    "\n",
    "x_dict = {\n",
    "    \n",
    "    'user_info' : np.zeros((args.batch_size, df_user_one_hot.shape[1])),\n",
    "\n",
    "    'app_list' : np.zeros((args.batch_size, args.app_install_list_max_length + 1)).astype('int'),\n",
    "    'app_list_te_qcut' : np.zeros((args.batch_size, args.app_install_list_max_length + 1, 4)).astype('int'),\n",
    "    'app_list_len' :  np.zeros((args.batch_size,)).astype('int'),\n",
    "    \n",
    "    'app_behave' : np.zeros((args.batch_size, args.app_behave_max_length + 1)).astype('int'),\n",
    "    'app_behave_time_cut' : np.zeros((args.batch_size, args.app_behave_max_length + 1)).astype('int'),\n",
    "    'app_behave_time_qcut' : np.zeros((args.batch_size, args.app_behave_max_length + 1)).astype('int'),\n",
    "    \n",
    "    'app_behave_action' : np.zeros((args.batch_size, args.app_behave_max_length + 1)).astype('int'),\n",
    "    'app_behave_te_qcut' : np.zeros((args.batch_size, args.app_behave_max_length + 1, 4)).astype('int'),\n",
    "\n",
    "    'app_behave_len' :  np.zeros((args.batch_size,)).astype('int'),\n",
    "    \n",
    "    'userlog' : np.zeros((args.batch_size, args.userlog_max_length + 1)).astype('int'),\n",
    "    'userlog_len' :  np.zeros((args.batch_size,)).astype('int'),\n",
    "    'userlog_day_qcut' : np.zeros((args.batch_size, args.userlog_max_length + 1)).astype('int'),\n",
    "    'userlog_day_cut' : np.zeros((args.batch_size, args.userlog_max_length + 1)).astype('int'),\n",
    "    'userlog_second_qcut' : np.zeros((args.batch_size, args.userlog_max_length + 1)).astype('int'),\n",
    "    'userlog_second_cut' : np.zeros((args.batch_size, args.userlog_max_length + 1)).astype('int'),\n",
    "    \n",
    "    'view_mask' : np.zeros((args.batch_size, 4)).astype('int'),\n",
    "}\n",
    "\n",
    "def set_first_token():\n",
    "    x_dict['app_list'][:, 0] = start_app_list_id\n",
    "    x_dict['app_behave'][:, 0] = start_app_behave_id\n",
    "    x_dict['userlog'][:, 0] = start_uselog_id\n",
    "\n",
    "    x_dict['app_list'][:, 0] = 0\n",
    "    x_dict['app_behave'][:, 0] = 0\n",
    "    x_dict['userlog'][:, 0] = 0\n",
    "\n",
    "    x_dict['userlog_day_qcut'][:, 0] = 8\n",
    "    x_dict['userlog_day_cut'][:, 0] = 8\n",
    "    x_dict['userlog_second_qcut'][:, 0] = 32\n",
    "    x_dict['userlog_second_cut'][:, 0] = 32\n",
    "\n",
    "set_first_token()\n",
    "\n",
    "def collate_fn(master_ids):\n",
    "    master_ids = np.array(master_ids)\n",
    "\n",
    "#     sub_master_id = se_id_install_list.loc[master_ids]\n",
    "#     df_sub_behave = df_install_behave.loc[master_ids]\n",
    "#     df_sub_time = df_behave_time.loc[master_ids]\n",
    "    for i, master_id in enumerate(master_ids):\n",
    "        if master_id in user_info_set and use_user_attribute:\n",
    "            x_dict['user_info'][i] = df_user_one_hot.loc[master_id].values\n",
    "            x_dict['view_mask'][i][0] = 1\n",
    "        else:\n",
    "            x_dict['user_info'][i] = 0\n",
    "            x_dict['view_mask'][i][0] = 1\n",
    "\n",
    "        if master_id in install_list_set and use_app_list:\n",
    "            app_list = se_id_install_list.at[master_id][:args.app_install_list_max_length]\n",
    "            x_dict['app_list_len'][i] = len(app_list) + 1\n",
    "            x_dict['app_list'][i][1 : x_dict['app_list_len'][i]] = app_list\n",
    "            x_dict['app_list'][i][x_dict['app_list_len'][i] :] = 0\n",
    "            \n",
    "#             target_encode_data = np.array(list(df_app_list_te_qcut.loc[master_id].values))[:, :args.app_install_list_max_length].T\n",
    "#             x_dict['app_list_te_qcut'][i][1 : x_dict['app_list_len'][i]] = target_encode_data\n",
    "            \n",
    "            x_dict['view_mask'][i][1] = 1\n",
    "        else:\n",
    "            x_dict['app_list_len'][i] = 1\n",
    "            x_dict['app_list'][i][1:] = 0\n",
    "            x_dict['app_list_te_qcut'][i] = 0\n",
    "            x_dict['view_mask'][i][1] = 0\n",
    "\n",
    "        if master_id in install_behave_set and use_app_behave:\n",
    "            app_behave = df_install_behave['pkg_id'].at[master_id][-args.app_behave_max_length:]\n",
    "            len_app = len(app_behave) + 1\n",
    "            x_dict['app_behave_len'][i] = len_app\n",
    "            x_dict['app_behave'][i][1: len_app] = app_behave\n",
    "            x_dict['app_behave'][i][len_app :] = 0\n",
    "            \n",
    "#             target_encode_data = np.array(list(df_app_behave_te_qcut.loc[master_id].values))[:, -args.app_behave_max_length:].T\n",
    "#             x_dict['app_behave_te_qcut'][i][1 : len_app] = target_encode_data\n",
    "            \n",
    "            x_dict['app_behave_time_cut'][i][1:len_app] = df_behave_time['cut_id'].at[master_id][-args.app_behave_max_length:]\n",
    "            x_dict['app_behave_time_qcut'][i][1:len_app] = df_behave_time['qcut_id'].at[master_id][-args.app_behave_max_length:]\n",
    "            x_dict['app_behave_action'][i][1:len_app] = df_install_behave['action'].at[master_id][-args.app_behave_max_length:]\n",
    "            x_dict['view_mask'][i][2] = 1\n",
    "        else:\n",
    "            x_dict['app_behave_len'][i] = 1\n",
    "            x_dict['app_behave'][i][1:] = 0\n",
    "            x_dict['app_behave_te_qcut'][i] = 0\n",
    "\n",
    "            x_dict['app_behave_time_cut'][i][1:] = 0\n",
    "            x_dict['app_behave_time_qcut'][i][1:] = 0\n",
    "            x_dict['app_behave_action'][i][1:] = 0\n",
    "            x_dict['view_mask'][i][2] = 0\n",
    "        \n",
    "        \n",
    "        if master_id in user_log_set and use_user_log:\n",
    "            userlog_list = se_userlog_cross.at[master_id][:args.userlog_max_length]\n",
    "            len_userlog = len(userlog_list) + 1\n",
    "            x_dict['userlog_len'][i] = len_userlog\n",
    "            x_dict['userlog'][i][1 : len_userlog] = userlog_list\n",
    "            x_dict['userlog'][i][len_userlog :] = 0\n",
    "            x_dict['userlog_day_qcut'][i][1 : len_userlog] = df_userlog_time_seq['qcut_day_id'].at[master_id][:args.userlog_max_length]\n",
    "            x_dict['userlog_day_qcut'][i][len_userlog :] = 0\n",
    "            x_dict['userlog_day_cut'][i][1 : len_userlog] = df_userlog_time_seq['cut_day_id'].at[master_id][:args.userlog_max_length]\n",
    "            x_dict['userlog_day_cut'][i][len_userlog :] = 0\n",
    "            x_dict['userlog_second_qcut'][i][1 : len_userlog] = df_userlog_time_seq['qcut_second_id'].at[master_id][:args.userlog_max_length]\n",
    "            x_dict['userlog_second_qcut'][i][len_userlog :] = 0\n",
    "            x_dict['userlog_second_cut'][i][1 : len_userlog] = df_userlog_time_seq['cut_second_id'].at[master_id][:args.userlog_max_length]\n",
    "            x_dict['userlog_second_cut'][i][len_userlog :] = 0\n",
    "\n",
    "            x_dict['view_mask'][i][3] = 1\n",
    "        else:\n",
    "            x_dict['userlog_len'][i] = 1\n",
    "            x_dict['userlog'][i] = 0\n",
    "            x_dict['userlog_day_qcut'][i] = 0\n",
    "            x_dict['userlog_day_cut'][i] = 0\n",
    "            x_dict['userlog_second_qcut'][i] = 0\n",
    "            x_dict['userlog_second_cut'][i] = 0\n",
    "\n",
    "            x_dict['view_mask'][i][3] = 0\n",
    "    \n",
    "    \n",
    "    len_id = master_ids.shape[0]\n",
    "    x_dict['app_list'][len_id:] = 0\n",
    "    x_dict['app_behave'][len_id:] = 0\n",
    "    return {\n",
    "        'master_ids' : master_ids,\n",
    "        'user_info' : torch.tensor(x_dict['user_info'][:len_id]).float(),\n",
    "        \n",
    "        'app_list' : torch.tensor(x_dict['app_list'][:len_id]).long(),\n",
    "        'app_list_te_qcut' : torch.tensor(x_dict['app_list_te_qcut'][:len_id]).long(),\n",
    "        'app_list_len' : torch.tensor(x_dict['app_list_len'][:len_id]).long(),\n",
    "        \n",
    "        'app_behave' : torch.tensor(x_dict['app_behave'][:len_id]).long(),\n",
    "        'app_behave_te_qcut' : torch.tensor(x_dict['app_behave_te_qcut'][:len_id]).long(),\n",
    "        'app_behave_len' : torch.tensor(x_dict['app_behave_len'][:len_id]).long(),\n",
    "        \n",
    "        'app_behave_time_cut' : torch.tensor(x_dict['app_behave_time_cut'][:len_id]).long(),\n",
    "        'app_behave_time_qcut' : torch.tensor(x_dict['app_behave_time_qcut'][:len_id]).long(),\n",
    "        'app_behave_action' : torch.tensor(x_dict['app_behave_action'][:len_id]).long(),\n",
    "        'userlog' : torch.tensor(x_dict['userlog'][:len_id]).long(),\n",
    "        'userlog_len' : torch.tensor(x_dict['userlog_len'][:len_id]).long(),\n",
    "        'userlog_day_qcut' : torch.tensor(x_dict['userlog_day_qcut'][:len_id]).long(),\n",
    "        'userlog_day_cut' : torch.tensor(x_dict['userlog_day_cut'][:len_id]).long(),\n",
    "        'userlog_second_qcut' : torch.tensor(x_dict['userlog_second_qcut'][:len_id]).long(),\n",
    "        'userlog_second_cut' : torch.tensor(x_dict['userlog_second_cut'][:len_id]).long(),\n",
    "\n",
    "        'view_mask' : torch.tensor(x_dict['view_mask'][:len_id]).long(),\n",
    "        'labels1' : torch.tensor(df_target.loc[master_ids]['target_1m30+'].values).long(),\n",
    "        'labels2' : torch.tensor(df_target.loc[master_ids]['target_2m30+'].values).long(),\n",
    "        'labels3' : torch.tensor(df_target.loc[master_ids]['target_3m30+'].values).long(),\n",
    "        'labels4' : torch.tensor(df_target.loc[master_ids]['target_4m30+'].values).long(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ac570989ab4abf984c3dd74038faa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=127819), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706d47810fba4b6dbbc1e8de3b9cc901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=240397), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdf3437f08a4eae82e5b6a2a562ec68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=138), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_app_list_wv_weight():\n",
    "    weight = np.zeros((start_app_list_id+1, 100))\n",
    "    for i in tqdm(range(1, start_app_list_id+1)):\n",
    "        weight[i] = wv_model_app_list.wv[str(i)]\n",
    "    weight_tensor = torch.tensor(weight).float()\n",
    "    return weight_tensor\n",
    "\n",
    "def get_app_behave_wv_weight():\n",
    "    weight = np.zeros((start_app_behave_id+1, 100))\n",
    "    for i in tqdm(range(1, start_app_behave_id+1)):\n",
    "        weight[i] = wv_model_app_behave.wv[str(i)]\n",
    "    weight_tensor = torch.tensor(weight).float()\n",
    "    return weight_tensor\n",
    "\n",
    "def get_userlog_wv_weight():\n",
    "    weight = np.zeros((start_uselog_id+1, 100))\n",
    "    for i in tqdm(range(1, start_uselog_id+1)):\n",
    "        weight[i] = wv_model_userlog.wv[str(i)]\n",
    "    weight_tensor = torch.tensor(weight).float()\n",
    "    return weight_tensor\n",
    "\n",
    "app_list_weight = get_app_list_wv_weight()\n",
    "app_behave_weight = get_app_behave_wv_weight()\n",
    "userlog_weight = get_userlog_wv_weight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sub model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [
     0,
     12,
     23,
     39,
     56,
     67,
     92,
     96,
     116,
     153,
     201,
     289
    ]
   },
   "outputs": [],
   "source": [
    "def masked_softmax(X, valid_len):\n",
    "    if valid_len is None:\n",
    "        return F.softmax(X,dim=-1)\n",
    "    else:\n",
    "        shape=X.shape\n",
    "        if valid_len.dim()==1:\n",
    "            valid_len=valid_len.view(-1,1).repeat(1,shape[1])\n",
    "        mask = (torch.arange(0,X.shape[-1]).repeat(X.shape[0],1).to(args.device) < valid_len).repeat(1, X.shape[1]).view(shape)\n",
    "        \n",
    "        X = X.masked_fill_(~mask, -float('inf'))\n",
    "        return F.softmax(X,dim=-1).view(shape)\n",
    "\n",
    "def make_mask(X, valid_len):\n",
    "    if valid_len is None:\n",
    "        return F.softmax(X,dim=-1)\n",
    "    else:\n",
    "        shape=X.shape\n",
    "        if valid_len.dim()==1:\n",
    "            valid_len=valid_len.view(-1,1).repeat(1,shape[1])\n",
    "\n",
    "        mask=(torch.arange(0,X.shape[1]).repeat(X.shape[0],1).to(X.device)<valid_len).byte()\n",
    "        return mask.unsqueeze(2) \n",
    "\n",
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # `query`: (`batch_size`, #queries, `d`)\n",
    "    # `key`: (`batch_size`, #kv_pairs, `d`)\n",
    "    # `value`: (`batch_size`, #kv_pairs, `dim_v`)\n",
    "    # `valid_len`: either (`batch_size`, ) or (`batch_size`, xx)\n",
    "    def forward(self, query, key, value, valid_len=None):\n",
    "        d = query.shape[-1]\n",
    "        # Set transpose_b=True to swap the last two dimensions of key\n",
    "        scores = torch.bmm(query, key.transpose(1,2)) / math.sqrt(d)\n",
    "        attention_weights = self.dropout(masked_softmax(scores, valid_len))\n",
    "        return torch.bmm(attention_weights, value)\n",
    "    \n",
    "class MLPAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size, units, dropout=0., **kwargs):\n",
    "        super(MLPAttention, self).__init__(**kwargs)\n",
    "        self.W_k = nn.Linear(key_size, units, bias=False)\n",
    "        self.W_q = nn.Linear(query_size, units, bias=False)\n",
    "        self.v = nn.Linear(units, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, query, key, value, valid_len):\n",
    "        query, key = self.W_k(query), self.W_q(key)\n",
    "        # Expand query to (`batch_size`, #queries, 1, units), and key to\n",
    "        # (`batch_size`, 1, #kv_pairs, units). Then plus them with broadcast\n",
    "        features = query.unsqueeze(2) + key.unsqueeze(1)\n",
    "        scores = self.v(features).squeeze(-1)\n",
    "        attention_weights = self.dropout(masked_softmax(scores, valid_len))\n",
    "        return torch.bmm(attention_weights, value)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,features,eps=1e-6):\n",
    "        super(LayerNorm,self).__init__()\n",
    "        self.gamma=nn.Parameter(torch.ones(features))\n",
    "        self.beta=nn.Parameter(torch.zeros(features))\n",
    "        self.eps=eps\n",
    "    def forward(self,X):\n",
    "        mean=X.mean(-1,keepdim=True)\n",
    "        std=X.std(-1,keepdim=True)\n",
    "        return self.gamma*(X-mean)/(std+self.eps)+self.beta\n",
    "    \n",
    "class MLPAttentionPool(nn.Module):\n",
    "    def __init__(self,key_size,units):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(nn.Linear(key_size,units,bias=False),\n",
    "                                  nn.Tanh(),\n",
    "                                  nn.Linear(units,1,bias=False))\n",
    "        \n",
    "    def masked_softmax_1d(self, X, valid_len):\n",
    "        if valid_len is None:\n",
    "            return F.softmax(X,dim=-1), _\n",
    "        else:\n",
    "            shape=X.shape\n",
    "            if valid_len.dim()==1:\n",
    "                valid_len=valid_len.view(-1,1).repeat(1,shape[1])\n",
    "\n",
    "            mask=(torch.arange(0,X.shape[-1]).repeat(X.shape[0],1).to(X.device)<valid_len).byte()\n",
    "            X = X.masked_fill_(~mask, -float('inf'))\n",
    "            return F.softmax(X,dim=-1).view(shape), mask\n",
    "\n",
    "    def forward(self, key, valid_len):\n",
    "        scores = self.proj(key).squeeze(-1)\n",
    "        attention_weights, mask = self.masked_softmax_1d(scores,valid_len)\n",
    "        seq_out = attention_weights.unsqueeze(-1) * key\n",
    "        return seq_out.sum(1)\n",
    "\n",
    "class GeLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1. + torch.tanh(x * 0.7978845608 * (1. + 0.044715 * x * x)))\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super().__init__()\n",
    "        hidden = 128\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_feature, hidden),\n",
    "            GeLU(),\n",
    "            nn.Dropout(args.dropout_rate),\n",
    "            nn.Linear(hidden, out_feature)\n",
    "        )\n",
    "        self.dense.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)\n",
    "\n",
    "class UserNetwork(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        n_dim = df_user_one_hot.shape[1]\n",
    "        self.dense_hidden = Dense(n_dim, config.hidden)\n",
    "\n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "        \n",
    "    def forward(self, input_dict):\n",
    "        \n",
    "        x = input_dict['user_info'].to(args.device)\n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        \n",
    "        hidden = self.dense_hidden(x)\n",
    "        \n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "        \n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return loss, y1, y2, y3, y4, hidden\n",
    "\n",
    "class AppListNetwork(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 64\n",
    "        self.input_size = 100\n",
    "        self.embeddings = nn.Embedding.from_pretrained(app_list_weight)\n",
    "        self.layer_norm = LayerNorm(self.input_size)\n",
    "        \n",
    "#         self.attention_layer = DotProductAttention(0.)\n",
    "#         self.attention_layer = MLPAttention(self.input_size, self.input_size, 256)\n",
    "\n",
    "        self.attention_layer = MLPAttentionPool(self.input_size, config.hidden)\n",
    "        self.dense_hidden = Dense(self.input_size, config.hidden)\n",
    "        \n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "        \n",
    "    def forward(self, input_dict):\n",
    "        app_list_ids = input_dict['app_list'].to(args.device)\n",
    "        app_list_len = input_dict['app_list_len'].to(args.device)\n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "\n",
    "        app_list = self.embeddings(app_list_ids)\n",
    "        app_list = self.layer_norm(app_list)\n",
    "\n",
    "        x = self.attention_layer(app_list, app_list_len)\n",
    "        \n",
    "        hidden = self.dense_hidden(x)        \n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "        \n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return loss, y1, y2, y3, y4, hidden\n",
    "\n",
    "class AppBehaveNetwork(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.hidden_size = config.hidden\n",
    "        self.embeddings = nn.Embedding.from_pretrained(app_behave_weight)        \n",
    "        for i in self.embeddings.parameters():\n",
    "            i.requires_grad=False\n",
    "        \n",
    "        self.qcut_time_embeddings = nn.Embedding(64, 16)\n",
    "        self.cut_time_embeddings = nn.Embedding(64, 16)\n",
    "#         self.action_embeddings = nn.Embedding(2, 4)\n",
    "\n",
    "        \n",
    "        self.layer_norm = LayerNorm(100)\n",
    "        self.rnn = nn.GRU(16 + 16 + 100,\n",
    "                          hidden_size = config.hidden,\n",
    "                          num_layers = 1,\n",
    "                          dropout = 0,\n",
    "                          bidirectional = False, \n",
    "                          batch_first=True)\n",
    "        \n",
    "#         self.attention_layer = DotProductAttention(0.)\n",
    "#         self.attention_layer = MLPAttention(config.hidden, config.hidden, config.hidden)\n",
    "        self.attention_layer = MLPAttentionPool(config.hidden, config.hidden)\n",
    "\n",
    "        self.dense_hidden = Dense(config.hidden, config.hidden)\n",
    "\n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "\n",
    "    def rnn_forward(self, x, x_lens):\n",
    "        X = torch.nn.utils.rnn.pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
    "        hidden, _= self.rnn(X)\n",
    "        hidden, _ = torch.nn.utils.rnn.pad_packed_sequence(hidden,total_length=x.shape[1],batch_first=True)\n",
    "        return hidden\n",
    "   \n",
    "    def forward(self, input_dict):\n",
    "        \n",
    "        app_behave_ids = input_dict['app_behave'].to(args.device)\n",
    "        app_behave_len = input_dict['app_behave_len'].to(args.device)\n",
    "        app_behave_time_cut = input_dict['app_behave_time_cut'].to(args.device)\n",
    "        app_behave_time_qcut = input_dict['app_behave_time_qcut'].to(args.device)\n",
    "#         app_behave_action = input_dict['app_behave_action'].to(args.device)\n",
    "        \n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        \n",
    "        app_behave = self.embeddings(app_behave_ids)\n",
    "#         app_behave = self.layer_norm(app_behave)\n",
    "        cut_time_embed = self.cut_time_embeddings(app_behave_time_cut)\n",
    "        qcut_time_embed = self.cut_time_embeddings(app_behave_time_qcut)\n",
    "#         action_embed = self.action_embeddings(app_behave_action)\n",
    "        \n",
    "        seq_data = torch.cat([\n",
    "            app_behave, \n",
    "            cut_time_embed,\n",
    "            qcut_time_embed,\n",
    "#             action_embed,\n",
    "        ], dim = -1)\n",
    "        \n",
    "        \n",
    "        rnn_out = self.rnn_forward(seq_data, app_behave_len)\n",
    "        \n",
    "        x = self.attention_layer(rnn_out, app_behave_len)\n",
    "#         mask = make_mask(x, app_behave_len)\n",
    "#         x = x.masked_fill_(~mask, 0).sum(1)\n",
    "\n",
    "        \n",
    "        hidden = self.dense_hidden(x)\n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "        \n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return loss, y1, y2, y3, y4, hidden\n",
    "\n",
    "class UserlogNetwork(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.hidden_size = config.hidden\n",
    "        self.embeddings = nn.Embedding.from_pretrained(userlog_weight)        \n",
    "#         for i in self.embeddings.parameters():\n",
    "#             i.requires_grad=False\n",
    "        self.embeddings_day_qcut = nn.Embedding(9, 8)\n",
    "        self.embeddings_day_cut = nn.Embedding(9, 8)\n",
    "        self.embeddings_second_qcut = nn.Embedding(33, 16)\n",
    "        self.embeddings_second_cut = nn.Embedding(33, 16)\n",
    "\n",
    "        \n",
    "        self.layer_norm = LayerNorm(100)\n",
    "        self.rnn = nn.GRU(100 + 8 + 16 + 8 + 16,\n",
    "                          hidden_size = config.hidden,\n",
    "                          num_layers = 1,\n",
    "                          dropout = 0,\n",
    "                          bidirectional = False, \n",
    "                          batch_first=True)\n",
    "        \n",
    "#         self.attention_layer = DotProductAttention(0.)\n",
    "#         self.attention_layer = MLPAttention(config.hidden, config.hidden, config.hidden)\n",
    "        self.attention_layer = MLPAttentionPool(config.hidden, config.hidden)\n",
    "\n",
    "        self.dense_hidden = Dense(config.hidden, config.hidden)\n",
    "\n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "\n",
    "    def rnn_forward(self, x, x_lens):\n",
    "        X = torch.nn.utils.rnn.pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
    "        hidden, _= self.rnn(X)\n",
    "        hidden, _ = torch.nn.utils.rnn.pad_packed_sequence(hidden,total_length=x.shape[1],batch_first=True)\n",
    "        return hidden\n",
    "   \n",
    "    def forward(self, input_dict):\n",
    "        \n",
    "        userlog_action_id = input_dict['userlog'].to(args.device)\n",
    "        userlog_len = input_dict['userlog_len'].to(args.device)\n",
    "        userlog_day_qcut_id = input_dict['userlog_day_qcut'].to(args.device)\n",
    "        userlog_day_cut_id = input_dict['userlog_day_cut'].to(args.device)\n",
    "        userlog_second_qcut_id = input_dict['userlog_second_qcut'].to(args.device)\n",
    "        userlog_second_cut_id = input_dict['userlog_second_cut'].to(args.device)\n",
    "\n",
    "        \n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        \n",
    "        userlog_action = self.embeddings(userlog_action_id)\n",
    "#         app_behave = self.layer_norm(app_behave)\n",
    "        userlog_day_qcut = self.embeddings_day_qcut(userlog_day_qcut_id)\n",
    "        userlog_day_cut = self.embeddings_day_cut(userlog_day_cut_id)\n",
    "        userlog_second_qcut = self.embeddings_second_qcut(userlog_second_qcut_id)\n",
    "        userlog_second_cut = self.embeddings_second_cut(userlog_second_cut_id)\n",
    "        hidden = torch.cat([\n",
    "            userlog_action,\n",
    "            userlog_day_qcut,\n",
    "            userlog_day_cut,\n",
    "            userlog_second_qcut,\n",
    "            userlog_second_cut], dim = -1)\n",
    "        \n",
    "    \n",
    "        rnn_out = self.rnn_forward(hidden, userlog_len)\n",
    "        \n",
    "        x = self.attention_layer(rnn_out, userlog_len)\n",
    "#         mask = make_mask(x, app_behave_len)\n",
    "#         x = x.masked_fill_(~mask, 0).sum(1)\n",
    "\n",
    "        \n",
    "        hidden = self.dense_hidden(x)\n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "         \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "        \n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return loss, y1, y2, y3, y4, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interactive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [
     0,
     19,
     32,
     49,
     191
    ]
   },
   "outputs": [],
   "source": [
    "class Alignment(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.tensor(1 / math.sqrt(config.hidden)))\n",
    "        self.summary = {}\n",
    "\n",
    "    def _attention(self, a, b):\n",
    "        return torch.matmul(a, b.transpose(1, 2)) * self.temperature\n",
    "    \n",
    "    def forward(self, a, b, mask_a, mask_b):\n",
    "        attn = self._attention(a, b)\n",
    "        mask = torch.matmul(mask_a.float(), mask_b.transpose(1, 2).float()).byte()\n",
    "        attn.masked_fill_(~mask, -1e7)\n",
    "        attn_a = F.softmax(attn, dim=1)\n",
    "        attn_b = F.softmax(attn, dim=2)\n",
    "        feature_b = torch.matmul(attn_a.transpose(1, 2), a)\n",
    "        feature_a = torch.matmul(attn_b, b)\n",
    "        return feature_a, feature_b\n",
    "\n",
    "class MappedAlignment(Alignment):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Dropout(args.dropout_rate),\n",
    "            Dense(config.hidden, config.hidden),\n",
    "        )\n",
    "\n",
    "    def _attention(self, a, b):\n",
    "        a = self.projection(a)\n",
    "        b = self.projection(b)\n",
    "        return super()._attention(a, b)\n",
    "\n",
    "class FullFusion(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dropout = args.dropout_rate\n",
    "        self.fusion1 = Dense(config.hidden * 2, config.hidden)\n",
    "        self.fusion2 = Dense(config.hidden * 2, config.hidden)\n",
    "        self.fusion3 = Dense(config.hidden * 2, config.hidden)\n",
    "        self.fusion = Dense(config.hidden * 3, config.hidden)\n",
    "\n",
    "    def forward(self, x, align):\n",
    "        x1 = self.fusion1(torch.cat([x, align], dim=-1))\n",
    "        x2 = self.fusion2(torch.cat([x, x - align], dim=-1))\n",
    "        x3 = self.fusion3(torch.cat([x, x * align], dim=-1))\n",
    "        x = torch.cat([x1, x2, x3], dim=-1)\n",
    "        x = F.dropout(x, self.dropout, self.training)\n",
    "        return self.fusion(x)\n",
    "\n",
    "class AppConcat(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.applist_embeddings = nn.Embedding.from_pretrained(app_list_weight)\n",
    "        self.appbehave_embeddings = nn.Embedding.from_pretrained(app_behave_weight)\n",
    "        for i in self.applist_embeddings.parameters():\n",
    "            i.requires_grad=False\n",
    "        for i in self.appbehave_embeddings.parameters():\n",
    "            i.requires_grad=False\n",
    "        \n",
    "\n",
    "        self.qcut_time_embeddings = nn.Embedding(64, 16)\n",
    "        self.cut_time_embeddings = nn.Embedding(64, 16)\n",
    "        self.action_embeddings = nn.Embedding(2, 4)\n",
    "        \n",
    "        self.app_list_qcut_embed_list = nn.ModuleList([nn.Embedding(17, 16) for _ in range(4)])\n",
    "        self.app_behave_qcut_embed_list = nn.ModuleList([nn.Embedding(17, 16) for _ in range(4)])\n",
    "\n",
    "        self.app_list_encoder = Dense(100, config.hidden)\n",
    "#         self.app_list_encoder = Dense(16 * 4, config.hidden)\n",
    "        self.attention_layer1 = MLPAttentionPool(config.hidden, config.hidden)\n",
    "        self.attention_layer2 = MLPAttentionPool(config.hidden, config.hidden)\n",
    "\n",
    "\n",
    "        self.rnn = nn.GRU(16 + 16 + 100,\n",
    "#         self.rnn = nn.GRU(16 * 4,\n",
    "                          hidden_size = config.hidden,\n",
    "                          num_layers = 1,\n",
    "                          dropout = 0,\n",
    "                          bidirectional = False, \n",
    "                          batch_first=True)        \n",
    "        \n",
    "        \n",
    "        self.dense = Dense(config.hidden * 2, config.hidden)\n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "        \n",
    "    def rnn_forward(self, x, x_lens):\n",
    "        X = torch.nn.utils.rnn.pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
    "        hidden, _= self.rnn(X)\n",
    "        hidden, _ = torch.nn.utils.rnn.pad_packed_sequence(hidden,total_length=x.shape[1],batch_first=True)\n",
    "        return hidden\n",
    "    \n",
    "    def maxpool(self, x, mask):\n",
    "        return x.masked_fill_(~mask, -float('inf')).max(dim=1)[0]\n",
    "\n",
    "    def app_behave_encode(self, input_dict):\n",
    "        app_behave_ids = input_dict['app_behave'].to(args.device)\n",
    "        app_behave_len = input_dict['app_behave_len'].to(args.device)\n",
    "        app_behave_time_cut = input_dict['app_behave_time_cut'].to(args.device)\n",
    "        app_behave_time_qcut = input_dict['app_behave_time_qcut'].to(args.device)\n",
    "        app_behave_action = input_dict['app_behave_action'].to(args.device)\n",
    "   \n",
    "#         app_behave_target_encode = input_dict['app_behave_target_encode'].to(args.device)\n",
    "        \n",
    "        app_behave_target_qcut = input_dict['app_behave_te_qcut'].to(args.device)\n",
    "\n",
    "#         app_behave_target_qcut_embed1 = self.app_behave_qcut_embed_list[0](app_behave_target_qcut[:, :, 0])\n",
    "#         app_behave_target_qcut_embed2 = self.app_behave_qcut_embed_list[1](app_behave_target_qcut[:, :, 1])\n",
    "#         app_behave_target_qcut_embed3 = self.app_behave_qcut_embed_list[2](app_behave_target_qcut[:, :, 2])\n",
    "#         app_behave_target_qcut_embed4 = self.app_behave_qcut_embed_list[3](app_behave_target_qcut[:, :, 3])\n",
    "\n",
    "        app_behave = self.appbehave_embeddings(app_behave_ids)\n",
    "        cut_time_embed = self.cut_time_embeddings(app_behave_time_cut)\n",
    "        qcut_time_embed = self.cut_time_embeddings(app_behave_time_qcut)\n",
    "#         action_embed = self.action_embeddings(app_behave_action)\n",
    "        \n",
    "        seq_data = torch.cat([\n",
    "            app_behave, \n",
    "            cut_time_embed,\n",
    "            qcut_time_embed,\n",
    "#             app_behave_target_qcut_embed1,\n",
    "#             app_behave_target_qcut_embed2,\n",
    "#             app_behave_target_qcut_embed3,\n",
    "#             app_behave_target_qcut_embed4,\n",
    "#             app_behave_target_encode,\n",
    "#             action_embed,\n",
    "        ], dim = -1)\n",
    "        \n",
    "        rnn_out = self.rnn_forward(seq_data, app_behave_len)\n",
    "\n",
    "        return rnn_out, app_behave_len\n",
    "    \n",
    "    def app_list_encode(self, input_dict):\n",
    "        app_list_ids = input_dict['app_list'].to(args.device)\n",
    "        app_list_len = input_dict['app_list_len'].to(args.device)\n",
    "        app_list_embed = self.applist_embeddings(app_list_ids)\n",
    "        \n",
    "        app_list_target_qcut = input_dict['app_list_te_qcut'].to(args.device)\n",
    "#         app_list_target_encode = input_dict['app_list_target_encode'].to(args.device)\n",
    "\n",
    "        app_list_target_qcut_embed1 = self.app_list_qcut_embed_list[0](app_list_target_qcut[:, :, 0])\n",
    "        app_list_target_qcut_embed2 = self.app_list_qcut_embed_list[1](app_list_target_qcut[:, :, 1])\n",
    "        app_list_target_qcut_embed3 = self.app_list_qcut_embed_list[2](app_list_target_qcut[:, :, 2])\n",
    "        app_list_target_qcut_embed4 = self.app_list_qcut_embed_list[3](app_list_target_qcut[:, :, 3])\n",
    "\n",
    "        seq_data = torch.cat([\n",
    "            app_list_embed, \n",
    "#             app_list_target_encode,\n",
    "#             app_list_target_qcut_embed1,\n",
    "#             app_list_target_qcut_embed2,\n",
    "#             app_list_target_qcut_embed3,\n",
    "#             app_list_target_qcut_embed4,\n",
    "\n",
    "        ], dim = -1)\n",
    "        \n",
    "        return self.app_list_encoder(seq_data), app_list_len \n",
    "    \n",
    "\n",
    "    def forward(self, input_dict):\n",
    "        a, a_len = self.app_behave_encode(input_dict)\n",
    "        b, b_len = self.app_list_encode(input_dict)\n",
    "#         mask_a = self.make_mask(a, a_len)\n",
    "#         mask_b = self.make_mask(b, b_len)\n",
    "                \n",
    "        a = self.attention_layer1(a, a_len)\n",
    "        b = self.attention_layer2(b, b_len)\n",
    "        \n",
    "        hidden = self.dense(torch.cat([a, b], dim=-1)) \n",
    "\n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        \n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "        \n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return loss, y1, y2, y3, y4, hidden\n",
    "    \n",
    "class AppInteractiveNetwork(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.applist_embeddings = nn.Embedding.from_pretrained(app_list_weight)\n",
    "        self.appbehave_embeddings = nn.Embedding.from_pretrained(app_behave_weight)\n",
    "        for i in self.applist_embeddings.parameters():\n",
    "            i.requires_grad=False\n",
    "        for i in self.appbehave_embeddings.parameters():\n",
    "            i.requires_grad=False\n",
    "        \n",
    "\n",
    "        self.qcut_time_embeddings = nn.Embedding(64, 16)\n",
    "        self.cut_time_embeddings = nn.Embedding(64, 16)\n",
    "        self.action_embeddings = nn.Embedding(2, 4)\n",
    "        \n",
    "        self.app_list_qcut_embed_list = nn.ModuleList([nn.Embedding(17, 16) for _ in range(4)])\n",
    "        self.app_behave_qcut_embed_list = nn.ModuleList([nn.Embedding(17, 16) for _ in range(4)])\n",
    "\n",
    "        self.app_list_encoder = Dense(100, config.hidden)\n",
    "#         self.app_list_encoder = Dense(16 * 4, config.hidden)\n",
    "\n",
    "\n",
    "        self.rnn = nn.GRU(16 + 16 + 100,\n",
    "#         self.rnn = nn.GRU(16 * 4,\n",
    "                          hidden_size = config.hidden,\n",
    "                          num_layers = 1,\n",
    "                          dropout = 0,\n",
    "                          bidirectional = False, \n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.alignment_layer = MappedAlignment(config)\n",
    "        self.fusion_layer = FullFusion(config)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.dense = Dense(config.hidden * 4, config.hidden)\n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "        \n",
    "    def rnn_forward(self, x, x_lens):\n",
    "        X = torch.nn.utils.rnn.pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
    "        hidden, _= self.rnn(X)\n",
    "        hidden, _ = torch.nn.utils.rnn.pad_packed_sequence(hidden,total_length=x.shape[1],batch_first=True)\n",
    "        return hidden\n",
    "    \n",
    "    def maxpool(self, x, mask):\n",
    "        return x.masked_fill_(~mask, -float('inf')).max(dim=1)[0]\n",
    "\n",
    "    def app_behave_encode(self, input_dict):\n",
    "        app_behave_ids = input_dict['app_behave'].to(args.device)\n",
    "        app_behave_len = input_dict['app_behave_len'].to(args.device)\n",
    "        app_behave_time_cut = input_dict['app_behave_time_cut'].to(args.device)\n",
    "        app_behave_time_qcut = input_dict['app_behave_time_qcut'].to(args.device)\n",
    "        app_behave_action = input_dict['app_behave_action'].to(args.device)\n",
    "   \n",
    "#         app_behave_target_encode = input_dict['app_behave_target_encode'].to(args.device)\n",
    "        \n",
    "#         app_behave_target_qcut = input_dict['app_behave_te_qcut'].to(args.device)\n",
    "\n",
    "#         app_behave_target_qcut_embed1 = self.app_behave_qcut_embed_list[0](app_behave_target_qcut[:, :, 0])\n",
    "#         app_behave_target_qcut_embed2 = self.app_behave_qcut_embed_list[1](app_behave_target_qcut[:, :, 1])\n",
    "#         app_behave_target_qcut_embed3 = self.app_behave_qcut_embed_list[2](app_behave_target_qcut[:, :, 2])\n",
    "#         app_behave_target_qcut_embed4 = self.app_behave_qcut_embed_list[3](app_behave_target_qcut[:, :, 3])\n",
    "\n",
    "        app_behave = self.appbehave_embeddings(app_behave_ids)\n",
    "        cut_time_embed = self.cut_time_embeddings(app_behave_time_cut)\n",
    "        qcut_time_embed = self.cut_time_embeddings(app_behave_time_qcut)\n",
    "#         action_embed = self.action_embeddings(app_behave_action)\n",
    "        \n",
    "        seq_data = torch.cat([\n",
    "            app_behave, \n",
    "            cut_time_embed,\n",
    "            qcut_time_embed,\n",
    "#             app_behave_target_qcut_embed1,\n",
    "#             app_behave_target_qcut_embed2,\n",
    "#             app_behave_target_qcut_embed3,\n",
    "#             app_behave_target_qcut_embed4,\n",
    "#             app_behave_target_encode,\n",
    "#             action_embed,\n",
    "        ], dim = -1)\n",
    "        \n",
    "        rnn_out = self.rnn_forward(seq_data, app_behave_len)\n",
    "\n",
    "        return rnn_out, app_behave_len\n",
    "    \n",
    "    def app_list_encode(self, input_dict):\n",
    "        app_list_ids = input_dict['app_list'].to(args.device)\n",
    "        app_list_len = input_dict['app_list_len'].to(args.device)\n",
    "        app_list_embed = self.applist_embeddings(app_list_ids)\n",
    "        \n",
    "        app_list_target_qcut = input_dict['app_list_te_qcut'].to(args.device)\n",
    "#         app_list_target_encode = input_dict['app_list_target_encode'].to(args.device)\n",
    "\n",
    "        app_list_target_qcut_embed1 = self.app_list_qcut_embed_list[0](app_list_target_qcut[:, :, 0])\n",
    "        app_list_target_qcut_embed2 = self.app_list_qcut_embed_list[1](app_list_target_qcut[:, :, 1])\n",
    "        app_list_target_qcut_embed3 = self.app_list_qcut_embed_list[2](app_list_target_qcut[:, :, 2])\n",
    "        app_list_target_qcut_embed4 = self.app_list_qcut_embed_list[3](app_list_target_qcut[:, :, 3])\n",
    "\n",
    "        seq_data = torch.cat([\n",
    "            app_list_embed, \n",
    "#             app_list_target_encode,\n",
    "#             app_list_target_qcut_embed1,\n",
    "#             app_list_target_qcut_embed2,\n",
    "#             app_list_target_qcut_embed3,\n",
    "#             app_list_target_qcut_embed4,\n",
    "\n",
    "        ], dim = -1)\n",
    "        \n",
    "        return self.app_list_encoder(seq_data), app_list_len \n",
    "    \n",
    "    def make_mask(self, X, valid_len):\n",
    "        shape=X.shape\n",
    "        if valid_len.dim()==1:\n",
    "            valid_len=valid_len.view(-1,1).repeat(1,shape[1])\n",
    "        mask=(torch.arange(0,X.shape[1]).repeat(X.shape[0],1).to(X.device)<valid_len).float()\n",
    "        return mask.unsqueeze(2).byte()\n",
    "\n",
    "    def forward(self, input_dict):\n",
    "        a, a_len = self.app_behave_encode(input_dict)\n",
    "        b, b_len = self.app_list_encode(input_dict)\n",
    "        mask_a = self.make_mask(a, a_len)\n",
    "        mask_b = self.make_mask(b, b_len)\n",
    "        \n",
    "        align_a, align_b = self.alignment_layer(a, b, mask_a, mask_b)\n",
    "        a = self.fusion_layer(a, align_a)\n",
    "        b = self.fusion_layer(b, align_b)\n",
    "        \n",
    "        a = self.maxpool(a, mask_a)\n",
    "        b = self.maxpool(b, mask_b)\n",
    "        \n",
    "        hidden = self.dense(torch.cat([a, b, (a - b).abs(), a * b], dim=-1)) #symmetric\n",
    "\n",
    "\n",
    "        \n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        \n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "        \n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "        \n",
    "        return loss, y1, y2, y3, y4, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi-view model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "code_folding": [
     0,
     17,
     33,
     84,
     136,
     196,
     270,
     346,
     360,
     440
    ]
   },
   "outputs": [],
   "source": [
    "class MaskMlpAttention(nn.Module):\n",
    "    def __init__(self, key_size, units):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(nn.Linear(key_size,units,bias=False),\n",
    "                                  nn.Tanh(),\n",
    "                                  nn.Linear(units,1,bias=False))\n",
    "        \n",
    "    def forward(self, key, mask):\n",
    "        scores = self.proj(key).squeeze(-1)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill_(~mask.byte(), -float('inf'))\n",
    "            \n",
    "        softmax_score = F.softmax(scores, dim=-1)\n",
    "        seq_out = softmax_score.unsqueeze(-1) * key\n",
    "        return seq_out.sum(1)\n",
    "\n",
    "class MaskMultiViewEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.user_network = config.user_net\n",
    "        self.app_list_network = config.app_list_net\n",
    "        self.app_behave_network = config.app_behave_net\n",
    "        self.userlog_network = config.userlog_network\n",
    "        \n",
    "    def forward(self,input_dict):\n",
    "        loss_user, y1_user, y2_user, y3_user, y4_user, hidden_user = self.user_network(input_dict)\n",
    "        loss_list, y1_list, y2_list, y3_list, y4_list, hidden_list = self.app_list_network(input_dict)\n",
    "        loss_behave, y1_behave, y2_behave, y3_behave, y4_behave, hidden_behave = self.app_behave_network(input_dict)\n",
    "        loss_userlog, y1_userlog, y2_userlog, y3_userlog, y4_userlog, hidden_userlog = self.userlog_network(input_dict)\n",
    "\n",
    "        return hidden_user, hidden_list, hidden_behave, hidden_userlog\n",
    "    \n",
    "class MaskMultiViewNetwork(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "#         self.user_network = UserNetwork(config)\n",
    "#         self.app_list_network = AppListNetwork(config)\n",
    "#         self.app_behave_network = AppBehaveNetwork(config)\n",
    "        \n",
    "        self.multiview_encoder = MaskMultiViewEncoder(config)\n",
    "\n",
    "        self.attention = MaskMlpAttention(config.hidden, config.hidden)\n",
    "#         self.attention = MaskMlpAttentionSeperateMap(config.hidden, config.hidden, 3)\n",
    "\n",
    "        self.dense = Dense(config.hidden, config.hidden)\n",
    "        \n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "        \n",
    "    def forward(self, input_dict):\n",
    "        \n",
    "        hidden_user, hidden_list, hidden_behave, hidden_userlog = self.multiview_encoder(input_dict)\n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        view_mask = input_dict['view_mask'].to(args.device)\n",
    "        \n",
    "        multi_view_hidden = torch.cat([hidden_user, hidden_list, hidden_behave, hidden_userlog], dim = 1).view(-1, 4, hidden_user.shape[1])\n",
    "        hidden = self.attention(multi_view_hidden, view_mask)\n",
    "\n",
    "        #         hidden = self.attention([hidden_user, hidden_list, hidden_behave], view_mask)\n",
    "#         hidden = torch.cat([hidden_user, hidden_list, hidden_behave], dim = 1)\n",
    "        hidden = self.dense(hidden)\n",
    "\n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "\n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "\n",
    "        return loss, y1, y2, y3, y4, _\n",
    "\n",
    "class MaskMultiViewNetworkFillZero(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "#         self.user_network = UserNetwork(config)\n",
    "#         self.app_list_network = AppListNetwork(config)\n",
    "#         self.app_behave_network = AppBehaveNetwork(config)\n",
    "        \n",
    "        self.multiview_encoder = MaskMultiViewEncoder(config)\n",
    "\n",
    "        self.dense = Dense(config.hidden * 4, config.hidden)\n",
    "        \n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "        \n",
    "    def forward(self, input_dict):\n",
    "        \n",
    "        hidden_user, hidden_list, hidden_behave, hidden_userlog = self.multiview_encoder(input_dict)\n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        view_mask = input_dict['view_mask'].to(args.device)\n",
    "        \n",
    "        hidden_user = view_mask[:, 0:1].float() * hidden_user\n",
    "        hidden_list = view_mask[:, 1:2].float() * hidden_list\n",
    "        hidden_behave = view_mask[:, 2:3].float() * hidden_behave\n",
    "        hidden_userlog = view_mask[:, 3:4].float() * hidden_userlog\n",
    "\n",
    "        multi_view_hidden = torch.cat([hidden_user, hidden_list, hidden_behave, hidden_userlog], dim = 1)\n",
    "\n",
    "        #         hidden = self.attention([hidden_user, hidden_list, hidden_behave], view_mask)\n",
    "#         hidden = torch.cat([hidden_user, hidden_list, hidden_behave], dim = 1)\n",
    "        hidden = self.dense(multi_view_hidden)\n",
    "\n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "\n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "\n",
    "        return loss, y1, y2, y3, y4, _\n",
    "\n",
    "class MaskMultiViewNetworkFillZeroIn(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "#         self.user_network = UserNetwork(config)\n",
    "#         self.app_list_network = AppListNetwork(config)\n",
    "#         self.app_behave_network = AppBehaveNetwork(config)\n",
    "        \n",
    "        self.multiview_encoder = MaskMultiViewEncoderAppInteractive(config)\n",
    "\n",
    "    \n",
    "        self.dense = Dense(3 * config.hidden, config.hidden)\n",
    "        \n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "        \n",
    "    def get_3view_mask(self, mask):\n",
    "        ret = torch.zeros((mask.shape[0], 3))\n",
    "        ret[:, 0] = mask[:, 0]\n",
    "        ret[:, 1] = (mask[:, 1] + mask[:, 2]) >= 1\n",
    "        ret[:, -1] = mask[:, -1]\n",
    "        return ret\n",
    "\n",
    "    \n",
    "    def forward(self, input_dict):\n",
    "        \n",
    "        hidden_user, hidden_app, hidden_userlog = self.multiview_encoder(input_dict)\n",
    "        \n",
    "        view_mask = self.get_3view_mask(input_dict['view_mask']).to(args.device)\n",
    "        hidden_user = view_mask[:, 0:1].float() * hidden_user\n",
    "        hidden_app = view_mask[:, 1:2].float() * hidden_app\n",
    "        hidden_userlog = view_mask[:, 2:3].float() * hidden_userlog\n",
    "\n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        \n",
    "        multi_view_hidden = torch.cat([hidden_user, hidden_app, hidden_userlog], dim = 1)\n",
    "\n",
    "        \n",
    "        hidden = self.dense(multi_view_hidden)\n",
    "        \n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "\n",
    "        loss = loss1 + loss2 + loss3 + loss4\n",
    "\n",
    "        return loss, y1, y2, y3, y4, _\n",
    "\n",
    "class MaskMultiViewNetworkGenerate(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "#         self.user_network = UserNetwork(config)\n",
    "#         self.app_list_network = AppListNetwork(config)\n",
    "#         self.app_behave_network = AppBehaveNetwork(config)\n",
    "        \n",
    "        self.multiview_encoder = MaskMultiViewEncoder(config)\n",
    "\n",
    "        self.attention_pool1 = MaskMlpAttention(config.hidden, config.hidden)\n",
    "#         self.attention = MaskMlpAttentionSeperateMap(config.hidden, config.hidden, 3)\n",
    "        self.attention_pool2 = MaskMlpAttention(config.hidden, config.hidden)\n",
    "\n",
    "    \n",
    "        self.decoder_user_info = Dense(config.hidden, config.hidden)\n",
    "        self.decoder_app_list = Dense(config.hidden, config.hidden)\n",
    "        self.decoder_app_behave = Dense(config.hidden, config.hidden)\n",
    "        self.decoder_user_log = Dense(config.hidden, config.hidden)\n",
    "\n",
    "        self.dense = Dense(config.hidden, config.hidden)\n",
    "        \n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "        \n",
    "    def forward(self, input_dict):\n",
    "        \n",
    "        hidden_user, hidden_list, hidden_behave, hidden_userlog = self.multiview_encoder(input_dict)\n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        view_mask = input_dict['view_mask'].to(args.device)\n",
    "        \n",
    "        multi_view_hidden = torch.stack([hidden_user, hidden_list, hidden_behave, hidden_userlog], dim = 1)\n",
    "\n",
    "        hidden = self.attention_pool1(multi_view_hidden, view_mask)\n",
    "\n",
    "        #         hidden = self.attention([hidden_user, hidden_list, hidden_behave], view_mask)\n",
    "#         hidden = torch.cat([hidden_user, hidden_list, hidden_behave], dim = 1)\n",
    "\n",
    "        generate_user = self.decoder_user_info(hidden)\n",
    "        generate_list = self.decoder_app_list(hidden)\n",
    "        generate_behave = self.decoder_app_behave(hidden)\n",
    "        generate_userlog = self.decoder_user_log(hidden)\n",
    "        \n",
    "        \n",
    "        loss_rebuild_user = (hidden_user - generate_user) ** 2 * view_mask[:, 0:1].float()\n",
    "        loss_rebuild_list = (hidden_list - generate_list) ** 2 * view_mask[:, 1:2].float()\n",
    "        loss_rebuild_behave = (hidden_behave - generate_behave) ** 2 * view_mask[:, 2:3].float()\n",
    "        loss_rebuild_userlog = (hidden_userlog - generate_userlog) ** 2 * view_mask[:, 3:4].float()\n",
    "        loss_rebuild = loss_rebuild_user.mean() + loss_rebuild_list.mean() + loss_rebuild_behave.mean() + loss_rebuild_userlog.mean()\n",
    "        \n",
    "        multi_view_hidden_generate = torch.stack([generate_user, generate_list, generate_behave, generate_userlog], dim = 1)\n",
    "        hidden_generate = self.attention_pool2(multi_view_hidden_generate, None)\n",
    "        hidden = self.dense(hidden_generate)\n",
    "\n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "\n",
    "        loss = loss1 + loss2 + loss3 + loss4 + loss_rebuild\n",
    "\n",
    "        return loss, y1, y2, y3, y4, _\n",
    "\n",
    "class MaskMultiViewNetworkGenerateWithResidual(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "#         self.user_network = UserNetwork(config)\n",
    "#         self.app_list_network = AppListNetwork(config)\n",
    "#         self.app_behave_network = AppBehaveNetwork(config)\n",
    "        \n",
    "        self.multiview_encoder = MaskMultiViewEncoder(config)\n",
    "\n",
    "        self.attention_pool1 = MaskMlpAttention(config.hidden, config.hidden)\n",
    "#         self.attention = MaskMlpAttentionSeperateMap(config.hidden, config.hidden, 3)\n",
    "        self.attention_pool2 = MaskMlpAttention(config.hidden, config.hidden)\n",
    "\n",
    "    \n",
    "        self.decoder_user_info = Dense(config.hidden, config.hidden)\n",
    "        self.decoder_app_list = Dense(config.hidden, config.hidden)\n",
    "        self.decoder_app_behave = Dense(config.hidden, config.hidden)\n",
    "        self.decoder_user_log = Dense(config.hidden, config.hidden)\n",
    "\n",
    "        self.dense = Dense(config.hidden, config.hidden)\n",
    "        \n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "                \n",
    "    def forward(self, input_dict):\n",
    "        \n",
    "        hidden_user, hidden_list, hidden_behave, hidden_userlog = self.multiview_encoder(input_dict)\n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        view_mask = input_dict['view_mask'].to(args.device)\n",
    "        \n",
    "        multi_view_hidden = torch.stack([hidden_user, hidden_list, hidden_behave, hidden_userlog], dim = 1)\n",
    "\n",
    "        hidden = self.attention_pool1(multi_view_hidden, view_mask)\n",
    "\n",
    "        #         hidden = self.attention([hidden_user, hidden_list, hidden_behave], view_mask)\n",
    "#         hidden = torch.cat([hidden_user, hidden_list, hidden_behave], dim = 1)\n",
    "\n",
    "        generate_user = self.decoder_user_info(hidden)\n",
    "        generate_list = self.decoder_app_list(hidden)\n",
    "        generate_behave = self.decoder_app_behave(hidden)\n",
    "        generate_userlog = self.decoder_user_log(hidden)\n",
    "        \n",
    "        \n",
    "        loss_rebuild_user = (hidden_user - generate_user) ** 2 * view_mask[:, 0:1].float()\n",
    "        loss_rebuild_list = (hidden_list - generate_list) ** 2 * view_mask[:, 1:2].float()\n",
    "        loss_rebuild_behave = (hidden_behave - generate_behave) ** 2 * view_mask[:, 2:3].float()\n",
    "        loss_rebuild_userlog = (hidden_userlog - generate_userlog) ** 2 * view_mask[:, 3:4].float()\n",
    "        loss_rebuild = loss_rebuild_user.mean() + loss_rebuild_list.mean() + loss_rebuild_behave.mean() + loss_rebuild_userlog.mean()\n",
    "        \n",
    "        multi_view_hidden_generate = torch.stack([generate_user, generate_list, generate_behave, generate_userlog], dim = 1)\n",
    "        hidden_generate = self.attention_pool2(multi_view_hidden_generate, None)\n",
    "        \n",
    "        hidden = hidden + hidden_generate\n",
    "        hidden = self.dense(hidden)\n",
    "        \n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "\n",
    "        loss = loss1 + loss2 + loss3 + loss4 + loss_rebuild\n",
    "\n",
    "        return loss, y1, y2, y3, y4, _\n",
    "\n",
    "class MaskMultiViewEncoderAppInteractive(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.user_network = config.user_net\n",
    "        self.app_network = config.app_net\n",
    "        self.userlog_network = config.userlog_network\n",
    "        \n",
    "    def forward(self,input_dict):\n",
    "        loss_user, y1_user, y2_user, y3_user, y4_user, hidden_user = self.user_network(input_dict)\n",
    "        loss_app, y1_app, y2_app, y3_app, y4_app, hidden_app = self.app_network(input_dict)\n",
    "        loss_userlog, y1_userlog, y2_userlog, y3_userlog, y4_userlog, hidden_userlog = self.userlog_network(input_dict)\n",
    "\n",
    "        return hidden_user, hidden_app, hidden_userlog\n",
    "\n",
    "class MaskMultiViewNetworkGenerateWithResidualAppInteractive(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "#         self.user_network = UserNetwork(config)\n",
    "#         self.app_list_network = AppListNetwork(config)\n",
    "#         self.app_behave_network = AppBehaveNetwork(config)\n",
    "        \n",
    "        self.multiview_encoder = MaskMultiViewEncoderAppInteractive(config)\n",
    "\n",
    "        self.attention_pool1 = MaskMlpAttention(config.hidden, config.hidden)\n",
    "#         self.attention = MaskMlpAttentionSeperateMap(config.hidden, config.hidden, 3)\n",
    "        self.attention_pool2 = MaskMlpAttention(config.hidden, config.hidden)\n",
    "    \n",
    "        self.decoder_user_info = Dense(config.hidden, config.hidden)\n",
    "        self.decoder_app = Dense(config.hidden, config.hidden)\n",
    "        self.decoder_user_log = Dense(config.hidden, config.hidden)\n",
    "\n",
    "        self.dense = Dense(config.hidden, config.hidden)\n",
    "        \n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "    \n",
    "    def get_3view_mask(self, mask):\n",
    "        ret = torch.zeros((mask.shape[0], 3))\n",
    "        ret[:, 0] = mask[:, 0]\n",
    "        ret[:, 1] = (mask[:, 1] + mask[:, 2]) >= 1\n",
    "        ret[:, -1] = mask[:, -1]\n",
    "        return ret\n",
    "    \n",
    "    def forward(self, input_dict):\n",
    "        \n",
    "        hidden_user, hidden_app, hidden_userlog = self.multiview_encoder(input_dict)\n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        view_mask = self.get_3view_mask(input_dict['view_mask']).to(args.device)\n",
    "        \n",
    "        multi_view_hidden = torch.stack([hidden_user, hidden_app, hidden_userlog], dim = 1)\n",
    "\n",
    "        hidden = self.attention_pool1(multi_view_hidden, view_mask)\n",
    "\n",
    "        #         hidden = self.attention([hidden_user, hidden_list, hidden_behave], view_mask)\n",
    "#         hidden = torch.cat([hidden_user, hidden_list, hidden_behave], dim = 1)\n",
    "\n",
    "        generate_user = self.decoder_user_info(hidden)\n",
    "        generate_app = self.decoder_app(hidden)\n",
    "        generate_userlog = self.decoder_user_log(hidden)\n",
    "        \n",
    "        \n",
    "        loss_rebuild_user = (hidden_user - generate_user) ** 2 * view_mask[:, 0:1].float()\n",
    "        loss_rebuild_app = (hidden_app - generate_app) ** 2 * view_mask[:, 1:2].float()\n",
    "        loss_rebuild_userlog = (hidden_userlog - generate_userlog) ** 2 * view_mask[:, 2:3].float()\n",
    "        loss_rebuild = loss_rebuild_user.mean() + loss_rebuild_app.mean()  + loss_rebuild_userlog.mean()\n",
    "        \n",
    "        multi_view_hidden_generate = torch.stack([generate_user, generate_app, generate_userlog], dim = 1)\n",
    "        hidden_generate = self.attention_pool2(multi_view_hidden_generate, None)\n",
    "        \n",
    "        hidden = hidden + hidden_generate\n",
    "        hidden = self.dense(hidden)\n",
    "\n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "\n",
    "        loss = loss1 + loss2 + loss3 + loss4 + loss_rebuild\n",
    "\n",
    "        return loss, y1, y2, y3, y4, _\n",
    "\n",
    "class MaskMultiViewNetworkDifferentGeneration(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "#         self.user_network = UserNetwork(config)\n",
    "#         self.app_list_network = AppListNetwork(config)\n",
    "#         self.app_behave_network = AppBehaveNetwork(config)\n",
    "        \n",
    "        self.multiview_encoder = MaskMultiViewEncoderAppInteractive(config)\n",
    "\n",
    "        self.attention_pool1 = MaskMlpAttention(config.hidden, config.hidden)\n",
    "#         self.attention = MaskMlpAttentionSeperateMap(config.hidden, config.hidden, 3)\n",
    "        self.attention_pool2 = MaskMlpAttention(config.hidden, config.hidden)\n",
    "    \n",
    "        self.decoder_user_info = Dense(config.hidden, config.hidden)\n",
    "        self.decoder_app = Dense(config.hidden, config.hidden)\n",
    "        self.decoder_user_log = Dense(config.hidden, config.hidden)\n",
    "\n",
    "        self.dense = Dense(config.hidden, config.hidden)\n",
    "        \n",
    "        self.dense1 = Dense(config.hidden, 2)\n",
    "        self.dense2 = Dense(config.hidden, 2)\n",
    "        self.dense3 = Dense(config.hidden, 2)\n",
    "        self.dense4 = Dense(config.hidden, 2)\n",
    "    \n",
    "    def get_3view_mask(self, mask):\n",
    "        ret = torch.zeros((mask.shape[0], 3))\n",
    "        ret[:, 0] = mask[:, 0]\n",
    "        ret[:, 1] = (mask[:, 1] + mask[:, 2]) >= 1\n",
    "        ret[:, -1] = mask[:, -1]\n",
    "        return ret\n",
    "    \n",
    "    def forward(self, input_dict):\n",
    "        \n",
    "        hidden_user, hidden_app, hidden_userlog = self.multiview_encoder(input_dict)\n",
    "        labels1 = input_dict['labels1'].to(args.device)\n",
    "        labels2 = input_dict['labels2'].to(args.device)\n",
    "        labels3 = input_dict['labels3'].to(args.device)\n",
    "        labels4 = input_dict['labels4'].to(args.device)\n",
    "        view_mask = self.get_3view_mask(input_dict['view_mask']).to(args.device)\n",
    "        \n",
    "        multi_view_hidden = torch.stack([hidden_user, hidden_app, hidden_userlog], dim = 1)\n",
    "        \n",
    "        hidden = self.attention_pool1(multi_view_hidden, view_mask)\n",
    "\n",
    "        #         hidden = self.attention([hidden_user, hidden_list, hidden_behave], view_mask)\n",
    "#         hidden = torch.cat([hidden_user, hidden_list, hidden_behave], dim = 1)\n",
    "        loss_rebuild = 0\n",
    "        generate_views = []\n",
    "        if use_user_attribute:\n",
    "            generate_user = self.decoder_user_info(hidden)\n",
    "            loss_rebuild_user = (hidden_user - generate_user) ** 2 * view_mask[:, 0:1].float()\n",
    "            loss_rebuild += loss_rebuild_user.mean()\n",
    "            generate_views.append(generate_user)\n",
    "        if use_app_list or use_app_behave:\n",
    "            generate_app = self.decoder_app(hidden)\n",
    "            loss_rebuild_app = (hidden_app - generate_app) ** 2 * view_mask[:, 1:2].float()\n",
    "            loss_rebuild += loss_rebuild_app.mean()\n",
    "            generate_views.append(generate_app)\n",
    "\n",
    "        if use_user_log:\n",
    "            generate_userlog = self.decoder_user_log(hidden)\n",
    "            loss_rebuild_userlog = (hidden_userlog - generate_userlog) ** 2 * view_mask[:, 2:3].float()\n",
    "            loss_rebuild += loss_rebuild_userlog.mean()\n",
    "            generate_views.append(generate_userlog)\n",
    "\n",
    "        multi_view_hidden_generate = torch.stack(generate_views, dim = 1)\n",
    "        hidden_generate = self.attention_pool2(multi_view_hidden_generate, None)\n",
    "        \n",
    "        hidden = hidden + hidden_generate\n",
    "        hidden = self.dense(hidden)\n",
    "\n",
    "        y1 = self.dense1(hidden)\n",
    "        y2 = self.dense2(hidden)\n",
    "        y3 = self.dense3(hidden)\n",
    "        y4 = self.dense4(hidden)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss1 = loss_func(y1, labels1.long())\n",
    "        loss2 = loss_func(y2, labels2.long())\n",
    "        loss3 = loss_func(y3, labels3.long())\n",
    "        loss4 = loss_func(y4, labels4.long())\n",
    "\n",
    "        loss = loss1 + loss2 + loss3 + loss4 + loss_rebuild\n",
    "\n",
    "        return loss, y1, y2, y3, y4, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": [
     0,
     98
    ]
   },
   "outputs": [],
   "source": [
    "def eval_data(model, master_ids, epoch = None, save = False, name = None):\n",
    "    \n",
    "    if(len(master_ids) > args.n_eval):\n",
    "        master_ids = random.sample(master_ids, args.n_eval)\n",
    "\n",
    "    torch_dataset = AppDataset(master_ids)\n",
    "    data_loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      \n",
    "        batch_size=args.batch_size,      \n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers = args.n_worker,\n",
    "    )\n",
    "    \n",
    "    loss_list = []\n",
    "    y1_list, y2_list, y3_list, y4_list = [], [], [], []\n",
    "    label1_list, label2_list, label3_list, label4_list = [], [], [], []\n",
    "#     for step, data in enumerate(tqdm(data_loader)):\n",
    "    id_list = []\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(data_loader):\n",
    "            loss, y1, y2, y3, y4, _ = model(data)\n",
    "\n",
    "            loss_list.append(loss.item())\n",
    "            y1_list.append(y1.cpu().detach().numpy())\n",
    "            y2_list.append(y2.cpu().detach().numpy())\n",
    "            y3_list.append(y3.cpu().detach().numpy())\n",
    "            y4_list.append(y4.cpu().detach().numpy())\n",
    "\n",
    "            label1_list.append(data['labels1'].cpu().detach().numpy())\n",
    "            label2_list.append(data['labels2'].cpu().detach().numpy())\n",
    "            label3_list.append(data['labels3'].cpu().detach().numpy())\n",
    "            label4_list.append(data['labels4'].cpu().detach().numpy())\n",
    "            \n",
    "            id_list.append(data['master_ids'])\n",
    "        loss = np.mean(loss_list)\n",
    "    \n",
    "    id_np = np.concatenate(id_list, axis = 0)\n",
    "    y1_np = np.concatenate(y1_list, axis = 0)\n",
    "    y2_np = np.concatenate(y2_list, axis = 0)\n",
    "    y3_np = np.concatenate(y3_list, axis = 0)\n",
    "    y4_np = np.concatenate(y4_list, axis = 0)\n",
    "\n",
    "    labels1_np = np.concatenate(label1_list, axis = 0)\n",
    "    labels2_np = np.concatenate(label2_list, axis = 0)\n",
    "    labels3_np = np.concatenate(label3_list, axis = 0)\n",
    "    labels4_np = np.concatenate(label4_list, axis = 0)\n",
    "    \n",
    "    if save:\n",
    "        df_save = pd.DataFrame({\n",
    "            'id' : id_np,\n",
    "            'y1' : y1_np[:, 1],\n",
    "            'y2' : y2_np[:, 1],\n",
    "            'y3' : y3_np[:, 1],\n",
    "            'y4' : y4_np[:, 1],\n",
    "            'labels1' : labels1_np,\n",
    "            'labels2' : labels2_np,\n",
    "            'labels3' : labels3_np,\n",
    "            'labels4' : labels4_np,\n",
    "        })\n",
    "        pickle.dump(df_save, open('2_data/epoch_%d_%s.pickle' % (epoch, name), 'wb'))\n",
    "        \n",
    "    auc1 = roc_auc_score(labels1_np, y1_np[:, 1])\n",
    "    auc2 = roc_auc_score(labels2_np, y2_np[:, 1])\n",
    "    auc3 = roc_auc_score(labels3_np, y3_np[:, 1])\n",
    "    auc4 = roc_auc_score(labels4_np, y4_np[:, 1])\n",
    "    auc_all = [auc1, auc2, auc3, auc4]\n",
    "    \n",
    "    new_client = np.array(df_master_records['new_client'].loc[master_ids].values)\n",
    "    new_client_auc1 = roc_auc_score(labels1_np[new_client], y1_np[:, 1][new_client])\n",
    "    new_client_auc2 = roc_auc_score(labels2_np[new_client], y2_np[:, 1][new_client])\n",
    "    new_client_auc3 = roc_auc_score(labels3_np[new_client], y3_np[:, 1][new_client])\n",
    "    new_client_auc4 = roc_auc_score(labels4_np[new_client], y4_np[:, 1][new_client])\n",
    "    auc_new_client = [new_client_auc1, new_client_auc2, new_client_auc3, new_client_auc4]\n",
    "\n",
    "    old_client = ~new_client\n",
    "    old_client_auc1 = roc_auc_score(labels1_np[old_client], y1_np[:, 1][old_client])\n",
    "    old_client_auc2 = roc_auc_score(labels2_np[old_client], y2_np[:, 1][old_client])\n",
    "    old_client_auc3 = roc_auc_score(labels3_np[old_client], y3_np[:, 1][old_client])\n",
    "    old_client_auc4 = roc_auc_score(labels4_np[old_client], y4_np[:, 1][old_client])\n",
    "    auc_old_client = [old_client_auc1, old_client_auc2, old_client_auc3, old_client_auc4]\n",
    "\n",
    "    return {\n",
    "        'loss' : loss,\n",
    "        '1m30+' : auc1,\n",
    "        '2m30+' : auc2,\n",
    "        '3m30+' : auc3,\n",
    "        '4m30+' : auc4,\n",
    "        'new_1m30+' : new_client_auc1,\n",
    "        'new_2m30+' : new_client_auc2,\n",
    "        'new_3m30+' : new_client_auc3,\n",
    "        'new_4m30+' : new_client_auc4,\n",
    "        'old_1m30+' : old_client_auc1,\n",
    "        'old_2m30+' : old_client_auc2,\n",
    "        'old_3m30+' : old_client_auc3,\n",
    "        'old_4m30+' : old_client_auc4,\n",
    "    }\n",
    "\n",
    "def train(train_ids, test_ids, model_class, config):\n",
    "        \n",
    "    torch_dataset = AppDataset(train_ids)\n",
    "    data_loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      \n",
    "        batch_size=args.batch_size,      \n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers = args.n_worker,\n",
    "    )\n",
    "    \n",
    "    model = model_class(config).to(args.device)\n",
    "#     model = UserNetwork().to(args.device)\n",
    "#     model = AppBehaveNetwork().to(args.device)\n",
    "#     model = AppListNetwork().to(args.device)\n",
    "#     model = MaskMultiViewNetwork(config).to(args.device)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "\n",
    "    decay = [\"app_network\"]\n",
    "\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in decay)], \"weight_decay\": args.weight_decay},\n",
    "    ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr = args.lr, weight_decay = args.weight_decay)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=int(len(train_ids)//(args.batch_size)), num_training_steps=int(len(train_ids) / args.batch_size * args.epoch)\n",
    "    )\n",
    "    max_auc = -1\n",
    "    for epoch in range(args.epoch):\n",
    "        model.train()\n",
    "        for step, data in enumerate(tqdm(data_loader)):\n",
    "            loss, y1, y2, y3, y4, _ = model(data)            \n",
    "            #backward\n",
    "            S = time.time()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 2)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "        model.eval()\n",
    "        train_ret_dict = eval_data(model, train_ids)\n",
    "        test_ret_dict = eval_data(model, test_ids, epoch, True, model_class.__name__)\n",
    "        df_ret = pd.DataFrame([\n",
    "            train_ret_dict, test_ret_dict\n",
    "        ], index = ['train', 'test'])\n",
    "        \n",
    "        \n",
    "#         install_behave_test = list(set(install_behave_set) & set(test_ids))\n",
    "#         install_list_test = list(set(install_list_set) & set(test_ids))\n",
    "#         user_info_test = list(set(user_info_set) & set(test_ids))\n",
    "#         user_log_test = list(set(user_log_set) & set(test_ids))\n",
    "        \n",
    "#         behave_ret_dict = eval_data(model, install_behave_test)\n",
    "#         list_ret_dict = eval_data(model, install_list_test)\n",
    "#         userinfo_ret_dict = eval_data(model, user_info_test)\n",
    "#         userlog_ret_dict = eval_data(model, user_log_test)\n",
    "\n",
    "#         df_ret = pd.DataFrame([\n",
    "#             test_ret_dict, behave_ret_dict, list_ret_dict, userinfo_ret_dict, userlog_ret_dict\n",
    "#         ], index = ['test', 'behave', 'list', 'user_info', 'user_log'])\n",
    "\n",
    "        logging.info('epoch : %d' % epoch)\n",
    "        logging.info('\\n%s' % pd.DataFrame(df_ret))\n",
    "        \n",
    "        if max_auc < test_ret_dict['1m30+']:\n",
    "            max_auc = test_ret_dict['1m30+']\n",
    "            use_view_name = '_'.join(use_view_str)\n",
    "            \n",
    "            os.system('rm 1_data/ret_%s*'%use_view_name)\n",
    "            os.system('rm 1_data/model_%s*'%use_view_name)\n",
    "            \n",
    "            df_ret.to_csv('1_data/ret_%s_epoch_%d.csv' % (use_view_name, epoch), index=False)\n",
    "            torch.save(model, '1_data/model_%s_epoch_%d.torch.model' % (use_view_name, epoch))\n",
    "\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "code_folding": [
     0,
     11,
     22,
     33,
     44,
     62
    ]
   },
   "outputs": [],
   "source": [
    "class UserNetConfig():\n",
    "    _instance = None\n",
    "    def __new__(cls, *args, **kw):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = object.__new__(cls, *args, **kw)\n",
    "        return cls._instance\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = 256\n",
    "\n",
    "class AppbehaveConfig():\n",
    "    _instance = None\n",
    "    def __new__(cls, *args, **kw):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = object.__new__(cls, *args, **kw)\n",
    "        return cls._instance\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = 256\n",
    "        \n",
    "class AppListConfig():\n",
    "    _instance = None\n",
    "    def __new__(cls, *args, **kw):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = object.__new__(cls, *args, **kw)\n",
    "        return cls._instance\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = 256\n",
    "        \n",
    "class Userlogconfig():\n",
    "    _instance = None\n",
    "    def __new__(cls, *args, **kw):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = object.__new__(cls, *args, **kw)\n",
    "        return cls._instance\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = 256\n",
    "\n",
    "class MultiviewConfig():\n",
    "    _instance = None\n",
    "    def __new__(cls, *args, **kw):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = object.__new__(cls, *args, **kw)\n",
    "        return cls._instance\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = 256\n",
    "#         self.app_list_net = torch.load('app_list_net.model.torch')\n",
    "#         self.app_behave_net =  torch.load('app_list_net.model.torch')\n",
    "#         self.user_net =  torch.load('user_net.model.torch')\n",
    "        self.app_list_net = AppListNetwork(AppListConfig())\n",
    "        self.app_behave_net = AppBehaveNetwork(AppbehaveConfig())\n",
    "        self.user_net = UserNetwork(UserNetConfig())\n",
    "        self.userlog_network = UserlogNetwork(Userlogconfig())\n",
    "\n",
    "class MultiviewAppInteractiveConfig():\n",
    "    _instance = None\n",
    "    def __new__(cls, *args, **kw):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = object.__new__(cls, *args, **kw)\n",
    "        return cls._instance\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = 256\n",
    "#         self.app_list_net = torch.load('app_list_net.model.torch')\n",
    "#         self.app_behave_net =  torch.load('app_list_net.model.torch')\n",
    "#         self.user_net =  torch.load('user_net.model.torch')\n",
    "        self.app_net = AppInteractiveNetwork(AppListConfig())\n",
    "        self.user_net = UserNetwork(UserNetConfig())\n",
    "        self.userlog_network = UserlogNetwork(Userlogconfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-13 18:09:35,279 - INFO - use views : app_list_app_behave\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c73a60b51ec4d15a0a95c5c1d3ad5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-13 18:09:47,860 - INFO - epoch : 0\n",
      "2020-11-13 18:09:47,870 - INFO - \n",
      "           loss     1m30+     2m30+     3m30+     4m30+  new_1m30+  new_2m30+  \\\n",
      "train  1.280747  0.499483  0.545181  0.545704  0.540150   0.461910   0.507194   \n",
      "test   1.238840  0.555466  0.513286  0.520228  0.513382   0.554038   0.545075   \n",
      "\n",
      "       new_3m30+  new_4m30+  old_1m30+  old_2m30+  old_3m30+  old_4m30+  \n",
      "train   0.521933   0.506468   0.588494   0.584463   0.559755   0.565957  \n",
      "test    0.559945   0.557310   0.633490   0.484943   0.488548   0.479661  \n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MaskMultiViewNetworkDifferentGeneration. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MaskMultiViewEncoderAppInteractive. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type UserNetwork. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Dense. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GeLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type AppInteractiveNetwork. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MappedAlignment. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type FullFusion. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type UserlogNetwork. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MLPAttentionPool. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type MaskMlpAttention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f05fc38a4d4334808f1743ef927f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-bcd91e2b16c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'use views : %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_view_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     multiview_net = train(random.sample(all_train_id, 5000), all_test_id, \\\n\u001b[0;32m---> 20\u001b[0;31m                           MaskMultiViewNetworkDifferentGeneration, MultiviewAppInteractiveConfig())\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-0b917f6079c2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_ids, test_ids, model_class, config)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0;31m#backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-8e39aea424d3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mhidden_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_app\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_userlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiview_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0mlabels1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mlabels2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-8e39aea424d3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mloss_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my3_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my4_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mloss_app\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_app\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2_app\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my3_app\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my4_app\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_app\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mloss_userlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_userlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2_userlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my3_userlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my4_userlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_userlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muserlog_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_app\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_userlog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-5ed0c083111f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_dict)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0my3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0my4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-5ed0c083111f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mUserNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyr/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(16):\n",
    "    use = []\n",
    "    for j in range(4):\n",
    "        if (i >> j) & 1:\n",
    "            use.append(j)\n",
    "    if len(use) == 4 or len(use) <= 1:\n",
    "        continue\n",
    "    use_list = [False, False, False, False]\n",
    "    for u in use:\n",
    "        use_list[u] = True\n",
    "    use_user_attribute, use_app_list, use_app_behave, use_user_log = \\\n",
    "    use_list[0], use_list[1], use_list[2], use_list[3] \n",
    "    \n",
    "    view_str = ['user_attribute', 'app_list', 'app_behave', 'user_log']\n",
    "    use_view_str = [v for u, v in zip(use_list, view_str) if u]\n",
    "    logging.info('use views : %s' % '_'.join(use_view_str))\n",
    "    multiview_net = train(all_train_id, all_test_id, \\\n",
    "                          MaskMultiViewNetworkDifferentGeneration, MultiviewAppInteractiveConfig())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(hyr)\n",
   "language": "python",
   "name": "hyr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
